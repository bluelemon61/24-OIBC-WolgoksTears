{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024 OIBC Challenge\n",
    "## (Deep Learning version skeleton 02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\24-OIBC-WolgoksTears\\personal_files\\hoon\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "print(os.getcwd())  # 현재 작업 경로 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actual_weather_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>real_feel_temp</th>\n",
       "      <th>rel_hum</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>wind_spd</th>\n",
       "      <th>wind_gust_spd</th>\n",
       "      <th>uv_idx</th>\n",
       "      <th>vis</th>\n",
       "      <th>cld_cvr</th>\n",
       "      <th>ceiling</th>\n",
       "      <th>wet_bulb_temp</th>\n",
       "      <th>precip_1h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 00:00:00</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>579.000000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-01 01:00:00</td>\n",
       "      <td>7.158333</td>\n",
       "      <td>3.041667</td>\n",
       "      <td>72.666667</td>\n",
       "      <td>2.508333</td>\n",
       "      <td>234.666667</td>\n",
       "      <td>20.483333</td>\n",
       "      <td>26.366667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.783333</td>\n",
       "      <td>97.750000</td>\n",
       "      <td>693.416667</td>\n",
       "      <td>5.091667</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-01 02:00:00</td>\n",
       "      <td>6.477778</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>2.433333</td>\n",
       "      <td>262.888889</td>\n",
       "      <td>21.944444</td>\n",
       "      <td>27.433333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.033333</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>616.222222</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>0.011111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-01 03:00:00</td>\n",
       "      <td>6.045455</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>74.545455</td>\n",
       "      <td>1.663636</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>22.490909</td>\n",
       "      <td>27.645455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>62.818182</td>\n",
       "      <td>8692.363636</td>\n",
       "      <td>4.209091</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-01 04:00:00</td>\n",
       "      <td>5.430000</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>68.100000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>256.800000</td>\n",
       "      <td>26.140000</td>\n",
       "      <td>42.440000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>38.100000</td>\n",
       "      <td>10911.800000</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime      temp  real_feel_temp    rel_hum  dew_point  \\\n",
       "0 2024-03-01 00:00:00  8.500000        8.000000  81.000000   5.500000   \n",
       "1 2024-03-01 01:00:00  7.158333        3.041667  72.666667   2.508333   \n",
       "2 2024-03-01 02:00:00  6.477778        2.111111  75.666667   2.433333   \n",
       "3 2024-03-01 03:00:00  6.045455        0.900000  74.545455   1.663636   \n",
       "4 2024-03-01 04:00:00  5.430000       -0.090000  68.100000  -0.030000   \n",
       "\n",
       "     wind_dir   wind_spd  wind_gust_spd  uv_idx        vis    cld_cvr  \\\n",
       "0  270.000000   6.100000      17.600000     0.0  20.900000  91.000000   \n",
       "1  234.666667  20.483333      26.366667     0.0  20.783333  97.750000   \n",
       "2  262.888889  21.944444      27.433333     0.0  20.033333  86.333333   \n",
       "3  213.000000  22.490909      27.645455     0.0  19.900000  62.818182   \n",
       "4  256.800000  26.140000      42.440000     0.0  23.800000  38.100000   \n",
       "\n",
       "        ceiling  wet_bulb_temp  precip_1h  \n",
       "0    579.000000       7.100000   0.100000  \n",
       "1    693.416667       5.091667   0.008333  \n",
       "2    616.222222       4.733333   0.011111  \n",
       "3   8692.363636       4.209091   0.136364  \n",
       "4  10911.800000       3.180000   0.410000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "actual_weather_1 = pd.read_csv(\"../../data_files/actual_weather_1.csv\")\n",
    "\n",
    "# 'ts'를 datetime 형식으로 변환 후 1시간 단위로 맞추기\n",
    "actual_weather_1['datetime'] = pd.to_datetime(actual_weather_1['ts'], unit='s')\n",
    "actual_weather_1['datetime'] = actual_weather_1['datetime'].dt.round('h') + timedelta(hours=9)\n",
    "\n",
    "# 원래 'ts' 열과 'location' 제거\n",
    "actual_weather_1.drop(columns=['ts'], inplace=True)\n",
    "actual_weather_1.drop(columns=['location'], inplace=True)\n",
    "\n",
    "# 1시간 단위로 그룹화하여 평균을 계산 (location을 제외한 모든 열)\n",
    "actual_weather_1 = actual_weather_1.groupby(['datetime'], as_index=False).mean()\n",
    "\n",
    "\n",
    "# weather_forecast에 없는 columns 제거\n",
    "actual_weather_1.drop(columns=['real_feel_temp_shade'], inplace=True)\n",
    "actual_weather_1.drop(columns=['pressure'], inplace=True)\n",
    "actual_weather_1.drop(columns=['appr_temp'], inplace=True)\n",
    "actual_weather_1.drop(columns=['wind_chill_temp'], inplace=True)\n",
    " \n",
    "# 결과 확인\n",
    "actual_weather_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weather_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>real_feel_temp</th>\n",
       "      <th>rel_hum</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>wind_spd</th>\n",
       "      <th>wind_gust_spd</th>\n",
       "      <th>uv_idx</th>\n",
       "      <th>vis</th>\n",
       "      <th>cld_cvr</th>\n",
       "      <th>ceiling</th>\n",
       "      <th>wet_bulb_temp</th>\n",
       "      <th>precip_1h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-02 00:00:00</td>\n",
       "      <td>1.728394</td>\n",
       "      <td>-4.320987</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>-4.320987</td>\n",
       "      <td>335.555556</td>\n",
       "      <td>22.048022</td>\n",
       "      <td>50.604944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.093400</td>\n",
       "      <td>75.555556</td>\n",
       "      <td>1700.106667</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-02 01:00:00</td>\n",
       "      <td>1.851852</td>\n",
       "      <td>-4.506173</td>\n",
       "      <td>64.333333</td>\n",
       "      <td>-4.135800</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>22.048022</td>\n",
       "      <td>50.640711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.378140</td>\n",
       "      <td>84.777778</td>\n",
       "      <td>1249.680000</td>\n",
       "      <td>-0.432099</td>\n",
       "      <td>0.056444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-02 02:00:00</td>\n",
       "      <td>1.790123</td>\n",
       "      <td>-5.061728</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>-3.950616</td>\n",
       "      <td>334.444444</td>\n",
       "      <td>22.656000</td>\n",
       "      <td>51.481144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.392882</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>1229.360000</td>\n",
       "      <td>-0.370370</td>\n",
       "      <td>0.197556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-02 03:00:00</td>\n",
       "      <td>1.604940</td>\n",
       "      <td>-5.308640</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>-3.888887</td>\n",
       "      <td>333.777778</td>\n",
       "      <td>23.263967</td>\n",
       "      <td>51.463267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.195758</td>\n",
       "      <td>94.555556</td>\n",
       "      <td>1933.786667</td>\n",
       "      <td>-0.370370</td>\n",
       "      <td>0.084667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-02 04:00:00</td>\n",
       "      <td>1.851852</td>\n",
       "      <td>-4.876541</td>\n",
       "      <td>66.444444</td>\n",
       "      <td>-3.950616</td>\n",
       "      <td>333.888889</td>\n",
       "      <td>23.871922</td>\n",
       "      <td>50.837400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.825200</td>\n",
       "      <td>82.555556</td>\n",
       "      <td>2600.960000</td>\n",
       "      <td>-0.308642</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime      temp  real_feel_temp    rel_hum  dew_point  \\\n",
       "0 2024-03-02 00:00:00  1.728394       -4.320987  64.333333  -4.320987   \n",
       "1 2024-03-02 01:00:00  1.851852       -4.506173  64.333333  -4.135800   \n",
       "2 2024-03-02 02:00:00  1.790123       -5.061728  66.333333  -3.950616   \n",
       "3 2024-03-02 03:00:00  1.604940       -5.308640  67.333333  -3.888887   \n",
       "4 2024-03-02 04:00:00  1.851852       -4.876541  66.444444  -3.950616   \n",
       "\n",
       "     wind_dir   wind_spd  wind_gust_spd  uv_idx        vis    cld_cvr  \\\n",
       "0  335.555556  22.048022      50.604944     0.0  16.093400  75.555556   \n",
       "1  335.000000  22.048022      50.640711     0.0  15.378140  84.777778   \n",
       "2  334.444444  22.656000      51.481144     0.0  14.392882  89.333333   \n",
       "3  333.777778  23.263967      51.463267     0.0  15.195758  94.555556   \n",
       "4  333.888889  23.871922      50.837400     0.0  15.825200  82.555556   \n",
       "\n",
       "       ceiling  wet_bulb_temp  precip_1h  \n",
       "0  1700.106667      -0.555556   0.000000  \n",
       "1  1249.680000      -0.432099   0.056444  \n",
       "2  1229.360000      -0.370370   0.197556  \n",
       "3  1933.786667      -0.370370   0.084667  \n",
       "4  2600.960000      -0.308642   0.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "weather_forecast_1 = pd.read_csv(\"../../data_files/weather_forecast_1.csv\")\n",
    "\n",
    "# 'ts'를 datetime 형식으로 변환 후 1시간 단위로 맞추기\n",
    "weather_forecast_1['datetime'] = pd.to_datetime(weather_forecast_1['ts'], unit='s')\n",
    "weather_forecast_1['datetime'] = weather_forecast_1['datetime'].dt.round('h') + timedelta(hours=9)\n",
    "\n",
    "# 원래 'ts' 열 제거, 'base_ts' 열 제거, 'location' 제거\n",
    "weather_forecast_1.drop(columns=['ts'], inplace=True)\n",
    "weather_forecast_1.drop(columns=['base_ts'], inplace=True)\n",
    "weather_forecast_1.drop(columns=['location'], inplace=True)\n",
    "\n",
    "# 1시간 단위로 그룹화하여 평균을 계산 (location을 제외한 모든 열)\n",
    "weather_forecast_1 = weather_forecast_1.groupby(['datetime'], as_index=False).mean()\n",
    "\n",
    "\n",
    "# 예보 데이터의 columns 순서를 actual_weather columns 순서와 맞추기\n",
    "weather_forecast_1 = weather_forecast_1[['datetime', 'temp', 'real_feel_temp', 'rel_hum',\n",
    "       'dew_point', 'wind_dir', 'wind_spd', 'wind_gust_spd', 'uv_idx', 'vis',\n",
    "       'cld_cvr', 'ceiling', 'wet_bulb_temp', 'total_liq']]\n",
    "weather_forecast_1['precip_1h'] = weather_forecast_1['total_liq']\n",
    "weather_forecast_1.drop(columns=['total_liq'], inplace=True)  \n",
    "\n",
    "# 결과 확인\n",
    "weather_forecast_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elec_supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>공급능력(kW)</th>\n",
       "      <th>현재 수요(kW)</th>\n",
       "      <th>태양광 발전량kW)</th>\n",
       "      <th>풍력 발전량(kW)</th>\n",
       "      <th>신재생 발전량 총합(kW)</th>\n",
       "      <th>공급 예비력(kW)</th>\n",
       "      <th>운영 예비력(kW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>1.285000e+06</td>\n",
       "      <td>757500.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115593.233333</td>\n",
       "      <td>123350.666667</td>\n",
       "      <td>527166.666667</td>\n",
       "      <td>328500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "      <td>1.238308e+06</td>\n",
       "      <td>727538.461538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68802.153846</td>\n",
       "      <td>77036.569231</td>\n",
       "      <td>510692.307692</td>\n",
       "      <td>312692.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "      <td>1.214818e+06</td>\n",
       "      <td>694090.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45923.181818</td>\n",
       "      <td>53740.109091</td>\n",
       "      <td>520727.272727</td>\n",
       "      <td>318545.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "      <td>1.207923e+06</td>\n",
       "      <td>672000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38567.161538</td>\n",
       "      <td>46614.815385</td>\n",
       "      <td>536000.000000</td>\n",
       "      <td>291000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "      <td>1.192364e+06</td>\n",
       "      <td>666000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22849.272727</td>\n",
       "      <td>30575.990909</td>\n",
       "      <td>526363.636364</td>\n",
       "      <td>318272.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime      공급능력(kW)      현재 수요(kW)  태양광 발전량kW)     풍력 발전량(kW)  \\\n",
       "0 2024-01-01 00:00:00  1.285000e+06  757500.000000         0.0  115593.233333   \n",
       "1 2024-01-01 01:00:00  1.238308e+06  727538.461538         0.0   68802.153846   \n",
       "2 2024-01-01 02:00:00  1.214818e+06  694090.909091         0.0   45923.181818   \n",
       "3 2024-01-01 03:00:00  1.207923e+06  672000.000000         0.0   38567.161538   \n",
       "4 2024-01-01 04:00:00  1.192364e+06  666000.000000         0.0   22849.272727   \n",
       "\n",
       "   신재생 발전량 총합(kW)     공급 예비력(kW)     운영 예비력(kW)  \n",
       "0   123350.666667  527166.666667  328500.000000  \n",
       "1    77036.569231  510692.307692  312692.307692  \n",
       "2    53740.109091  520727.272727  318545.454545  \n",
       "3    46614.815385  536000.000000  291000.000000  \n",
       "4    30575.990909  526363.636364  318272.727273  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "elec_supply = pd.read_csv(\"../../data_files/elec_supply.csv\")\n",
    "\n",
    "# 'ts'를 datetime 형식으로 변환 후 1시간 단위로 맞추기\n",
    "elec_supply['datetime'] = pd.to_datetime(elec_supply['ts'], unit='s')\n",
    "elec_supply['datetime'] = elec_supply['datetime'].dt.round('h') + timedelta(hours=9)\n",
    "\n",
    "# 1시간 단위로 그룹화하여 평균을 계산\n",
    "elec_supply = elec_supply.groupby(['datetime'], as_index=False).mean()\n",
    "\n",
    "# 결과 확인\n",
    "elec_supply.drop(columns=['ts'], inplace=True)  # 원래 'ts' 열 제거\n",
    "elec_supply.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smp_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>하루전가격(원/kWh)</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107.39</td>\n",
       "      <td>2024-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.39</td>\n",
       "      <td>2024-03-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.30</td>\n",
       "      <td>2024-03-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.89</td>\n",
       "      <td>2024-03-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2024-03-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   하루전가격(원/kWh)            datetime\n",
       "0        107.39 2024-03-01 00:00:00\n",
       "1        107.39 2024-03-01 01:00:00\n",
       "2         95.30 2024-03-01 02:00:00\n",
       "3         87.89 2024-03-01 03:00:00\n",
       "4          0.00 2024-03-01 04:00:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "smp_da = pd.read_csv(\"../../data_files/smp_da.csv\")\n",
    "\n",
    "# 'ts'를 datetime 형식으로 변환 후 1시간 단위로 맞추기\n",
    "smp_da['datetime'] = pd.to_datetime(smp_da['ts'], unit='s') + timedelta(hours=9)\n",
    "\n",
    "# 결과 확인\n",
    "smp_da.drop(columns=['ts'], inplace=True)  # 원래 'ts' 열 제거\n",
    "smp_da.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smp_rt_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>실시간 임시 가격(원/kWh)</th>\n",
       "      <th>실시간 확정 가격(원/kWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 00:00:00</td>\n",
       "      <td>95.30</td>\n",
       "      <td>95.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-01 01:00:00</td>\n",
       "      <td>107.39</td>\n",
       "      <td>107.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-01 02:00:00</td>\n",
       "      <td>95.30</td>\n",
       "      <td>95.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-01 03:00:00</td>\n",
       "      <td>87.89</td>\n",
       "      <td>87.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-01 04:00:00</td>\n",
       "      <td>86.50</td>\n",
       "      <td>86.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  실시간 임시 가격(원/kWh)  실시간 확정 가격(원/kWh)\n",
       "0 2024-03-01 00:00:00             95.30             95.30\n",
       "1 2024-03-01 01:00:00            107.39            107.39\n",
       "2 2024-03-01 02:00:00             95.30             95.30\n",
       "3 2024-03-01 03:00:00             87.89             87.89\n",
       "4 2024-03-01 04:00:00             86.50             86.50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "smp_rt_rc = pd.read_csv(\"../../data_files/smp_rt_rc.csv\")\n",
    "\n",
    "# 'ts'를 datetime 형식으로 변환 후 1시간 단위로 맞추기\n",
    "smp_rt_rc['datetime'] = pd.to_datetime(smp_rt_rc['ts'], unit='s')\n",
    "smp_rt_rc['datetime'] = smp_rt_rc['datetime'].dt.round('h') + timedelta(hours=9)\n",
    "\n",
    "# 1시간 단위로 그룹화하여 평균을 계산\n",
    "smp_rt_rc = smp_rt_rc.groupby(['datetime'], as_index=False).mean()\n",
    "\n",
    "# 결과 확인\n",
    "smp_rt_rc.drop(columns=['ts'], inplace=True)  # 원래 'ts' 열 제거\n",
    "smp_rt_rc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### X 데이터\n",
    "\n",
    "- 제주 기상 실측 (n+1)\n",
    "- 제주 전력 시장 실시간 (n-1)\n",
    "- 제주 전력 시장 현황 (n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_weather_1\n",
    "smp_rt_rc['datetime'] += pd.Timedelta(days=2)\n",
    "elec_supply['datetime'] += pd.Timedelta(days=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [actual_weather_1, smp_rt_rc, elec_supply]\n",
    "\n",
    "X = reduce(lambda left, right: pd.merge(left, right, on='datetime', how='inner'), dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Y 데이터\n",
    "\n",
    "- 하루 전 시장 전기 예측 가격(n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = smp_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이토치 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 날짜 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = {\n",
    "  # 최소 2024-03-04\n",
    "  \"train_start_date\": '2024-03-03',\n",
    "  # 최대 2024-10-22\n",
    "  \"train_end_date\": '2024-10-22',\n",
    "  # 예측할 날짜\n",
    "  \"predict_target_date\": '2024-11-03',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[\n",
    "  (X['datetime'] > target_date['train_start_date']) &\n",
    "  (X['datetime'] <= target_date['train_end_date'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.loc[\n",
    "  (Y['datetime'] > target_date['train_start_date']) &\n",
    "  (Y['datetime'] <= target_date['train_end_date'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-03 01:00:00 2024-10-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "targ = datetime.strptime(target_date['train_start_date'], '%Y-%m-%d') + timedelta(hours=1)\n",
    "endd = datetime.strptime(target_date['train_end_date'], '%Y-%m-%d')\n",
    "\n",
    "print(targ, endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17084\\1153060925.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y.drop(idx, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# X 데이터의 특정 시간이 누락되었기 때문에\n",
    "# Y 데이터에서도 누락된 시간대를 제거한다.\n",
    "\n",
    "while targ <= endd:\n",
    "  if not len(X.loc[X['datetime'] == targ]):\n",
    "    idx = Y[Y['datetime'] == targ].index\n",
    "    Y.drop(idx, inplace=True)\n",
    "  \n",
    "  targ = targ + timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5527, 5527)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  print(torch.cuda.get_device_name())\n",
    "  print(torch.__version__)\n",
    "  print(torch.version.cuda)\n",
    "  x = torch.randn(1).cuda()\n",
    "  print(x)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElecDataset(Dataset):\n",
    "  def __init__(self, x_data, y_data):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    columns_to_scale = x_data.columns[1:]\n",
    "    x_data[columns_to_scale] = scaler.fit_transform(x_data[columns_to_scale])\n",
    "    \n",
    "    self.x_data = x_data\n",
    "    self.y_data = y_data\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    target_y = self.y_data['하루전가격(원/kWh)'].iloc[index]\n",
    "    targets = self.x_data.drop(columns='datetime').iloc[index].to_numpy()\n",
    "\n",
    "    return torch.from_numpy(targets).unsqueeze(0), torch.tensor(target_y)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ElecDataset(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dataloader 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset,\n",
    "                        batch_size=24,\n",
    "                        # 데이터의 순서가 중요해서 shuffle하면 안될 듯\n",
    "                        shuffle=False,\n",
    "                        drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "    super(LSTMModel, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    # Define the LSTM layer\n",
    "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dtype=torch.float64)\n",
    "    \n",
    "    # Define a fully connected layer to produce output of size 1\n",
    "    self.fc = nn.Linear(hidden_size, output_size, dtype=torch.float64)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # Set initial hidden and cell states to zeros\n",
    "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=torch.float64).to(x.device)  # hidden state\n",
    "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, dtype=torch.float64).to(x.device)  # cell state\n",
    "    \n",
    "    # Forward propagate LSTM\n",
    "    out, _ = self.lstm(x, (h0, c0))  # out의 shape은 (batch_size, seq_length, hidden_size)입니다.\n",
    "    \n",
    "    # 모든 타임스텝에 대해 최종 출력 처리\n",
    "    out = self.fc(out[:, -1, :])  # 각 배치에 대해 마지막 타임스텝의 출력만 취함, out의 shape은 (batch_size, output_size)로 설정됩니다.\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(X.columns) - 1  # Number of input features\n",
    "hidden_size = 16  # Hidden state size, you can choose other values too\n",
    "output_size = 1  # Single output\n",
    "num_layers = 3  # Number of LSTM layers (you can adjust this)\n",
    "\n",
    "learning_rate = 0.01\n",
    "epoches= 10\n",
    "\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Example input: batch of 16 sequences, each of length 12, with 7 features per timestep\n",
    "# it = iter(dataloader)\n",
    "# input_tensor = next(it)[0]\n",
    "# print(input_tensor)\n",
    "\n",
    "# # Forward pass\n",
    "# output = model(input_tensor)\n",
    "# print(output)  # Expected output: (16, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs, device):\n",
    "    model = model.to(device)  # Move model to GPU/CPU\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        \n",
    "        running_loss = 0.0  # To keep track of loss\n",
    "        for inputs, targets in train_loader:\n",
    "            # Move data to the same device as the model\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.view(-1, 1)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            print(f'outputs: {outputs}')\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()  # Clear the gradients\n",
    "            loss.backward()        # Compute gradients\n",
    "            optimizer.step()        # Update model parameters\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print the loss after each epoch\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: tensor([[-0.2334],\n",
      "        [-0.2335],\n",
      "        [-0.2334],\n",
      "        [-0.2333],\n",
      "        [-0.2334],\n",
      "        [-0.2333],\n",
      "        [-0.2334],\n",
      "        [-0.2335],\n",
      "        [-0.2337],\n",
      "        [-0.2336],\n",
      "        [-0.2331],\n",
      "        [-0.2332],\n",
      "        [-0.2333],\n",
      "        [-0.2335],\n",
      "        [-0.2335],\n",
      "        [-0.2334],\n",
      "        [-0.2335],\n",
      "        [-0.2333],\n",
      "        [-0.2334],\n",
      "        [-0.2334],\n",
      "        [-0.2336],\n",
      "        [-0.2334],\n",
      "        [-0.2334],\n",
      "        [-0.2333]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[-0.1966],\n",
      "        [-0.1967],\n",
      "        [-0.1970],\n",
      "        [-0.1970],\n",
      "        [-0.1968],\n",
      "        [-0.1968],\n",
      "        [-0.1968],\n",
      "        [-0.1967],\n",
      "        [-0.1971],\n",
      "        [-0.1968],\n",
      "        [-0.1966],\n",
      "        [-0.1963],\n",
      "        [-0.1964],\n",
      "        [-0.1965],\n",
      "        [-0.1963],\n",
      "        [-0.1964],\n",
      "        [-0.1965],\n",
      "        [-0.1966],\n",
      "        [-0.1970],\n",
      "        [-0.1970],\n",
      "        [-0.1970],\n",
      "        [-0.1968],\n",
      "        [-0.1966],\n",
      "        [-0.1965]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[-0.1593],\n",
      "        [-0.1590],\n",
      "        [-0.1591],\n",
      "        [-0.1593],\n",
      "        [-0.1592],\n",
      "        [-0.1593],\n",
      "        [-0.1594],\n",
      "        [-0.1593],\n",
      "        [-0.1595],\n",
      "        [-0.1595],\n",
      "        [-0.1593],\n",
      "        [-0.1594],\n",
      "        [-0.1594],\n",
      "        [-0.1593],\n",
      "        [-0.1594],\n",
      "        [-0.1594],\n",
      "        [-0.1593],\n",
      "        [-0.1593],\n",
      "        [-0.1595],\n",
      "        [-0.1596],\n",
      "        [-0.1597],\n",
      "        [-0.1595],\n",
      "        [-0.1597],\n",
      "        [-0.1597]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[-0.1202],\n",
      "        [-0.1200],\n",
      "        [-0.1198],\n",
      "        [-0.1196],\n",
      "        [-0.1199],\n",
      "        [-0.1199],\n",
      "        [-0.1203],\n",
      "        [-0.1206],\n",
      "        [-0.1204],\n",
      "        [-0.1199],\n",
      "        [-0.1200],\n",
      "        [-0.1203],\n",
      "        [-0.1199],\n",
      "        [-0.1202],\n",
      "        [-0.1202],\n",
      "        [-0.1196],\n",
      "        [-0.1195],\n",
      "        [-0.1197],\n",
      "        [-0.1194],\n",
      "        [-0.1202],\n",
      "        [-0.1196],\n",
      "        [-0.1199],\n",
      "        [-0.1198],\n",
      "        [-0.1202]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[-0.0777],\n",
      "        [-0.0773],\n",
      "        [-0.0780],\n",
      "        [-0.0772],\n",
      "        [-0.0770],\n",
      "        [-0.0766],\n",
      "        [-0.0773],\n",
      "        [-0.0771],\n",
      "        [-0.0782],\n",
      "        [-0.0777],\n",
      "        [-0.0755],\n",
      "        [-0.0756],\n",
      "        [-0.0758],\n",
      "        [-0.0770],\n",
      "        [-0.0767],\n",
      "        [-0.0758],\n",
      "        [-0.0768],\n",
      "        [-0.0765],\n",
      "        [-0.0757],\n",
      "        [-0.0757],\n",
      "        [-0.0767],\n",
      "        [-0.0765],\n",
      "        [-0.0776],\n",
      "        [-0.0780]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[-0.0301],\n",
      "        [-0.0304],\n",
      "        [-0.0307],\n",
      "        [-0.0305],\n",
      "        [-0.0308],\n",
      "        [-0.0301],\n",
      "        [-0.0295],\n",
      "        [-0.0294],\n",
      "        [-0.0296],\n",
      "        [-0.0284],\n",
      "        [-0.0289],\n",
      "        [-0.0289],\n",
      "        [-0.0290],\n",
      "        [-0.0283],\n",
      "        [-0.0278],\n",
      "        [-0.0281],\n",
      "        [-0.0285],\n",
      "        [-0.0289],\n",
      "        [-0.0282],\n",
      "        [-0.0285],\n",
      "        [-0.0291],\n",
      "        [-0.0274],\n",
      "        [-0.0278],\n",
      "        [-0.0277]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[0.0259],\n",
      "        [0.0248],\n",
      "        [0.0281],\n",
      "        [0.0261],\n",
      "        [0.0268],\n",
      "        [0.0271],\n",
      "        [0.0257],\n",
      "        [0.0273],\n",
      "        [0.0245],\n",
      "        [0.0286],\n",
      "        [0.0288],\n",
      "        [0.0293],\n",
      "        [0.0276],\n",
      "        [0.0285],\n",
      "        [0.0288],\n",
      "        [0.0284],\n",
      "        [0.0273],\n",
      "        [0.0272],\n",
      "        [0.0251],\n",
      "        [0.0241],\n",
      "        [0.0244],\n",
      "        [0.0232],\n",
      "        [0.0221],\n",
      "        [0.0217]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[0.0839],\n",
      "        [0.0856],\n",
      "        [0.0863],\n",
      "        [0.0853],\n",
      "        [0.0857],\n",
      "        [0.0852],\n",
      "        [0.0857],\n",
      "        [0.0877],\n",
      "        [0.0867],\n",
      "        [0.0860],\n",
      "        [0.0875],\n",
      "        [0.0902],\n",
      "        [0.0928],\n",
      "        [0.0914],\n",
      "        [0.0913],\n",
      "        [0.0964],\n",
      "        [0.0908],\n",
      "        [0.0883],\n",
      "        [0.0866],\n",
      "        [0.0836],\n",
      "        [0.0840],\n",
      "        [0.0856],\n",
      "        [0.0833],\n",
      "        [0.0831]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[0.1615],\n",
      "        [0.1632],\n",
      "        [0.1616],\n",
      "        [0.1615],\n",
      "        [0.1577],\n",
      "        [0.1586],\n",
      "        [0.1588],\n",
      "        [0.1615],\n",
      "        [0.1667],\n",
      "        [0.1764],\n",
      "        [0.1765],\n",
      "        [0.1750],\n",
      "        [0.1781],\n",
      "        [0.1743],\n",
      "        [0.1783],\n",
      "        [0.1756],\n",
      "        [0.1719],\n",
      "        [0.1702],\n",
      "        [0.1634],\n",
      "        [0.1624],\n",
      "        [0.1626],\n",
      "        [0.1631],\n",
      "        [0.1668],\n",
      "        [0.1708]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[0.2513],\n",
      "        [0.2564],\n",
      "        [0.2502],\n",
      "        [0.2443],\n",
      "        [0.2485],\n",
      "        [0.2463],\n",
      "        [0.2479],\n",
      "        [0.2533],\n",
      "        [0.2557],\n",
      "        [0.2595],\n",
      "        [0.2640],\n",
      "        [0.2689],\n",
      "        [0.2686],\n",
      "        [0.2729],\n",
      "        [0.2738],\n",
      "        [0.2709],\n",
      "        [0.2744],\n",
      "        [0.2689],\n",
      "        [0.2613],\n",
      "        [0.2603],\n",
      "        [0.2581],\n",
      "        [0.2547],\n",
      "        [0.2489],\n",
      "        [0.2452]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[0.3435],\n",
      "        [0.3491],\n",
      "        [0.3506],\n",
      "        [0.3412],\n",
      "        [0.3336],\n",
      "        [0.3396],\n",
      "        [0.3402],\n",
      "        [0.3434],\n",
      "        [0.3427],\n",
      "        [0.3308],\n",
      "        [0.3512],\n",
      "        [0.3589],\n",
      "        [0.3539],\n",
      "        [0.3611],\n",
      "        [0.3495],\n",
      "        [0.3501],\n",
      "        [0.3403],\n",
      "        [0.3500],\n",
      "        [0.3548],\n",
      "        [0.3520],\n",
      "        [0.3486],\n",
      "        [0.3467],\n",
      "        [0.3411],\n",
      "        [0.3469]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[0.4698],\n",
      "        [0.4709],\n",
      "        [0.4583],\n",
      "        [0.4670],\n",
      "        [0.4600],\n",
      "        [0.4511],\n",
      "        [0.4621],\n",
      "        [0.4626],\n",
      "        [0.4733],\n",
      "        [0.4901],\n",
      "        [0.4792],\n",
      "        [0.4822],\n",
      "        [0.4916],\n",
      "        [0.4810],\n",
      "        [0.4810],\n",
      "        [0.4890],\n",
      "        [0.4901],\n",
      "        [0.4885],\n",
      "        [0.4903],\n",
      "        [0.4790],\n",
      "        [0.4767],\n",
      "        [0.4731],\n",
      "        [0.4718],\n",
      "        [0.4685]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[0.6001],\n",
      "        [0.6020],\n",
      "        [0.6137],\n",
      "        [0.6030],\n",
      "        [0.6041],\n",
      "        [0.5949],\n",
      "        [0.5954],\n",
      "        [0.6098],\n",
      "        [0.6224],\n",
      "        [0.6137],\n",
      "        [0.6463],\n",
      "        [0.6542],\n",
      "        [0.6504],\n",
      "        [0.6522],\n",
      "        [0.6506],\n",
      "        [0.6481],\n",
      "        [0.6368],\n",
      "        [0.6315],\n",
      "        [0.6204],\n",
      "        [0.6113],\n",
      "        [0.6024],\n",
      "        [0.5969],\n",
      "        [0.5950],\n",
      "        [0.5924]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[0.7365],\n",
      "        [0.7374],\n",
      "        [0.7252],\n",
      "        [0.7153],\n",
      "        [0.7358],\n",
      "        [0.7552],\n",
      "        [0.7537],\n",
      "        [0.7635],\n",
      "        [0.7729],\n",
      "        [0.7484],\n",
      "        [0.7871],\n",
      "        [0.8003],\n",
      "        [0.8113],\n",
      "        [0.8078],\n",
      "        [0.7979],\n",
      "        [0.8108],\n",
      "        [0.7902],\n",
      "        [0.7741],\n",
      "        [0.7682],\n",
      "        [0.7797],\n",
      "        [0.7787],\n",
      "        [0.7790],\n",
      "        [0.7778],\n",
      "        [0.7798]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[0.9465],\n",
      "        [0.9515],\n",
      "        [0.9434],\n",
      "        [0.9386],\n",
      "        [0.9350],\n",
      "        [0.9445],\n",
      "        [0.9471],\n",
      "        [0.9477],\n",
      "        [0.9683],\n",
      "        [0.9643],\n",
      "        [0.9809],\n",
      "        [1.0075],\n",
      "        [1.0091],\n",
      "        [1.0060],\n",
      "        [0.9994],\n",
      "        [0.9901],\n",
      "        [0.9748],\n",
      "        [0.9651],\n",
      "        [0.9635],\n",
      "        [0.9518],\n",
      "        [0.9569],\n",
      "        [0.9555],\n",
      "        [0.9351],\n",
      "        [0.9378]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[1.1095],\n",
      "        [1.1118],\n",
      "        [1.1154],\n",
      "        [1.1146],\n",
      "        [1.1189],\n",
      "        [1.1141],\n",
      "        [1.1002],\n",
      "        [1.1215],\n",
      "        [1.1266],\n",
      "        [1.1192],\n",
      "        [1.1410],\n",
      "        [1.1487],\n",
      "        [1.1492],\n",
      "        [1.1559],\n",
      "        [1.1419],\n",
      "        [1.1394],\n",
      "        [1.1144],\n",
      "        [1.1127],\n",
      "        [1.1345],\n",
      "        [1.1289],\n",
      "        [1.1247],\n",
      "        [1.1283],\n",
      "        [1.1279],\n",
      "        [1.1402]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[1.3451],\n",
      "        [1.3336],\n",
      "        [1.3288],\n",
      "        [1.3228],\n",
      "        [1.3156],\n",
      "        [1.3200],\n",
      "        [1.3231],\n",
      "        [1.3394],\n",
      "        [1.3475],\n",
      "        [1.3660],\n",
      "        [1.3798],\n",
      "        [1.3769],\n",
      "        [1.3878],\n",
      "        [1.3844],\n",
      "        [1.3892],\n",
      "        [1.3960],\n",
      "        [1.3911],\n",
      "        [1.3945],\n",
      "        [1.3717],\n",
      "        [1.3601],\n",
      "        [1.3620],\n",
      "        [1.3690],\n",
      "        [1.3800],\n",
      "        [1.3517]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[1.5450],\n",
      "        [1.5399],\n",
      "        [1.5504],\n",
      "        [1.5406],\n",
      "        [1.5372],\n",
      "        [1.5421],\n",
      "        [1.5536],\n",
      "        [1.5605],\n",
      "        [1.5693],\n",
      "        [1.5610],\n",
      "        [1.5632],\n",
      "        [1.5821],\n",
      "        [1.5932],\n",
      "        [1.5892],\n",
      "        [1.5680],\n",
      "        [1.5766],\n",
      "        [1.5595],\n",
      "        [1.5357],\n",
      "        [1.5409],\n",
      "        [1.5334],\n",
      "        [1.5239],\n",
      "        [1.5316],\n",
      "        [1.5072],\n",
      "        [1.5186]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[1.7217],\n",
      "        [1.7167],\n",
      "        [1.6983],\n",
      "        [1.6994],\n",
      "        [1.6997],\n",
      "        [1.7026],\n",
      "        [1.7121],\n",
      "        [1.7029],\n",
      "        [1.7228],\n",
      "        [1.7423],\n",
      "        [1.7775],\n",
      "        [1.7692],\n",
      "        [1.7565],\n",
      "        [1.7575],\n",
      "        [1.7637],\n",
      "        [1.7742],\n",
      "        [1.7360],\n",
      "        [1.7463],\n",
      "        [1.7474],\n",
      "        [1.7369],\n",
      "        [1.7386],\n",
      "        [1.7405],\n",
      "        [1.7402],\n",
      "        [1.7401]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[1.9499],\n",
      "        [1.9338],\n",
      "        [1.9393],\n",
      "        [1.9414],\n",
      "        [1.9399],\n",
      "        [1.9449],\n",
      "        [1.9554],\n",
      "        [1.9647],\n",
      "        [1.9622],\n",
      "        [1.9831],\n",
      "        [1.9843],\n",
      "        [1.9847],\n",
      "        [1.9844],\n",
      "        [1.9828],\n",
      "        [1.9893],\n",
      "        [1.9912],\n",
      "        [1.9945],\n",
      "        [1.9920],\n",
      "        [1.9899],\n",
      "        [1.9850],\n",
      "        [1.9766],\n",
      "        [1.9842],\n",
      "        [1.9812],\n",
      "        [1.9832]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[2.1817],\n",
      "        [2.1786],\n",
      "        [2.1750],\n",
      "        [2.1753],\n",
      "        [2.1676],\n",
      "        [2.1697],\n",
      "        [2.1812],\n",
      "        [2.1870],\n",
      "        [2.1928],\n",
      "        [2.1820],\n",
      "        [2.2016],\n",
      "        [2.2049],\n",
      "        [2.2042],\n",
      "        [2.2035],\n",
      "        [2.1984],\n",
      "        [2.1938],\n",
      "        [2.1690],\n",
      "        [2.1805],\n",
      "        [2.1671],\n",
      "        [2.1656],\n",
      "        [2.1634],\n",
      "        [2.1655],\n",
      "        [2.1729],\n",
      "        [2.1776]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[2.3745],\n",
      "        [2.3741],\n",
      "        [2.3677],\n",
      "        [2.3640],\n",
      "        [2.3773],\n",
      "        [2.3782],\n",
      "        [2.3811],\n",
      "        [2.3841],\n",
      "        [2.3899],\n",
      "        [2.3968],\n",
      "        [2.3931],\n",
      "        [2.3927],\n",
      "        [2.3913],\n",
      "        [2.3974],\n",
      "        [2.3945],\n",
      "        [2.3841],\n",
      "        [2.3881],\n",
      "        [2.4003],\n",
      "        [2.3945],\n",
      "        [2.3906],\n",
      "        [2.3867],\n",
      "        [2.3802],\n",
      "        [2.3901],\n",
      "        [2.3895]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[2.5905],\n",
      "        [2.5884],\n",
      "        [2.5917],\n",
      "        [2.5842],\n",
      "        [2.5914],\n",
      "        [2.5872],\n",
      "        [2.5776],\n",
      "        [2.5805],\n",
      "        [2.5889],\n",
      "        [2.5928],\n",
      "        [2.5989],\n",
      "        [2.5949],\n",
      "        [2.5931],\n",
      "        [2.6022],\n",
      "        [2.5939],\n",
      "        [2.5848],\n",
      "        [2.5885],\n",
      "        [2.5837],\n",
      "        [2.5811],\n",
      "        [2.5881],\n",
      "        [2.5866],\n",
      "        [2.5805],\n",
      "        [2.5797],\n",
      "        [2.5819]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[2.7879],\n",
      "        [2.7978],\n",
      "        [2.7951],\n",
      "        [2.7939],\n",
      "        [2.7964],\n",
      "        [2.7952],\n",
      "        [2.7915],\n",
      "        [2.7918],\n",
      "        [2.7984],\n",
      "        [2.8022],\n",
      "        [2.8072],\n",
      "        [2.8064],\n",
      "        [2.8045],\n",
      "        [2.8054],\n",
      "        [2.8011],\n",
      "        [2.8036],\n",
      "        [2.8011],\n",
      "        [2.7983],\n",
      "        [2.8017],\n",
      "        [2.7944],\n",
      "        [2.7934],\n",
      "        [2.7841],\n",
      "        [2.7811],\n",
      "        [2.7834]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[2.9932],\n",
      "        [2.9879],\n",
      "        [2.9829],\n",
      "        [2.9821],\n",
      "        [2.9823],\n",
      "        [2.9866],\n",
      "        [2.9944],\n",
      "        [2.9948],\n",
      "        [2.9992],\n",
      "        [3.0033],\n",
      "        [3.0047],\n",
      "        [3.0141],\n",
      "        [3.0112],\n",
      "        [3.0074],\n",
      "        [3.0105],\n",
      "        [3.0110],\n",
      "        [3.0061],\n",
      "        [3.0049],\n",
      "        [3.0074],\n",
      "        [3.0049],\n",
      "        [3.0085],\n",
      "        [3.0070],\n",
      "        [3.0059],\n",
      "        [3.0031]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[3.2142],\n",
      "        [3.2116],\n",
      "        [3.2112],\n",
      "        [3.2122],\n",
      "        [3.2071],\n",
      "        [3.2178],\n",
      "        [3.2243],\n",
      "        [3.2197],\n",
      "        [3.2227],\n",
      "        [3.2287],\n",
      "        [3.2308],\n",
      "        [3.2328],\n",
      "        [3.2323],\n",
      "        [3.2349],\n",
      "        [3.2347],\n",
      "        [3.2327],\n",
      "        [3.2311],\n",
      "        [3.2238],\n",
      "        [3.2215],\n",
      "        [3.2162],\n",
      "        [3.2189],\n",
      "        [3.2203],\n",
      "        [3.2157],\n",
      "        [3.2121]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[3.4231],\n",
      "        [3.4193],\n",
      "        [3.4212],\n",
      "        [3.4189],\n",
      "        [3.4099],\n",
      "        [3.4156],\n",
      "        [3.4151],\n",
      "        [3.4226],\n",
      "        [3.4268],\n",
      "        [3.4315],\n",
      "        [3.4322],\n",
      "        [3.4346],\n",
      "        [3.4367],\n",
      "        [3.4372],\n",
      "        [3.4360],\n",
      "        [3.4296],\n",
      "        [3.4282],\n",
      "        [3.4278],\n",
      "        [3.4245],\n",
      "        [3.4220],\n",
      "        [3.4230],\n",
      "        [3.4232],\n",
      "        [3.4216],\n",
      "        [3.4178]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[3.6126],\n",
      "        [3.6152],\n",
      "        [3.6161],\n",
      "        [3.6133],\n",
      "        [3.6137],\n",
      "        [3.6185],\n",
      "        [3.6227],\n",
      "        [3.6289],\n",
      "        [3.6319],\n",
      "        [3.6333],\n",
      "        [3.6337],\n",
      "        [3.6349],\n",
      "        [3.6359],\n",
      "        [3.6340],\n",
      "        [3.6301],\n",
      "        [3.6328],\n",
      "        [3.6290],\n",
      "        [3.6303],\n",
      "        [3.6338],\n",
      "        [3.6284],\n",
      "        [3.6311],\n",
      "        [3.6322],\n",
      "        [3.6302],\n",
      "        [3.6280]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[3.8210],\n",
      "        [3.8161],\n",
      "        [3.8146],\n",
      "        [3.8106],\n",
      "        [3.8050],\n",
      "        [3.8105],\n",
      "        [3.8119],\n",
      "        [3.8172],\n",
      "        [3.8226],\n",
      "        [3.8224],\n",
      "        [3.8223],\n",
      "        [3.8242],\n",
      "        [3.8249],\n",
      "        [3.8252],\n",
      "        [3.8300],\n",
      "        [3.8297],\n",
      "        [3.8245],\n",
      "        [3.8230],\n",
      "        [3.8213],\n",
      "        [3.8196],\n",
      "        [3.8185],\n",
      "        [3.8132],\n",
      "        [3.8137],\n",
      "        [3.8129]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[4.0107],\n",
      "        [4.0129],\n",
      "        [4.0133],\n",
      "        [4.0117],\n",
      "        [4.0092],\n",
      "        [4.0094],\n",
      "        [4.0129],\n",
      "        [4.0156],\n",
      "        [4.0231],\n",
      "        [4.0162],\n",
      "        [4.0200],\n",
      "        [4.0209],\n",
      "        [4.0203],\n",
      "        [4.0235],\n",
      "        [4.0251],\n",
      "        [4.0268],\n",
      "        [4.0227],\n",
      "        [4.0141],\n",
      "        [4.0144],\n",
      "        [4.0138],\n",
      "        [4.0167],\n",
      "        [4.0155],\n",
      "        [4.0168],\n",
      "        [4.0191]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[4.2123],\n",
      "        [4.2124],\n",
      "        [4.2123],\n",
      "        [4.2154],\n",
      "        [4.2136],\n",
      "        [4.2110],\n",
      "        [4.2137],\n",
      "        [4.2158],\n",
      "        [4.2164],\n",
      "        [4.2193],\n",
      "        [4.2186],\n",
      "        [4.2182],\n",
      "        [4.2178],\n",
      "        [4.2177],\n",
      "        [4.2192],\n",
      "        [4.2168],\n",
      "        [4.2169],\n",
      "        [4.2199],\n",
      "        [4.2166],\n",
      "        [4.2179],\n",
      "        [4.2174],\n",
      "        [4.2161],\n",
      "        [4.2148],\n",
      "        [4.2159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[4.4082],\n",
      "        [4.4096],\n",
      "        [4.4081],\n",
      "        [4.4078],\n",
      "        [4.4071],\n",
      "        [4.4066],\n",
      "        [4.4045],\n",
      "        [4.4080],\n",
      "        [4.4082],\n",
      "        [4.4110],\n",
      "        [4.4085],\n",
      "        [4.4094],\n",
      "        [4.4103],\n",
      "        [4.4106],\n",
      "        [4.4132],\n",
      "        [4.4124],\n",
      "        [4.4119],\n",
      "        [4.4099],\n",
      "        [4.4090],\n",
      "        [4.4077],\n",
      "        [4.4064],\n",
      "        [4.4067],\n",
      "        [4.4089],\n",
      "        [4.4068]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[4.5998],\n",
      "        [4.5983],\n",
      "        [4.5994],\n",
      "        [4.5981],\n",
      "        [4.5979],\n",
      "        [4.5986],\n",
      "        [4.5971],\n",
      "        [4.5960],\n",
      "        [4.5967],\n",
      "        [4.5933],\n",
      "        [4.5983],\n",
      "        [4.5994],\n",
      "        [4.6004],\n",
      "        [4.5992],\n",
      "        [4.5997],\n",
      "        [4.5996],\n",
      "        [4.6009],\n",
      "        [4.6027],\n",
      "        [4.6019],\n",
      "        [4.6010],\n",
      "        [4.6010],\n",
      "        [4.5999],\n",
      "        [4.5989],\n",
      "        [4.5977]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[4.7859],\n",
      "        [4.7863],\n",
      "        [4.7843],\n",
      "        [4.7848],\n",
      "        [4.7857],\n",
      "        [4.7863],\n",
      "        [4.7855],\n",
      "        [4.7884],\n",
      "        [4.7874],\n",
      "        [4.7888],\n",
      "        [4.7899],\n",
      "        [4.7896],\n",
      "        [4.7893],\n",
      "        [4.7877],\n",
      "        [4.7883],\n",
      "        [4.7879],\n",
      "        [4.7864],\n",
      "        [4.7853],\n",
      "        [4.7843],\n",
      "        [4.7845],\n",
      "        [4.7854],\n",
      "        [4.7855],\n",
      "        [4.7832],\n",
      "        [4.7849]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[4.9703],\n",
      "        [4.9717],\n",
      "        [4.9702],\n",
      "        [4.9703],\n",
      "        [4.9704],\n",
      "        [4.9705],\n",
      "        [4.9719],\n",
      "        [4.9721],\n",
      "        [4.9719],\n",
      "        [4.9737],\n",
      "        [4.9742],\n",
      "        [4.9743],\n",
      "        [4.9745],\n",
      "        [4.9737],\n",
      "        [4.9735],\n",
      "        [4.9736],\n",
      "        [4.9731],\n",
      "        [4.9707],\n",
      "        [4.9722],\n",
      "        [4.9710],\n",
      "        [4.9707],\n",
      "        [4.9704],\n",
      "        [4.9697],\n",
      "        [4.9717]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[5.1544],\n",
      "        [5.1562],\n",
      "        [5.1557],\n",
      "        [5.1553],\n",
      "        [5.1540],\n",
      "        [5.1536],\n",
      "        [5.1547],\n",
      "        [5.1570],\n",
      "        [5.1570],\n",
      "        [5.1582],\n",
      "        [5.1600],\n",
      "        [5.1609],\n",
      "        [5.1610],\n",
      "        [5.1604],\n",
      "        [5.1600],\n",
      "        [5.1600],\n",
      "        [5.1587],\n",
      "        [5.1568],\n",
      "        [5.1576],\n",
      "        [5.1551],\n",
      "        [5.1563],\n",
      "        [5.1557],\n",
      "        [5.1540],\n",
      "        [5.1549]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[5.3377],\n",
      "        [5.3378],\n",
      "        [5.3370],\n",
      "        [5.3380],\n",
      "        [5.3381],\n",
      "        [5.3388],\n",
      "        [5.3392],\n",
      "        [5.3389],\n",
      "        [5.3394],\n",
      "        [5.3397],\n",
      "        [5.3394],\n",
      "        [5.3401],\n",
      "        [5.3403],\n",
      "        [5.3402],\n",
      "        [5.3408],\n",
      "        [5.3399],\n",
      "        [5.3396],\n",
      "        [5.3392],\n",
      "        [5.3396],\n",
      "        [5.3377],\n",
      "        [5.3363],\n",
      "        [5.3386],\n",
      "        [5.3385],\n",
      "        [5.3397]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[5.5176],\n",
      "        [5.5178],\n",
      "        [5.5168],\n",
      "        [5.5173],\n",
      "        [5.5169],\n",
      "        [5.5165],\n",
      "        [5.5175],\n",
      "        [5.5177],\n",
      "        [5.5195],\n",
      "        [5.5182],\n",
      "        [5.5206],\n",
      "        [5.5207],\n",
      "        [5.5213],\n",
      "        [5.5198],\n",
      "        [5.5203],\n",
      "        [5.5197],\n",
      "        [5.5194],\n",
      "        [5.5191],\n",
      "        [5.5171],\n",
      "        [5.5171],\n",
      "        [5.5173],\n",
      "        [5.5162],\n",
      "        [5.5168],\n",
      "        [5.5166]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[5.6936],\n",
      "        [5.6927],\n",
      "        [5.6928],\n",
      "        [5.6927],\n",
      "        [5.6926],\n",
      "        [5.6935],\n",
      "        [5.6940],\n",
      "        [5.6943],\n",
      "        [5.6947],\n",
      "        [5.6956],\n",
      "        [5.6957],\n",
      "        [5.6957],\n",
      "        [5.6960],\n",
      "        [5.6957],\n",
      "        [5.6952],\n",
      "        [5.6948],\n",
      "        [5.6939],\n",
      "        [5.6936],\n",
      "        [5.6946],\n",
      "        [5.6945],\n",
      "        [5.6944],\n",
      "        [5.6944],\n",
      "        [5.6939],\n",
      "        [5.6953]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[5.8679],\n",
      "        [5.8674],\n",
      "        [5.8673],\n",
      "        [5.8672],\n",
      "        [5.8674],\n",
      "        [5.8678],\n",
      "        [5.8690],\n",
      "        [5.8695],\n",
      "        [5.8688],\n",
      "        [5.8701],\n",
      "        [5.8694],\n",
      "        [5.8704],\n",
      "        [5.8703],\n",
      "        [5.8700],\n",
      "        [5.8699],\n",
      "        [5.8695],\n",
      "        [5.8689],\n",
      "        [5.8684],\n",
      "        [5.8685],\n",
      "        [5.8685],\n",
      "        [5.8688],\n",
      "        [5.8685],\n",
      "        [5.8688],\n",
      "        [5.8688]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[6.0387],\n",
      "        [6.0380],\n",
      "        [6.0381],\n",
      "        [6.0378],\n",
      "        [6.0379],\n",
      "        [6.0378],\n",
      "        [6.0382],\n",
      "        [6.0388],\n",
      "        [6.0395],\n",
      "        [6.0395],\n",
      "        [6.0407],\n",
      "        [6.0404],\n",
      "        [6.0403],\n",
      "        [6.0407],\n",
      "        [6.0406],\n",
      "        [6.0404],\n",
      "        [6.0399],\n",
      "        [6.0397],\n",
      "        [6.0393],\n",
      "        [6.0390],\n",
      "        [6.0391],\n",
      "        [6.0391],\n",
      "        [6.0388],\n",
      "        [6.0390]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[6.2060],\n",
      "        [6.2056],\n",
      "        [6.2054],\n",
      "        [6.2055],\n",
      "        [6.2058],\n",
      "        [6.2060],\n",
      "        [6.2058],\n",
      "        [6.2065],\n",
      "        [6.2068],\n",
      "        [6.2068],\n",
      "        [6.2072],\n",
      "        [6.2074],\n",
      "        [6.2074],\n",
      "        [6.2071],\n",
      "        [6.2066],\n",
      "        [6.2067],\n",
      "        [6.2065],\n",
      "        [6.2064],\n",
      "        [6.2064],\n",
      "        [6.2064],\n",
      "        [6.2065],\n",
      "        [6.2061],\n",
      "        [6.2062],\n",
      "        [6.2062]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[6.3695],\n",
      "        [6.3700],\n",
      "        [6.3700],\n",
      "        [6.3699],\n",
      "        [6.3693],\n",
      "        [6.3693],\n",
      "        [6.3703],\n",
      "        [6.3703],\n",
      "        [6.3709],\n",
      "        [6.3714],\n",
      "        [6.3716],\n",
      "        [6.3716],\n",
      "        [6.3716],\n",
      "        [6.3714],\n",
      "        [6.3714],\n",
      "        [6.3712],\n",
      "        [6.3710],\n",
      "        [6.3707],\n",
      "        [6.3706],\n",
      "        [6.3703],\n",
      "        [6.3707],\n",
      "        [6.3708],\n",
      "        [6.3706],\n",
      "        [6.3706]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[6.5309],\n",
      "        [6.5307],\n",
      "        [6.5310],\n",
      "        [6.5302],\n",
      "        [6.5305],\n",
      "        [6.5306],\n",
      "        [6.5306],\n",
      "        [6.5307],\n",
      "        [6.5311],\n",
      "        [6.5313],\n",
      "        [6.5314],\n",
      "        [6.5315],\n",
      "        [6.5317],\n",
      "        [6.5318],\n",
      "        [6.5316],\n",
      "        [6.5316],\n",
      "        [6.5313],\n",
      "        [6.5307],\n",
      "        [6.5305],\n",
      "        [6.5304],\n",
      "        [6.5306],\n",
      "        [6.5301],\n",
      "        [6.5304],\n",
      "        [6.5304]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[6.6915],\n",
      "        [6.6913],\n",
      "        [6.6913],\n",
      "        [6.6915],\n",
      "        [6.6911],\n",
      "        [6.6917],\n",
      "        [6.6915],\n",
      "        [6.6915],\n",
      "        [6.6922],\n",
      "        [6.6925],\n",
      "        [6.6925],\n",
      "        [6.6925],\n",
      "        [6.6926],\n",
      "        [6.6925],\n",
      "        [6.6923],\n",
      "        [6.6924],\n",
      "        [6.6921],\n",
      "        [6.6921],\n",
      "        [6.6920],\n",
      "        [6.6921],\n",
      "        [6.6920],\n",
      "        [6.6918],\n",
      "        [6.6919],\n",
      "        [6.6915]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[6.8521],\n",
      "        [6.8520],\n",
      "        [6.8521],\n",
      "        [6.8522],\n",
      "        [6.8522],\n",
      "        [6.8516],\n",
      "        [6.8516],\n",
      "        [6.8520],\n",
      "        [6.8523],\n",
      "        [6.8527],\n",
      "        [6.8526],\n",
      "        [6.8524],\n",
      "        [6.8526],\n",
      "        [6.8525],\n",
      "        [6.8525],\n",
      "        [6.8524],\n",
      "        [6.8521],\n",
      "        [6.8518],\n",
      "        [6.8519],\n",
      "        [6.8516],\n",
      "        [6.8516],\n",
      "        [6.8516],\n",
      "        [6.8514],\n",
      "        [6.8513]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[7.0106],\n",
      "        [7.0103],\n",
      "        [7.0109],\n",
      "        [7.0106],\n",
      "        [7.0102],\n",
      "        [7.0096],\n",
      "        [7.0105],\n",
      "        [7.0112],\n",
      "        [7.0113],\n",
      "        [7.0116],\n",
      "        [7.0116],\n",
      "        [7.0118],\n",
      "        [7.0119],\n",
      "        [7.0118],\n",
      "        [7.0117],\n",
      "        [7.0113],\n",
      "        [7.0111],\n",
      "        [7.0112],\n",
      "        [7.0113],\n",
      "        [7.0109],\n",
      "        [7.0109],\n",
      "        [7.0105],\n",
      "        [7.0105],\n",
      "        [7.0102]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[7.1662],\n",
      "        [7.1663],\n",
      "        [7.1660],\n",
      "        [7.1660],\n",
      "        [7.1660],\n",
      "        [7.1661],\n",
      "        [7.1665],\n",
      "        [7.1673],\n",
      "        [7.1675],\n",
      "        [7.1677],\n",
      "        [7.1676],\n",
      "        [7.1676],\n",
      "        [7.1677],\n",
      "        [7.1676],\n",
      "        [7.1673],\n",
      "        [7.1675],\n",
      "        [7.1671],\n",
      "        [7.1671],\n",
      "        [7.1671],\n",
      "        [7.1668],\n",
      "        [7.1669],\n",
      "        [7.1669],\n",
      "        [7.1668],\n",
      "        [7.1671]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[7.3200],\n",
      "        [7.3199],\n",
      "        [7.3199],\n",
      "        [7.3200],\n",
      "        [7.3201],\n",
      "        [7.3201],\n",
      "        [7.3204],\n",
      "        [7.3204],\n",
      "        [7.3204],\n",
      "        [7.3208],\n",
      "        [7.3207],\n",
      "        [7.3208],\n",
      "        [7.3208],\n",
      "        [7.3209],\n",
      "        [7.3208],\n",
      "        [7.3207],\n",
      "        [7.3206],\n",
      "        [7.3202],\n",
      "        [7.3201],\n",
      "        [7.3199],\n",
      "        [7.3201],\n",
      "        [7.3199],\n",
      "        [7.3199],\n",
      "        [7.3200]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[7.4729],\n",
      "        [7.4727],\n",
      "        [7.4727],\n",
      "        [7.4728],\n",
      "        [7.4728],\n",
      "        [7.4728],\n",
      "        [7.4730],\n",
      "        [7.4731],\n",
      "        [7.4732],\n",
      "        [7.4733],\n",
      "        [7.4734],\n",
      "        [7.4734],\n",
      "        [7.4734],\n",
      "        [7.4735],\n",
      "        [7.4733],\n",
      "        [7.4733],\n",
      "        [7.4732],\n",
      "        [7.4729],\n",
      "        [7.4728],\n",
      "        [7.4730],\n",
      "        [7.4728],\n",
      "        [7.4729],\n",
      "        [7.4728],\n",
      "        [7.4727]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[7.6253],\n",
      "        [7.6250],\n",
      "        [7.6250],\n",
      "        [7.6251],\n",
      "        [7.6254],\n",
      "        [7.6255],\n",
      "        [7.6255],\n",
      "        [7.6256],\n",
      "        [7.6258],\n",
      "        [7.6258],\n",
      "        [7.6259],\n",
      "        [7.6258],\n",
      "        [7.6257],\n",
      "        [7.6257],\n",
      "        [7.6257],\n",
      "        [7.6257],\n",
      "        [7.6256],\n",
      "        [7.6256],\n",
      "        [7.6255],\n",
      "        [7.6255],\n",
      "        [7.6254],\n",
      "        [7.6254],\n",
      "        [7.6253],\n",
      "        [7.6253]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[7.7781],\n",
      "        [7.7782],\n",
      "        [7.7782],\n",
      "        [7.7782],\n",
      "        [7.7781],\n",
      "        [7.7780],\n",
      "        [7.7782],\n",
      "        [7.7782],\n",
      "        [7.7783],\n",
      "        [7.7784],\n",
      "        [7.7785],\n",
      "        [7.7785],\n",
      "        [7.7785],\n",
      "        [7.7785],\n",
      "        [7.7784],\n",
      "        [7.7783],\n",
      "        [7.7783],\n",
      "        [7.7781],\n",
      "        [7.7780],\n",
      "        [7.7781],\n",
      "        [7.7781],\n",
      "        [7.7780],\n",
      "        [7.7779],\n",
      "        [7.7779]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[7.9316],\n",
      "        [7.9316],\n",
      "        [7.9315],\n",
      "        [7.9317],\n",
      "        [7.9316],\n",
      "        [7.9318],\n",
      "        [7.9319],\n",
      "        [7.9321],\n",
      "        [7.9322],\n",
      "        [7.9322],\n",
      "        [7.9322],\n",
      "        [7.9322],\n",
      "        [7.9322],\n",
      "        [7.9322],\n",
      "        [7.9322],\n",
      "        [7.9323],\n",
      "        [7.9322],\n",
      "        [7.9322],\n",
      "        [7.9321],\n",
      "        [7.9319],\n",
      "        [7.9318],\n",
      "        [7.9318],\n",
      "        [7.9318],\n",
      "        [7.9317]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[8.0826],\n",
      "        [8.0825],\n",
      "        [8.0826],\n",
      "        [8.0827],\n",
      "        [8.0825],\n",
      "        [8.0826],\n",
      "        [8.0827],\n",
      "        [8.0826],\n",
      "        [8.0828],\n",
      "        [8.0828],\n",
      "        [8.0829],\n",
      "        [8.0828],\n",
      "        [8.0829],\n",
      "        [8.0828],\n",
      "        [8.0828],\n",
      "        [8.0827],\n",
      "        [8.0826],\n",
      "        [8.0825],\n",
      "        [8.0827],\n",
      "        [8.0824],\n",
      "        [8.0823],\n",
      "        [8.0823],\n",
      "        [8.0825],\n",
      "        [8.0825]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[8.2311],\n",
      "        [8.2310],\n",
      "        [8.2308],\n",
      "        [8.2307],\n",
      "        [8.2309],\n",
      "        [8.2309],\n",
      "        [8.2311],\n",
      "        [8.2313],\n",
      "        [8.2316],\n",
      "        [8.2315],\n",
      "        [8.2315],\n",
      "        [8.2315],\n",
      "        [8.2315],\n",
      "        [8.2316],\n",
      "        [8.2317],\n",
      "        [8.2317],\n",
      "        [8.2315],\n",
      "        [8.2313],\n",
      "        [8.2312],\n",
      "        [8.2308],\n",
      "        [8.2310],\n",
      "        [8.2311],\n",
      "        [8.2310],\n",
      "        [8.2310]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[8.3806],\n",
      "        [8.3807],\n",
      "        [8.3807],\n",
      "        [8.3807],\n",
      "        [8.3807],\n",
      "        [8.3808],\n",
      "        [8.3807],\n",
      "        [8.3807],\n",
      "        [8.3808],\n",
      "        [8.3809],\n",
      "        [8.3809],\n",
      "        [8.3810],\n",
      "        [8.3812],\n",
      "        [8.3812],\n",
      "        [8.3811],\n",
      "        [8.3811],\n",
      "        [8.3808],\n",
      "        [8.3808],\n",
      "        [8.3807],\n",
      "        [8.3805],\n",
      "        [8.3806],\n",
      "        [8.3805],\n",
      "        [8.3806],\n",
      "        [8.3805]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[8.5284],\n",
      "        [8.5283],\n",
      "        [8.5284],\n",
      "        [8.5283],\n",
      "        [8.5284],\n",
      "        [8.5285],\n",
      "        [8.5285],\n",
      "        [8.5287],\n",
      "        [8.5287],\n",
      "        [8.5290],\n",
      "        [8.5290],\n",
      "        [8.5291],\n",
      "        [8.5291],\n",
      "        [8.5290],\n",
      "        [8.5291],\n",
      "        [8.5291],\n",
      "        [8.5290],\n",
      "        [8.5289],\n",
      "        [8.5289],\n",
      "        [8.5287],\n",
      "        [8.5288],\n",
      "        [8.5288],\n",
      "        [8.5288],\n",
      "        [8.5288]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[8.6718],\n",
      "        [8.6719],\n",
      "        [8.6719],\n",
      "        [8.6718],\n",
      "        [8.6719],\n",
      "        [8.6719],\n",
      "        [8.6718],\n",
      "        [8.6719],\n",
      "        [8.6717],\n",
      "        [8.6719],\n",
      "        [8.6720],\n",
      "        [8.6720],\n",
      "        [8.6720],\n",
      "        [8.6720],\n",
      "        [8.6721],\n",
      "        [8.6720],\n",
      "        [8.6720],\n",
      "        [8.6718],\n",
      "        [8.6717],\n",
      "        [8.6718],\n",
      "        [8.6718],\n",
      "        [8.6717],\n",
      "        [8.6716],\n",
      "        [8.6717]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[8.8160],\n",
      "        [8.8159],\n",
      "        [8.8160],\n",
      "        [8.8161],\n",
      "        [8.8160],\n",
      "        [8.8162],\n",
      "        [8.8162],\n",
      "        [8.8162],\n",
      "        [8.8161],\n",
      "        [8.8162],\n",
      "        [8.8163],\n",
      "        [8.8164],\n",
      "        [8.8165],\n",
      "        [8.8165],\n",
      "        [8.8165],\n",
      "        [8.8162],\n",
      "        [8.8163],\n",
      "        [8.8162],\n",
      "        [8.8161],\n",
      "        [8.8161],\n",
      "        [8.8161],\n",
      "        [8.8161],\n",
      "        [8.8162],\n",
      "        [8.8162]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[8.9615],\n",
      "        [8.9616],\n",
      "        [8.9616],\n",
      "        [8.9616],\n",
      "        [8.9616],\n",
      "        [8.9615],\n",
      "        [8.9615],\n",
      "        [8.9615],\n",
      "        [8.9617],\n",
      "        [8.9618],\n",
      "        [8.9619],\n",
      "        [8.9619],\n",
      "        [8.9618],\n",
      "        [8.9618],\n",
      "        [8.9618],\n",
      "        [8.9617],\n",
      "        [8.9617],\n",
      "        [8.9617],\n",
      "        [8.9617],\n",
      "        [8.9618],\n",
      "        [8.9617],\n",
      "        [8.9617],\n",
      "        [8.9616],\n",
      "        [8.9615]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[9.1076],\n",
      "        [9.1075],\n",
      "        [9.1074],\n",
      "        [9.1074],\n",
      "        [9.1075],\n",
      "        [9.1075],\n",
      "        [9.1076],\n",
      "        [9.1077],\n",
      "        [9.1078],\n",
      "        [9.1079],\n",
      "        [9.1080],\n",
      "        [9.1080],\n",
      "        [9.1080],\n",
      "        [9.1079],\n",
      "        [9.1079],\n",
      "        [9.1079],\n",
      "        [9.1077],\n",
      "        [9.1077],\n",
      "        [9.1077],\n",
      "        [9.1075],\n",
      "        [9.1077],\n",
      "        [9.1077],\n",
      "        [9.1076],\n",
      "        [9.1076]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[9.2516],\n",
      "        [9.2516],\n",
      "        [9.2516],\n",
      "        [9.2515],\n",
      "        [9.2514],\n",
      "        [9.2515],\n",
      "        [9.2514],\n",
      "        [9.2515],\n",
      "        [9.2516],\n",
      "        [9.2516],\n",
      "        [9.2517],\n",
      "        [9.2518],\n",
      "        [9.2518],\n",
      "        [9.2518],\n",
      "        [9.2517],\n",
      "        [9.2518],\n",
      "        [9.2517],\n",
      "        [9.2517],\n",
      "        [9.2515],\n",
      "        [9.2515],\n",
      "        [9.2514],\n",
      "        [9.2514],\n",
      "        [9.2513],\n",
      "        [9.2514]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[9.3953],\n",
      "        [9.3951],\n",
      "        [9.3952],\n",
      "        [9.3953],\n",
      "        [9.3954],\n",
      "        [9.3954],\n",
      "        [9.3955],\n",
      "        [9.3955],\n",
      "        [9.3957],\n",
      "        [9.3958],\n",
      "        [9.3958],\n",
      "        [9.3958],\n",
      "        [9.3958],\n",
      "        [9.3958],\n",
      "        [9.3958],\n",
      "        [9.3957],\n",
      "        [9.3957],\n",
      "        [9.3955],\n",
      "        [9.3956],\n",
      "        [9.3955],\n",
      "        [9.3955],\n",
      "        [9.3955],\n",
      "        [9.3955],\n",
      "        [9.3955]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[9.5391],\n",
      "        [9.5391],\n",
      "        [9.5391],\n",
      "        [9.5390],\n",
      "        [9.5391],\n",
      "        [9.5391],\n",
      "        [9.5391],\n",
      "        [9.5392],\n",
      "        [9.5393],\n",
      "        [9.5392],\n",
      "        [9.5392],\n",
      "        [9.5392],\n",
      "        [9.5392],\n",
      "        [9.5393],\n",
      "        [9.5393],\n",
      "        [9.5392],\n",
      "        [9.5393],\n",
      "        [9.5392],\n",
      "        [9.5391],\n",
      "        [9.5391],\n",
      "        [9.5391],\n",
      "        [9.5391],\n",
      "        [9.5390],\n",
      "        [9.5390]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[9.6777],\n",
      "        [9.6778],\n",
      "        [9.6777],\n",
      "        [9.6777],\n",
      "        [9.6777],\n",
      "        [9.6777],\n",
      "        [9.6778],\n",
      "        [9.6778],\n",
      "        [9.6779],\n",
      "        [9.6780],\n",
      "        [9.6780],\n",
      "        [9.6780],\n",
      "        [9.6780],\n",
      "        [9.6780],\n",
      "        [9.6778],\n",
      "        [9.6779],\n",
      "        [9.6780],\n",
      "        [9.6779],\n",
      "        [9.6779],\n",
      "        [9.6780],\n",
      "        [9.6780],\n",
      "        [9.6779],\n",
      "        [9.6778],\n",
      "        [9.6779]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[9.8192],\n",
      "        [9.8192],\n",
      "        [9.8191],\n",
      "        [9.8192],\n",
      "        [9.8192],\n",
      "        [9.8192],\n",
      "        [9.8193],\n",
      "        [9.8193],\n",
      "        [9.8193],\n",
      "        [9.8194],\n",
      "        [9.8194],\n",
      "        [9.8194],\n",
      "        [9.8194],\n",
      "        [9.8194],\n",
      "        [9.8195],\n",
      "        [9.8195],\n",
      "        [9.8195],\n",
      "        [9.8195],\n",
      "        [9.8195],\n",
      "        [9.8194],\n",
      "        [9.8193],\n",
      "        [9.8193],\n",
      "        [9.8192],\n",
      "        [9.8192]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[9.9571],\n",
      "        [9.9572],\n",
      "        [9.9571],\n",
      "        [9.9572],\n",
      "        [9.9572],\n",
      "        [9.9571],\n",
      "        [9.9573],\n",
      "        [9.9572],\n",
      "        [9.9573],\n",
      "        [9.9573],\n",
      "        [9.9573],\n",
      "        [9.9574],\n",
      "        [9.9575],\n",
      "        [9.9575],\n",
      "        [9.9574],\n",
      "        [9.9574],\n",
      "        [9.9573],\n",
      "        [9.9570],\n",
      "        [9.9570],\n",
      "        [9.9571],\n",
      "        [9.9572],\n",
      "        [9.9571],\n",
      "        [9.9570],\n",
      "        [9.9570]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[10.0993],\n",
      "        [10.0993],\n",
      "        [10.0992],\n",
      "        [10.0992],\n",
      "        [10.0991],\n",
      "        [10.0992],\n",
      "        [10.0994],\n",
      "        [10.0994],\n",
      "        [10.0997],\n",
      "        [10.0996],\n",
      "        [10.0996],\n",
      "        [10.0997],\n",
      "        [10.0997],\n",
      "        [10.0997],\n",
      "        [10.0997],\n",
      "        [10.0998],\n",
      "        [10.0997],\n",
      "        [10.0996],\n",
      "        [10.0995],\n",
      "        [10.0993],\n",
      "        [10.0995],\n",
      "        [10.0994],\n",
      "        [10.0993],\n",
      "        [10.0991]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[10.2402],\n",
      "        [10.2402],\n",
      "        [10.2401],\n",
      "        [10.2401],\n",
      "        [10.2399],\n",
      "        [10.2401],\n",
      "        [10.2401],\n",
      "        [10.2404],\n",
      "        [10.2406],\n",
      "        [10.2407],\n",
      "        [10.2407],\n",
      "        [10.2408],\n",
      "        [10.2408],\n",
      "        [10.2407],\n",
      "        [10.2407],\n",
      "        [10.2407],\n",
      "        [10.2407],\n",
      "        [10.2405],\n",
      "        [10.2404],\n",
      "        [10.2403],\n",
      "        [10.2404],\n",
      "        [10.2404],\n",
      "        [10.2403],\n",
      "        [10.2403]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[10.3779],\n",
      "        [10.3778],\n",
      "        [10.3778],\n",
      "        [10.3779],\n",
      "        [10.3778],\n",
      "        [10.3779],\n",
      "        [10.3781],\n",
      "        [10.3780],\n",
      "        [10.3783],\n",
      "        [10.3782],\n",
      "        [10.3783],\n",
      "        [10.3783],\n",
      "        [10.3783],\n",
      "        [10.3784],\n",
      "        [10.3784],\n",
      "        [10.3783],\n",
      "        [10.3782],\n",
      "        [10.3781],\n",
      "        [10.3780],\n",
      "        [10.3780],\n",
      "        [10.3780],\n",
      "        [10.3779],\n",
      "        [10.3780],\n",
      "        [10.3780]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[10.5130],\n",
      "        [10.5130],\n",
      "        [10.5130],\n",
      "        [10.5130],\n",
      "        [10.5129],\n",
      "        [10.5128],\n",
      "        [10.5130],\n",
      "        [10.5128],\n",
      "        [10.5129],\n",
      "        [10.5130],\n",
      "        [10.5131],\n",
      "        [10.5130],\n",
      "        [10.5132],\n",
      "        [10.5133],\n",
      "        [10.5133],\n",
      "        [10.5133],\n",
      "        [10.5133],\n",
      "        [10.5132],\n",
      "        [10.5131],\n",
      "        [10.5130],\n",
      "        [10.5131],\n",
      "        [10.5131],\n",
      "        [10.5131],\n",
      "        [10.5130]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[10.6461],\n",
      "        [10.6460],\n",
      "        [10.6460],\n",
      "        [10.6461],\n",
      "        [10.6460],\n",
      "        [10.6461],\n",
      "        [10.6461],\n",
      "        [10.6462],\n",
      "        [10.6463],\n",
      "        [10.6463],\n",
      "        [10.6463],\n",
      "        [10.6465],\n",
      "        [10.6465],\n",
      "        [10.6464],\n",
      "        [10.6464],\n",
      "        [10.6463],\n",
      "        [10.6463],\n",
      "        [10.6463],\n",
      "        [10.6463],\n",
      "        [10.6461],\n",
      "        [10.6460],\n",
      "        [10.6460],\n",
      "        [10.6459],\n",
      "        [10.6460]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[10.7759],\n",
      "        [10.7758],\n",
      "        [10.7756],\n",
      "        [10.7757],\n",
      "        [10.7757],\n",
      "        [10.7758],\n",
      "        [10.7760],\n",
      "        [10.7761],\n",
      "        [10.7762],\n",
      "        [10.7764],\n",
      "        [10.7764],\n",
      "        [10.7764],\n",
      "        [10.7764],\n",
      "        [10.7762],\n",
      "        [10.7762],\n",
      "        [10.7763],\n",
      "        [10.7763],\n",
      "        [10.7764],\n",
      "        [10.7762],\n",
      "        [10.7762],\n",
      "        [10.7762],\n",
      "        [10.7761],\n",
      "        [10.7761],\n",
      "        [10.7761]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[10.9050],\n",
      "        [10.9050],\n",
      "        [10.9050],\n",
      "        [10.9047],\n",
      "        [10.9049],\n",
      "        [10.9048],\n",
      "        [10.9050],\n",
      "        [10.9051],\n",
      "        [10.9053],\n",
      "        [10.9054],\n",
      "        [10.9054],\n",
      "        [10.9054],\n",
      "        [10.9056],\n",
      "        [10.9056],\n",
      "        [10.9056],\n",
      "        [10.9055],\n",
      "        [10.9056],\n",
      "        [10.9054],\n",
      "        [10.9054],\n",
      "        [10.9053],\n",
      "        [10.9053],\n",
      "        [10.9053],\n",
      "        [10.9052],\n",
      "        [10.9051]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[11.0276],\n",
      "        [11.0276],\n",
      "        [11.0275],\n",
      "        [11.0276],\n",
      "        [11.0274],\n",
      "        [11.0274],\n",
      "        [11.0276],\n",
      "        [11.0276],\n",
      "        [11.0278],\n",
      "        [11.0277],\n",
      "        [11.0279],\n",
      "        [11.0279],\n",
      "        [11.0280],\n",
      "        [11.0279],\n",
      "        [11.0279],\n",
      "        [11.0278],\n",
      "        [11.0277],\n",
      "        [11.0277],\n",
      "        [11.0276],\n",
      "        [11.0275],\n",
      "        [11.0273],\n",
      "        [11.0275],\n",
      "        [11.0272],\n",
      "        [11.0272]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[11.1381],\n",
      "        [11.1378],\n",
      "        [11.1378],\n",
      "        [11.1380],\n",
      "        [11.1377],\n",
      "        [11.1377],\n",
      "        [11.1381],\n",
      "        [11.1383],\n",
      "        [11.1382],\n",
      "        [11.1382],\n",
      "        [11.1380],\n",
      "        [11.1383],\n",
      "        [11.1383],\n",
      "        [11.1382],\n",
      "        [11.1383],\n",
      "        [11.1382],\n",
      "        [11.1381],\n",
      "        [11.1384],\n",
      "        [11.1386],\n",
      "        [11.1384],\n",
      "        [11.1386],\n",
      "        [11.1386],\n",
      "        [11.1386],\n",
      "        [11.1386]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[11.2470],\n",
      "        [11.2470],\n",
      "        [11.2469],\n",
      "        [11.2468],\n",
      "        [11.2466],\n",
      "        [11.2465],\n",
      "        [11.2466],\n",
      "        [11.2465],\n",
      "        [11.2465],\n",
      "        [11.2463],\n",
      "        [11.2463],\n",
      "        [11.2465],\n",
      "        [11.2465],\n",
      "        [11.2463],\n",
      "        [11.2464],\n",
      "        [11.2465],\n",
      "        [11.2465],\n",
      "        [11.2463],\n",
      "        [11.2465],\n",
      "        [11.2469],\n",
      "        [11.2468],\n",
      "        [11.2469],\n",
      "        [11.2470],\n",
      "        [11.2470]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[11.3550],\n",
      "        [11.3550],\n",
      "        [11.3548],\n",
      "        [11.3547],\n",
      "        [11.3547],\n",
      "        [11.3546],\n",
      "        [11.3547],\n",
      "        [11.3546],\n",
      "        [11.3546],\n",
      "        [11.3546],\n",
      "        [11.3545],\n",
      "        [11.3544],\n",
      "        [11.3543],\n",
      "        [11.3543],\n",
      "        [11.3543],\n",
      "        [11.3544],\n",
      "        [11.3543],\n",
      "        [11.3544],\n",
      "        [11.3546],\n",
      "        [11.3548],\n",
      "        [11.3549],\n",
      "        [11.3550],\n",
      "        [11.3550],\n",
      "        [11.3550]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[11.4643],\n",
      "        [11.4642],\n",
      "        [11.4642],\n",
      "        [11.4640],\n",
      "        [11.4640],\n",
      "        [11.4640],\n",
      "        [11.4640],\n",
      "        [11.4638],\n",
      "        [11.4639],\n",
      "        [11.4639],\n",
      "        [11.4638],\n",
      "        [11.4638],\n",
      "        [11.4638],\n",
      "        [11.4637],\n",
      "        [11.4638],\n",
      "        [11.4638],\n",
      "        [11.4638],\n",
      "        [11.4640],\n",
      "        [11.4640],\n",
      "        [11.4640],\n",
      "        [11.4641],\n",
      "        [11.4642],\n",
      "        [11.4642],\n",
      "        [11.4642]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[11.5780],\n",
      "        [11.5780],\n",
      "        [11.5779],\n",
      "        [11.5778],\n",
      "        [11.5778],\n",
      "        [11.5778],\n",
      "        [11.5777],\n",
      "        [11.5777],\n",
      "        [11.5776],\n",
      "        [11.5775],\n",
      "        [11.5777],\n",
      "        [11.5774],\n",
      "        [11.5774],\n",
      "        [11.5775],\n",
      "        [11.5775],\n",
      "        [11.5774],\n",
      "        [11.5776],\n",
      "        [11.5778],\n",
      "        [11.5780],\n",
      "        [11.5779],\n",
      "        [11.5781],\n",
      "        [11.5781],\n",
      "        [11.5781],\n",
      "        [11.5781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[11.6966],\n",
      "        [11.6967],\n",
      "        [11.6965],\n",
      "        [11.6964],\n",
      "        [11.6964],\n",
      "        [11.6963],\n",
      "        [11.6963],\n",
      "        [11.6963],\n",
      "        [11.6964],\n",
      "        [11.6963],\n",
      "        [11.6962],\n",
      "        [11.6962],\n",
      "        [11.6962],\n",
      "        [11.6962],\n",
      "        [11.6961],\n",
      "        [11.6962],\n",
      "        [11.6963],\n",
      "        [11.6963],\n",
      "        [11.6965],\n",
      "        [11.6965],\n",
      "        [11.6965],\n",
      "        [11.6965],\n",
      "        [11.6966],\n",
      "        [11.6966]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[11.8138],\n",
      "        [11.8137],\n",
      "        [11.8136],\n",
      "        [11.8135],\n",
      "        [11.8135],\n",
      "        [11.8133],\n",
      "        [11.8133],\n",
      "        [11.8133],\n",
      "        [11.8133],\n",
      "        [11.8134],\n",
      "        [11.8134],\n",
      "        [11.8133],\n",
      "        [11.8133],\n",
      "        [11.8134],\n",
      "        [11.8134],\n",
      "        [11.8134],\n",
      "        [11.8135],\n",
      "        [11.8136],\n",
      "        [11.8137],\n",
      "        [11.8138],\n",
      "        [11.8137],\n",
      "        [11.8138],\n",
      "        [11.8138],\n",
      "        [11.8138]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[11.9298],\n",
      "        [11.9297],\n",
      "        [11.9297],\n",
      "        [11.9296],\n",
      "        [11.9295],\n",
      "        [11.9295],\n",
      "        [11.9294],\n",
      "        [11.9295],\n",
      "        [11.9295],\n",
      "        [11.9294],\n",
      "        [11.9295],\n",
      "        [11.9294],\n",
      "        [11.9293],\n",
      "        [11.9294],\n",
      "        [11.9294],\n",
      "        [11.9295],\n",
      "        [11.9296],\n",
      "        [11.9296],\n",
      "        [11.9296],\n",
      "        [11.9297],\n",
      "        [11.9298],\n",
      "        [11.9298],\n",
      "        [11.9298],\n",
      "        [11.9298]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[12.0418],\n",
      "        [12.0418],\n",
      "        [12.0417],\n",
      "        [12.0417],\n",
      "        [12.0416],\n",
      "        [12.0416],\n",
      "        [12.0416],\n",
      "        [12.0416],\n",
      "        [12.0417],\n",
      "        [12.0416],\n",
      "        [12.0415],\n",
      "        [12.0415],\n",
      "        [12.0414],\n",
      "        [12.0415],\n",
      "        [12.0414],\n",
      "        [12.0415],\n",
      "        [12.0415],\n",
      "        [12.0416],\n",
      "        [12.0416],\n",
      "        [12.0416],\n",
      "        [12.0416],\n",
      "        [12.0417],\n",
      "        [12.0417],\n",
      "        [12.0418]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[12.1544],\n",
      "        [12.1544],\n",
      "        [12.1543],\n",
      "        [12.1542],\n",
      "        [12.1542],\n",
      "        [12.1542],\n",
      "        [12.1542],\n",
      "        [12.1541],\n",
      "        [12.1540],\n",
      "        [12.1540],\n",
      "        [12.1541],\n",
      "        [12.1540],\n",
      "        [12.1540],\n",
      "        [12.1541],\n",
      "        [12.1542],\n",
      "        [12.1542],\n",
      "        [12.1541],\n",
      "        [12.1540],\n",
      "        [12.1541],\n",
      "        [12.1541],\n",
      "        [12.1543],\n",
      "        [12.1543],\n",
      "        [12.1543],\n",
      "        [12.1543]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[12.2670],\n",
      "        [12.2669],\n",
      "        [12.2669],\n",
      "        [12.2669],\n",
      "        [12.2669],\n",
      "        [12.2669],\n",
      "        [12.2668],\n",
      "        [12.2667],\n",
      "        [12.2666],\n",
      "        [12.2666],\n",
      "        [12.2665],\n",
      "        [12.2665],\n",
      "        [12.2665],\n",
      "        [12.2667],\n",
      "        [12.2666],\n",
      "        [12.2668],\n",
      "        [12.2669],\n",
      "        [12.2670],\n",
      "        [12.2670],\n",
      "        [12.2669],\n",
      "        [12.2670],\n",
      "        [12.2671],\n",
      "        [12.2671],\n",
      "        [12.2671]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[12.3840],\n",
      "        [12.3841],\n",
      "        [12.3840],\n",
      "        [12.3839],\n",
      "        [12.3840],\n",
      "        [12.3839],\n",
      "        [12.3839],\n",
      "        [12.3838],\n",
      "        [12.3839],\n",
      "        [12.3838],\n",
      "        [12.3837],\n",
      "        [12.3838],\n",
      "        [12.3839],\n",
      "        [12.3839],\n",
      "        [12.3839],\n",
      "        [12.3840],\n",
      "        [12.3839],\n",
      "        [12.3839],\n",
      "        [12.3841],\n",
      "        [12.3841],\n",
      "        [12.3841],\n",
      "        [12.3841],\n",
      "        [12.3841],\n",
      "        [12.3841]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[12.5073],\n",
      "        [12.5073],\n",
      "        [12.5072],\n",
      "        [12.5072],\n",
      "        [12.5071],\n",
      "        [12.5071],\n",
      "        [12.5071],\n",
      "        [12.5071],\n",
      "        [12.5071],\n",
      "        [12.5071],\n",
      "        [12.5069],\n",
      "        [12.5070],\n",
      "        [12.5070],\n",
      "        [12.5069],\n",
      "        [12.5070],\n",
      "        [12.5070],\n",
      "        [12.5070],\n",
      "        [12.5071],\n",
      "        [12.5072],\n",
      "        [12.5072],\n",
      "        [12.5073],\n",
      "        [12.5073],\n",
      "        [12.5073],\n",
      "        [12.5073]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[12.6352],\n",
      "        [12.6352],\n",
      "        [12.6352],\n",
      "        [12.6351],\n",
      "        [12.6351],\n",
      "        [12.6351],\n",
      "        [12.6351],\n",
      "        [12.6351],\n",
      "        [12.6350],\n",
      "        [12.6350],\n",
      "        [12.6350],\n",
      "        [12.6350],\n",
      "        [12.6350],\n",
      "        [12.6350],\n",
      "        [12.6350],\n",
      "        [12.6350],\n",
      "        [12.6351],\n",
      "        [12.6351],\n",
      "        [12.6352],\n",
      "        [12.6352],\n",
      "        [12.6353],\n",
      "        [12.6353],\n",
      "        [12.6353],\n",
      "        [12.6352]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[12.7625],\n",
      "        [12.7625],\n",
      "        [12.7624],\n",
      "        [12.7623],\n",
      "        [12.7623],\n",
      "        [12.7622],\n",
      "        [12.7622],\n",
      "        [12.7623],\n",
      "        [12.7622],\n",
      "        [12.7622],\n",
      "        [12.7622],\n",
      "        [12.7623],\n",
      "        [12.7623],\n",
      "        [12.7623],\n",
      "        [12.7623],\n",
      "        [12.7623],\n",
      "        [12.7622],\n",
      "        [12.7623],\n",
      "        [12.7623],\n",
      "        [12.7624],\n",
      "        [12.7624],\n",
      "        [12.7624],\n",
      "        [12.7625],\n",
      "        [12.7625]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[12.8882],\n",
      "        [12.8882],\n",
      "        [12.8881],\n",
      "        [12.8881],\n",
      "        [12.8881],\n",
      "        [12.8880],\n",
      "        [12.8880],\n",
      "        [12.8880],\n",
      "        [12.8880],\n",
      "        [12.8880],\n",
      "        [12.8880],\n",
      "        [12.8879],\n",
      "        [12.8879],\n",
      "        [12.8879],\n",
      "        [12.8879],\n",
      "        [12.8879],\n",
      "        [12.8879],\n",
      "        [12.8879],\n",
      "        [12.8880],\n",
      "        [12.8881],\n",
      "        [12.8881],\n",
      "        [12.8881],\n",
      "        [12.8882],\n",
      "        [12.8881]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[13.0150],\n",
      "        [13.0151],\n",
      "        [13.0151],\n",
      "        [13.0150],\n",
      "        [13.0150],\n",
      "        [13.0150],\n",
      "        [13.0149],\n",
      "        [13.0150],\n",
      "        [13.0149],\n",
      "        [13.0149],\n",
      "        [13.0149],\n",
      "        [13.0149],\n",
      "        [13.0149],\n",
      "        [13.0149],\n",
      "        [13.0148],\n",
      "        [13.0149],\n",
      "        [13.0148],\n",
      "        [13.0148],\n",
      "        [13.0149],\n",
      "        [13.0150],\n",
      "        [13.0150],\n",
      "        [13.0150],\n",
      "        [13.0151],\n",
      "        [13.0151]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[13.1442],\n",
      "        [13.1442],\n",
      "        [13.1441],\n",
      "        [13.1441],\n",
      "        [13.1440],\n",
      "        [13.1440],\n",
      "        [13.1440],\n",
      "        [13.1440],\n",
      "        [13.1440],\n",
      "        [13.1440],\n",
      "        [13.1439],\n",
      "        [13.1440],\n",
      "        [13.1439],\n",
      "        [13.1439],\n",
      "        [13.1438],\n",
      "        [13.1439],\n",
      "        [13.1439],\n",
      "        [13.1441],\n",
      "        [13.1442],\n",
      "        [13.1442],\n",
      "        [13.1442],\n",
      "        [13.1442],\n",
      "        [13.1442],\n",
      "        [13.1442]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[13.2770],\n",
      "        [13.2770],\n",
      "        [13.2769],\n",
      "        [13.2769],\n",
      "        [13.2768],\n",
      "        [13.2768],\n",
      "        [13.2769],\n",
      "        [13.2768],\n",
      "        [13.2768],\n",
      "        [13.2768],\n",
      "        [13.2768],\n",
      "        [13.2767],\n",
      "        [13.2767],\n",
      "        [13.2768],\n",
      "        [13.2768],\n",
      "        [13.2768],\n",
      "        [13.2769],\n",
      "        [13.2769],\n",
      "        [13.2769],\n",
      "        [13.2769],\n",
      "        [13.2770],\n",
      "        [13.2770],\n",
      "        [13.2771],\n",
      "        [13.2771]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[13.4136],\n",
      "        [13.4135],\n",
      "        [13.4135],\n",
      "        [13.4134],\n",
      "        [13.4133],\n",
      "        [13.4133],\n",
      "        [13.4133],\n",
      "        [13.4133],\n",
      "        [13.4133],\n",
      "        [13.4132],\n",
      "        [13.4133],\n",
      "        [13.4133],\n",
      "        [13.4133],\n",
      "        [13.4133],\n",
      "        [13.4132],\n",
      "        [13.4133],\n",
      "        [13.4133],\n",
      "        [13.4134],\n",
      "        [13.4135],\n",
      "        [13.4136],\n",
      "        [13.4136],\n",
      "        [13.4136],\n",
      "        [13.4136],\n",
      "        [13.4136]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[13.5523],\n",
      "        [13.5523],\n",
      "        [13.5523],\n",
      "        [13.5523],\n",
      "        [13.5522],\n",
      "        [13.5522],\n",
      "        [13.5522],\n",
      "        [13.5523],\n",
      "        [13.5522],\n",
      "        [13.5522],\n",
      "        [13.5522],\n",
      "        [13.5522],\n",
      "        [13.5522],\n",
      "        [13.5522],\n",
      "        [13.5521],\n",
      "        [13.5522],\n",
      "        [13.5521],\n",
      "        [13.5522],\n",
      "        [13.5522],\n",
      "        [13.5523],\n",
      "        [13.5523],\n",
      "        [13.5522],\n",
      "        [13.5523],\n",
      "        [13.5523]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[13.6932],\n",
      "        [13.6932],\n",
      "        [13.6932],\n",
      "        [13.6932],\n",
      "        [13.6931],\n",
      "        [13.6931],\n",
      "        [13.6931],\n",
      "        [13.6931],\n",
      "        [13.6931],\n",
      "        [13.6931],\n",
      "        [13.6931],\n",
      "        [13.6931],\n",
      "        [13.6931],\n",
      "        [13.6931],\n",
      "        [13.6930],\n",
      "        [13.6930],\n",
      "        [13.6931],\n",
      "        [13.6931],\n",
      "        [13.6932],\n",
      "        [13.6933],\n",
      "        [13.6933],\n",
      "        [13.6933],\n",
      "        [13.6933],\n",
      "        [13.6934]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[13.8345],\n",
      "        [13.8344],\n",
      "        [13.8344],\n",
      "        [13.8344],\n",
      "        [13.8344],\n",
      "        [13.8344],\n",
      "        [13.8344],\n",
      "        [13.8344],\n",
      "        [13.8344],\n",
      "        [13.8344],\n",
      "        [13.8343],\n",
      "        [13.8343],\n",
      "        [13.8343],\n",
      "        [13.8343],\n",
      "        [13.8343],\n",
      "        [13.8343],\n",
      "        [13.8343],\n",
      "        [13.8344],\n",
      "        [13.8344],\n",
      "        [13.8345],\n",
      "        [13.8345],\n",
      "        [13.8345],\n",
      "        [13.8345],\n",
      "        [13.8344]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[13.9763],\n",
      "        [13.9764],\n",
      "        [13.9763],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9761],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9762],\n",
      "        [13.9763],\n",
      "        [13.9763],\n",
      "        [13.9763],\n",
      "        [13.9764],\n",
      "        [13.9764],\n",
      "        [13.9764]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[14.1199],\n",
      "        [14.1199],\n",
      "        [14.1198],\n",
      "        [14.1198],\n",
      "        [14.1197],\n",
      "        [14.1197],\n",
      "        [14.1197],\n",
      "        [14.1197],\n",
      "        [14.1196],\n",
      "        [14.1196],\n",
      "        [14.1196],\n",
      "        [14.1196],\n",
      "        [14.1196],\n",
      "        [14.1195],\n",
      "        [14.1195],\n",
      "        [14.1195],\n",
      "        [14.1196],\n",
      "        [14.1197],\n",
      "        [14.1198],\n",
      "        [14.1199],\n",
      "        [14.1198],\n",
      "        [14.1199],\n",
      "        [14.1199],\n",
      "        [14.1199]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[14.2654],\n",
      "        [14.2654],\n",
      "        [14.2653],\n",
      "        [14.2653],\n",
      "        [14.2653],\n",
      "        [14.2652],\n",
      "        [14.2652],\n",
      "        [14.2652],\n",
      "        [14.2652],\n",
      "        [14.2652],\n",
      "        [14.2651],\n",
      "        [14.2651],\n",
      "        [14.2651],\n",
      "        [14.2650],\n",
      "        [14.2650],\n",
      "        [14.2651],\n",
      "        [14.2651],\n",
      "        [14.2652],\n",
      "        [14.2653],\n",
      "        [14.2654],\n",
      "        [14.2654],\n",
      "        [14.2654],\n",
      "        [14.2654],\n",
      "        [14.2654]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[14.4125],\n",
      "        [14.4125],\n",
      "        [14.4125],\n",
      "        [14.4125],\n",
      "        [14.4124],\n",
      "        [14.4124],\n",
      "        [14.4124],\n",
      "        [14.4123],\n",
      "        [14.4123],\n",
      "        [14.4124],\n",
      "        [14.4123],\n",
      "        [14.4123],\n",
      "        [14.4123],\n",
      "        [14.4123],\n",
      "        [14.4124],\n",
      "        [14.4124],\n",
      "        [14.4124],\n",
      "        [14.4124],\n",
      "        [14.4125],\n",
      "        [14.4125],\n",
      "        [14.4125],\n",
      "        [14.4125],\n",
      "        [14.4125],\n",
      "        [14.4125]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[14.5609],\n",
      "        [14.5609],\n",
      "        [14.5609],\n",
      "        [14.5609],\n",
      "        [14.5609],\n",
      "        [14.5608],\n",
      "        [14.5608],\n",
      "        [14.5608],\n",
      "        [14.5608],\n",
      "        [14.5608],\n",
      "        [14.5608],\n",
      "        [14.5607],\n",
      "        [14.5607],\n",
      "        [14.5607],\n",
      "        [14.5607],\n",
      "        [14.5608],\n",
      "        [14.5608],\n",
      "        [14.5609],\n",
      "        [14.5609],\n",
      "        [14.5609],\n",
      "        [14.5610],\n",
      "        [14.5610],\n",
      "        [14.5610],\n",
      "        [14.5610]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[14.7099],\n",
      "        [14.7099],\n",
      "        [14.7099],\n",
      "        [14.7099],\n",
      "        [14.7098],\n",
      "        [14.7098],\n",
      "        [14.7098],\n",
      "        [14.7098],\n",
      "        [14.7098],\n",
      "        [14.7098],\n",
      "        [14.7097],\n",
      "        [14.7098],\n",
      "        [14.7097],\n",
      "        [14.7097],\n",
      "        [14.7097],\n",
      "        [14.7097],\n",
      "        [14.7098],\n",
      "        [14.7098],\n",
      "        [14.7099],\n",
      "        [14.7099],\n",
      "        [14.7099],\n",
      "        [14.7099],\n",
      "        [14.7099],\n",
      "        [14.7099]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[14.8576],\n",
      "        [14.8576],\n",
      "        [14.8576],\n",
      "        [14.8576],\n",
      "        [14.8576],\n",
      "        [14.8575],\n",
      "        [14.8575],\n",
      "        [14.8574],\n",
      "        [14.8574],\n",
      "        [14.8574],\n",
      "        [14.8574],\n",
      "        [14.8574],\n",
      "        [14.8574],\n",
      "        [14.8574],\n",
      "        [14.8574],\n",
      "        [14.8574],\n",
      "        [14.8574],\n",
      "        [14.8575],\n",
      "        [14.8575],\n",
      "        [14.8575],\n",
      "        [14.8576],\n",
      "        [14.8576],\n",
      "        [14.8576],\n",
      "        [14.8576]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[15.0057],\n",
      "        [15.0057],\n",
      "        [15.0056],\n",
      "        [15.0056],\n",
      "        [15.0056],\n",
      "        [15.0055],\n",
      "        [15.0055],\n",
      "        [15.0055],\n",
      "        [15.0054],\n",
      "        [15.0054],\n",
      "        [15.0055],\n",
      "        [15.0055],\n",
      "        [15.0055],\n",
      "        [15.0055],\n",
      "        [15.0055],\n",
      "        [15.0055],\n",
      "        [15.0056],\n",
      "        [15.0056],\n",
      "        [15.0056],\n",
      "        [15.0057],\n",
      "        [15.0057],\n",
      "        [15.0056],\n",
      "        [15.0057],\n",
      "        [15.0057]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[15.1552],\n",
      "        [15.1552],\n",
      "        [15.1551],\n",
      "        [15.1551],\n",
      "        [15.1551],\n",
      "        [15.1550],\n",
      "        [15.1550],\n",
      "        [15.1550],\n",
      "        [15.1550],\n",
      "        [15.1550],\n",
      "        [15.1550],\n",
      "        [15.1549],\n",
      "        [15.1548],\n",
      "        [15.1549],\n",
      "        [15.1549],\n",
      "        [15.1550],\n",
      "        [15.1550],\n",
      "        [15.1550],\n",
      "        [15.1551],\n",
      "        [15.1551],\n",
      "        [15.1552],\n",
      "        [15.1552],\n",
      "        [15.1552],\n",
      "        [15.1552]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[15.3056],\n",
      "        [15.3056],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3055],\n",
      "        [15.3056],\n",
      "        [15.3056],\n",
      "        [15.3056],\n",
      "        [15.3056],\n",
      "        [15.3056],\n",
      "        [15.3056],\n",
      "        [15.3056],\n",
      "        [15.3057]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[15.4564],\n",
      "        [15.4564],\n",
      "        [15.4564],\n",
      "        [15.4563],\n",
      "        [15.4563],\n",
      "        [15.4563],\n",
      "        [15.4563],\n",
      "        [15.4563],\n",
      "        [15.4562],\n",
      "        [15.4562],\n",
      "        [15.4562],\n",
      "        [15.4562],\n",
      "        [15.4562],\n",
      "        [15.4562],\n",
      "        [15.4562],\n",
      "        [15.4562],\n",
      "        [15.4562],\n",
      "        [15.4563],\n",
      "        [15.4564],\n",
      "        [15.4564],\n",
      "        [15.4564],\n",
      "        [15.4564],\n",
      "        [15.4564],\n",
      "        [15.4564]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[15.6077],\n",
      "        [15.6077],\n",
      "        [15.6077],\n",
      "        [15.6076],\n",
      "        [15.6077],\n",
      "        [15.6077],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6076],\n",
      "        [15.6077],\n",
      "        [15.6077],\n",
      "        [15.6077],\n",
      "        [15.6077],\n",
      "        [15.6077],\n",
      "        [15.6077]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[15.7594],\n",
      "        [15.7594],\n",
      "        [15.7594],\n",
      "        [15.7594],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7593],\n",
      "        [15.7594],\n",
      "        [15.7594],\n",
      "        [15.7594],\n",
      "        [15.7594],\n",
      "        [15.7594]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[15.9099],\n",
      "        [15.9099],\n",
      "        [15.9099],\n",
      "        [15.9099],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9098],\n",
      "        [15.9099],\n",
      "        [15.9099],\n",
      "        [15.9099],\n",
      "        [15.9099],\n",
      "        [15.9099],\n",
      "        [15.9099]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[16.0602],\n",
      "        [16.0602],\n",
      "        [16.0602],\n",
      "        [16.0602],\n",
      "        [16.0602],\n",
      "        [16.0602],\n",
      "        [16.0602],\n",
      "        [16.0602],\n",
      "        [16.0602],\n",
      "        [16.0602],\n",
      "        [16.0601],\n",
      "        [16.0601],\n",
      "        [16.0601],\n",
      "        [16.0601],\n",
      "        [16.0601],\n",
      "        [16.0600],\n",
      "        [16.0601],\n",
      "        [16.0601],\n",
      "        [16.0601],\n",
      "        [16.0601],\n",
      "        [16.0602],\n",
      "        [16.0602],\n",
      "        [16.0602],\n",
      "        [16.0602]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[16.2108],\n",
      "        [16.2108],\n",
      "        [16.2108],\n",
      "        [16.2108],\n",
      "        [16.2108],\n",
      "        [16.2108],\n",
      "        [16.2108],\n",
      "        [16.2108],\n",
      "        [16.2108],\n",
      "        [16.2108],\n",
      "        [16.2107],\n",
      "        [16.2108],\n",
      "        [16.2107],\n",
      "        [16.2107],\n",
      "        [16.2107],\n",
      "        [16.2107],\n",
      "        [16.2107],\n",
      "        [16.2107],\n",
      "        [16.2108],\n",
      "        [16.2108],\n",
      "        [16.2109],\n",
      "        [16.2109],\n",
      "        [16.2109],\n",
      "        [16.2109]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[16.3621],\n",
      "        [16.3620],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3619],\n",
      "        [16.3620],\n",
      "        [16.3620],\n",
      "        [16.3620],\n",
      "        [16.3620],\n",
      "        [16.3620],\n",
      "        [16.3620],\n",
      "        [16.3620],\n",
      "        [16.3620],\n",
      "        [16.3620]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[16.5136],\n",
      "        [16.5135],\n",
      "        [16.5135],\n",
      "        [16.5135],\n",
      "        [16.5135],\n",
      "        [16.5135],\n",
      "        [16.5135],\n",
      "        [16.5135],\n",
      "        [16.5134],\n",
      "        [16.5134],\n",
      "        [16.5134],\n",
      "        [16.5134],\n",
      "        [16.5134],\n",
      "        [16.5134],\n",
      "        [16.5134],\n",
      "        [16.5135],\n",
      "        [16.5135],\n",
      "        [16.5135],\n",
      "        [16.5136],\n",
      "        [16.5136],\n",
      "        [16.5136],\n",
      "        [16.5136],\n",
      "        [16.5136],\n",
      "        [16.5136]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[16.6649],\n",
      "        [16.6649],\n",
      "        [16.6649],\n",
      "        [16.6649],\n",
      "        [16.6648],\n",
      "        [16.6648],\n",
      "        [16.6648],\n",
      "        [16.6648],\n",
      "        [16.6648],\n",
      "        [16.6648],\n",
      "        [16.6648],\n",
      "        [16.6648],\n",
      "        [16.6648],\n",
      "        [16.6648],\n",
      "        [16.6648],\n",
      "        [16.6649],\n",
      "        [16.6649],\n",
      "        [16.6649],\n",
      "        [16.6649],\n",
      "        [16.6649],\n",
      "        [16.6649],\n",
      "        [16.6649],\n",
      "        [16.6649],\n",
      "        [16.6649]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[16.8160],\n",
      "        [16.8160],\n",
      "        [16.8159],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8159],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160],\n",
      "        [16.8160]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[16.9659],\n",
      "        [16.9659],\n",
      "        [16.9659],\n",
      "        [16.9659],\n",
      "        [16.9659],\n",
      "        [16.9658],\n",
      "        [16.9658],\n",
      "        [16.9658],\n",
      "        [16.9658],\n",
      "        [16.9658],\n",
      "        [16.9658],\n",
      "        [16.9658],\n",
      "        [16.9658],\n",
      "        [16.9658],\n",
      "        [16.9658],\n",
      "        [16.9659],\n",
      "        [16.9659],\n",
      "        [16.9659],\n",
      "        [16.9659],\n",
      "        [16.9659],\n",
      "        [16.9659],\n",
      "        [16.9659],\n",
      "        [16.9659],\n",
      "        [16.9659]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[17.1159],\n",
      "        [17.1159],\n",
      "        [17.1158],\n",
      "        [17.1158],\n",
      "        [17.1159],\n",
      "        [17.1158],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1158],\n",
      "        [17.1158],\n",
      "        [17.1158],\n",
      "        [17.1158],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1159],\n",
      "        [17.1159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[17.2664],\n",
      "        [17.2664],\n",
      "        [17.2664],\n",
      "        [17.2664],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2664],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663],\n",
      "        [17.2663]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[17.4165],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4164],\n",
      "        [17.4165],\n",
      "        [17.4165],\n",
      "        [17.4165],\n",
      "        [17.4165],\n",
      "        [17.4165],\n",
      "        [17.4165],\n",
      "        [17.4165],\n",
      "        [17.4165],\n",
      "        [17.4165]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663],\n",
      "        [17.5663]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[17.7163],\n",
      "        [17.7163],\n",
      "        [17.7162],\n",
      "        [17.7162],\n",
      "        [17.7162],\n",
      "        [17.7162],\n",
      "        [17.7162],\n",
      "        [17.7162],\n",
      "        [17.7162],\n",
      "        [17.7162],\n",
      "        [17.7162],\n",
      "        [17.7162],\n",
      "        [17.7162],\n",
      "        [17.7163],\n",
      "        [17.7162],\n",
      "        [17.7163],\n",
      "        [17.7163],\n",
      "        [17.7163],\n",
      "        [17.7163],\n",
      "        [17.7164],\n",
      "        [17.7164],\n",
      "        [17.7164],\n",
      "        [17.7163],\n",
      "        [17.7163]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[17.8665],\n",
      "        [17.8665],\n",
      "        [17.8665],\n",
      "        [17.8665],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8664],\n",
      "        [17.8665],\n",
      "        [17.8665],\n",
      "        [17.8665],\n",
      "        [17.8665],\n",
      "        [17.8665],\n",
      "        [17.8665]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0159],\n",
      "        [18.0160],\n",
      "        [18.0160],\n",
      "        [18.0160],\n",
      "        [18.0160],\n",
      "        [18.0160],\n",
      "        [18.0160],\n",
      "        [18.0159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653],\n",
      "        [18.1653]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3152],\n",
      "        [18.3152],\n",
      "        [18.3152],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151],\n",
      "        [18.3151]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4652],\n",
      "        [18.4653],\n",
      "        [18.4653],\n",
      "        [18.4653],\n",
      "        [18.4653],\n",
      "        [18.4653],\n",
      "        [18.4653],\n",
      "        [18.4652]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[18.6157],\n",
      "        [18.6157],\n",
      "        [18.6157],\n",
      "        [18.6157],\n",
      "        [18.6156],\n",
      "        [18.6157],\n",
      "        [18.6156],\n",
      "        [18.6156],\n",
      "        [18.6156],\n",
      "        [18.6156],\n",
      "        [18.6157],\n",
      "        [18.6157],\n",
      "        [18.6156],\n",
      "        [18.6156],\n",
      "        [18.6156],\n",
      "        [18.6156],\n",
      "        [18.6157],\n",
      "        [18.6156],\n",
      "        [18.6157],\n",
      "        [18.6157],\n",
      "        [18.6157],\n",
      "        [18.6157],\n",
      "        [18.6156],\n",
      "        [18.6157]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7667],\n",
      "        [18.7668],\n",
      "        [18.7668],\n",
      "        [18.7668],\n",
      "        [18.7667],\n",
      "        [18.7667]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[18.9178],\n",
      "        [18.9179],\n",
      "        [18.9179],\n",
      "        [18.9179],\n",
      "        [18.9178],\n",
      "        [18.9178],\n",
      "        [18.9178],\n",
      "        [18.9178],\n",
      "        [18.9178],\n",
      "        [18.9178],\n",
      "        [18.9178],\n",
      "        [18.9178],\n",
      "        [18.9178],\n",
      "        [18.9178],\n",
      "        [18.9178],\n",
      "        [18.9179],\n",
      "        [18.9179],\n",
      "        [18.9179],\n",
      "        [18.9179],\n",
      "        [18.9179],\n",
      "        [18.9179],\n",
      "        [18.9179],\n",
      "        [18.9179],\n",
      "        [18.9179]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0674],\n",
      "        [19.0674],\n",
      "        [19.0674],\n",
      "        [19.0674],\n",
      "        [19.0674],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675],\n",
      "        [19.0675]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2168],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2167],\n",
      "        [19.2168],\n",
      "        [19.2168],\n",
      "        [19.2168],\n",
      "        [19.2168],\n",
      "        [19.2168],\n",
      "        [19.2168]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3657],\n",
      "        [19.3658],\n",
      "        [19.3658],\n",
      "        [19.3658],\n",
      "        [19.3658],\n",
      "        [19.3658],\n",
      "        [19.3658],\n",
      "        [19.3658],\n",
      "        [19.3658]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5143],\n",
      "        [19.5144],\n",
      "        [19.5144],\n",
      "        [19.5144],\n",
      "        [19.5144],\n",
      "        [19.5144],\n",
      "        [19.5143]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6629],\n",
      "        [19.6629],\n",
      "        [19.6629],\n",
      "        [19.6629],\n",
      "        [19.6629],\n",
      "        [19.6629],\n",
      "        [19.6629],\n",
      "        [19.6629],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630],\n",
      "        [19.6630]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8123],\n",
      "        [19.8122],\n",
      "        [19.8122],\n",
      "        [19.8123],\n",
      "        [19.8122],\n",
      "        [19.8122]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[19.9612],\n",
      "        [19.9612],\n",
      "        [19.9611],\n",
      "        [19.9611],\n",
      "        [19.9611],\n",
      "        [19.9611],\n",
      "        [19.9612],\n",
      "        [19.9612],\n",
      "        [19.9611],\n",
      "        [19.9612],\n",
      "        [19.9611],\n",
      "        [19.9612],\n",
      "        [19.9611],\n",
      "        [19.9611],\n",
      "        [19.9612],\n",
      "        [19.9612],\n",
      "        [19.9612],\n",
      "        [19.9612],\n",
      "        [19.9612],\n",
      "        [19.9612],\n",
      "        [19.9612],\n",
      "        [19.9612],\n",
      "        [19.9612],\n",
      "        [19.9612]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1094],\n",
      "        [20.1095],\n",
      "        [20.1094],\n",
      "        [20.1094],\n",
      "        [20.1094],\n",
      "        [20.1094],\n",
      "        [20.1095],\n",
      "        [20.1094],\n",
      "        [20.1094],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095],\n",
      "        [20.1095]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2572],\n",
      "        [20.2572],\n",
      "        [20.2572],\n",
      "        [20.2572],\n",
      "        [20.2572],\n",
      "        [20.2572],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573],\n",
      "        [20.2573]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4054],\n",
      "        [20.4055],\n",
      "        [20.4055],\n",
      "        [20.4055],\n",
      "        [20.4055],\n",
      "        [20.4054],\n",
      "        [20.4054]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5537],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5536],\n",
      "        [20.5537],\n",
      "        [20.5537],\n",
      "        [20.5537],\n",
      "        [20.5537],\n",
      "        [20.5537],\n",
      "        [20.5537],\n",
      "        [20.5537]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020],\n",
      "        [20.7020]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8509],\n",
      "        [20.8510],\n",
      "        [20.8510],\n",
      "        [20.8510],\n",
      "        [20.8510],\n",
      "        [20.8510],\n",
      "        [20.8510],\n",
      "        [20.8510]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996],\n",
      "        [20.9996]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475],\n",
      "        [21.1475]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2948],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2948],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949],\n",
      "        [21.2949]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[21.4422],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4421],\n",
      "        [21.4422],\n",
      "        [21.4422],\n",
      "        [21.4422],\n",
      "        [21.4422],\n",
      "        [21.4422],\n",
      "        [21.4422],\n",
      "        [21.4422]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[21.5896],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5895],\n",
      "        [21.5895],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5895],\n",
      "        [21.5895],\n",
      "        [21.5895],\n",
      "        [21.5895],\n",
      "        [21.5895],\n",
      "        [21.5895],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5896],\n",
      "        [21.5896]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7373],\n",
      "        [21.7374],\n",
      "        [21.7374],\n",
      "        [21.7374],\n",
      "        [21.7374],\n",
      "        [21.7374],\n",
      "        [21.7374],\n",
      "        [21.7374]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[21.8865],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8864],\n",
      "        [21.8865],\n",
      "        [21.8865],\n",
      "        [21.8865],\n",
      "        [21.8865],\n",
      "        [21.8865],\n",
      "        [21.8865],\n",
      "        [21.8865],\n",
      "        [21.8865]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0361],\n",
      "        [22.0361],\n",
      "        [22.0361],\n",
      "        [22.0361],\n",
      "        [22.0361],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362],\n",
      "        [22.0362]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[22.1864],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1863],\n",
      "        [22.1864],\n",
      "        [22.1864],\n",
      "        [22.1864],\n",
      "        [22.1864],\n",
      "        [22.1864],\n",
      "        [22.1864],\n",
      "        [22.1864]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3374],\n",
      "        [22.3375],\n",
      "        [22.3375],\n",
      "        [22.3375],\n",
      "        [22.3375],\n",
      "        [22.3375],\n",
      "        [22.3375],\n",
      "        [22.3374]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4903],\n",
      "        [22.4903],\n",
      "        [22.4903],\n",
      "        [22.4903],\n",
      "        [22.4903],\n",
      "        [22.4903],\n",
      "        [22.4903],\n",
      "        [22.4903],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904],\n",
      "        [22.4904]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6447],\n",
      "        [22.6448],\n",
      "        [22.6448],\n",
      "        [22.6448],\n",
      "        [22.6448],\n",
      "        [22.6448],\n",
      "        [22.6448],\n",
      "        [22.6448],\n",
      "        [22.6448],\n",
      "        [22.6448]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[22.8010],\n",
      "        [22.8011],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8010],\n",
      "        [22.8011],\n",
      "        [22.8011],\n",
      "        [22.8011],\n",
      "        [22.8011],\n",
      "        [22.8011],\n",
      "        [22.8011],\n",
      "        [22.8011],\n",
      "        [22.8011]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[22.9584],\n",
      "        [22.9584],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9583],\n",
      "        [22.9584],\n",
      "        [22.9584],\n",
      "        [22.9584],\n",
      "        [22.9584],\n",
      "        [22.9584],\n",
      "        [22.9584],\n",
      "        [22.9584],\n",
      "        [22.9584],\n",
      "        [22.9584]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[23.1162],\n",
      "        [23.1162],\n",
      "        [23.1162],\n",
      "        [23.1161],\n",
      "        [23.1161],\n",
      "        [23.1162],\n",
      "        [23.1161],\n",
      "        [23.1161],\n",
      "        [23.1161],\n",
      "        [23.1161],\n",
      "        [23.1161],\n",
      "        [23.1161],\n",
      "        [23.1161],\n",
      "        [23.1161],\n",
      "        [23.1162],\n",
      "        [23.1162],\n",
      "        [23.1162],\n",
      "        [23.1162],\n",
      "        [23.1162],\n",
      "        [23.1162],\n",
      "        [23.1162],\n",
      "        [23.1162],\n",
      "        [23.1162],\n",
      "        [23.1162]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2733],\n",
      "        [23.2734],\n",
      "        [23.2734],\n",
      "        [23.2734],\n",
      "        [23.2734],\n",
      "        [23.2734],\n",
      "        [23.2734],\n",
      "        [23.2734],\n",
      "        [23.2734],\n",
      "        [23.2734]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4311],\n",
      "        [23.4312],\n",
      "        [23.4312],\n",
      "        [23.4312],\n",
      "        [23.4312],\n",
      "        [23.4312],\n",
      "        [23.4312],\n",
      "        [23.4312],\n",
      "        [23.4312],\n",
      "        [23.4312]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5903],\n",
      "        [23.5904],\n",
      "        [23.5903],\n",
      "        [23.5903],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5903],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904],\n",
      "        [23.5904]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[23.7502],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7501],\n",
      "        [23.7502],\n",
      "        [23.7502],\n",
      "        [23.7502],\n",
      "        [23.7502],\n",
      "        [23.7502],\n",
      "        [23.7502],\n",
      "        [23.7502],\n",
      "        [23.7502],\n",
      "        [23.7502]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104],\n",
      "        [23.9104]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0702],\n",
      "        [24.0703],\n",
      "        [24.0703],\n",
      "        [24.0703],\n",
      "        [24.0703],\n",
      "        [24.0703],\n",
      "        [24.0703],\n",
      "        [24.0703],\n",
      "        [24.0703]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2297],\n",
      "        [24.2298],\n",
      "        [24.2298],\n",
      "        [24.2298],\n",
      "        [24.2298],\n",
      "        [24.2298],\n",
      "        [24.2298],\n",
      "        [24.2298],\n",
      "        [24.2297]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3879],\n",
      "        [24.3879],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880],\n",
      "        [24.3880]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[24.5458],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5457],\n",
      "        [24.5458],\n",
      "        [24.5458],\n",
      "        [24.5458],\n",
      "        [24.5458],\n",
      "        [24.5458],\n",
      "        [24.5458],\n",
      "        [24.5458],\n",
      "        [24.5458],\n",
      "        [24.5458],\n",
      "        [24.5458]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042],\n",
      "        [24.7042]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625],\n",
      "        [24.8625]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204],\n",
      "        [25.0204]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1780],\n",
      "        [25.1780],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779],\n",
      "        [25.1779]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3339],\n",
      "        [25.3339],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340],\n",
      "        [25.3340]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4885],\n",
      "        [25.4885],\n",
      "        [25.4885],\n",
      "        [25.4885],\n",
      "        [25.4885],\n",
      "        [25.4885],\n",
      "        [25.4885],\n",
      "        [25.4885],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886],\n",
      "        [25.4886]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[25.6426],\n",
      "        [25.6426],\n",
      "        [25.6426],\n",
      "        [25.6425],\n",
      "        [25.6425],\n",
      "        [25.6426],\n",
      "        [25.6426],\n",
      "        [25.6425],\n",
      "        [25.6425],\n",
      "        [25.6425],\n",
      "        [25.6425],\n",
      "        [25.6425],\n",
      "        [25.6425],\n",
      "        [25.6425],\n",
      "        [25.6426],\n",
      "        [25.6426],\n",
      "        [25.6426],\n",
      "        [25.6426],\n",
      "        [25.6426],\n",
      "        [25.6426],\n",
      "        [25.6426],\n",
      "        [25.6426],\n",
      "        [25.6426],\n",
      "        [25.6426]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[25.7965],\n",
      "        [25.7964],\n",
      "        [25.7964],\n",
      "        [25.7965],\n",
      "        [25.7965],\n",
      "        [25.7965],\n",
      "        [25.7964],\n",
      "        [25.7964],\n",
      "        [25.7964],\n",
      "        [25.7964],\n",
      "        [25.7964],\n",
      "        [25.7964],\n",
      "        [25.7964],\n",
      "        [25.7964],\n",
      "        [25.7965],\n",
      "        [25.7965],\n",
      "        [25.7965],\n",
      "        [25.7965],\n",
      "        [25.7965],\n",
      "        [25.7965],\n",
      "        [25.7965],\n",
      "        [25.7965],\n",
      "        [25.7965],\n",
      "        [25.7965]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9495],\n",
      "        [25.9496],\n",
      "        [25.9496],\n",
      "        [25.9496],\n",
      "        [25.9496],\n",
      "        [25.9496],\n",
      "        [25.9496],\n",
      "        [25.9495]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009],\n",
      "        [26.1009]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2508],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509],\n",
      "        [26.2509]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[26.3999],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3998],\n",
      "        [26.3999],\n",
      "        [26.3999],\n",
      "        [26.3999],\n",
      "        [26.3999],\n",
      "        [26.3999],\n",
      "        [26.3999],\n",
      "        [26.3999],\n",
      "        [26.3999],\n",
      "        [26.3999]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5474],\n",
      "        [26.5474],\n",
      "        [26.5474],\n",
      "        [26.5474],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475],\n",
      "        [26.5475]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[26.6950],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6949],\n",
      "        [26.6950],\n",
      "        [26.6950],\n",
      "        [26.6950],\n",
      "        [26.6950],\n",
      "        [26.6950],\n",
      "        [26.6950],\n",
      "        [26.6950],\n",
      "        [26.6950]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8422],\n",
      "        [26.8423],\n",
      "        [26.8423],\n",
      "        [26.8423],\n",
      "        [26.8423],\n",
      "        [26.8423],\n",
      "        [26.8423],\n",
      "        [26.8423],\n",
      "        [26.8422]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9888],\n",
      "        [26.9888],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889],\n",
      "        [26.9889]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1348],\n",
      "        [27.1348],\n",
      "        [27.1348],\n",
      "        [27.1348],\n",
      "        [27.1348],\n",
      "        [27.1348],\n",
      "        [27.1348],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349],\n",
      "        [27.1349]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2807],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806],\n",
      "        [27.2806]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265],\n",
      "        [27.4265]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5716],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5718],\n",
      "        [27.5718],\n",
      "        [27.5718],\n",
      "        [27.5717],\n",
      "        [27.5717],\n",
      "        [27.5717]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169],\n",
      "        [27.7169]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8628],\n",
      "        [27.8629],\n",
      "        [27.8629],\n",
      "        [27.8629],\n",
      "        [27.8629],\n",
      "        [27.8629],\n",
      "        [27.8629],\n",
      "        [27.8629],\n",
      "        [27.8628]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093],\n",
      "        [28.0093]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1566],\n",
      "        [28.1566],\n",
      "        [28.1567],\n",
      "        [28.1566],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567],\n",
      "        [28.1567]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[28.3049],\n",
      "        [28.3049],\n",
      "        [28.3049],\n",
      "        [28.3049],\n",
      "        [28.3048],\n",
      "        [28.3048],\n",
      "        [28.3048],\n",
      "        [28.3048],\n",
      "        [28.3048],\n",
      "        [28.3048],\n",
      "        [28.3048],\n",
      "        [28.3048],\n",
      "        [28.3048],\n",
      "        [28.3048],\n",
      "        [28.3048],\n",
      "        [28.3049],\n",
      "        [28.3049],\n",
      "        [28.3049],\n",
      "        [28.3049],\n",
      "        [28.3049],\n",
      "        [28.3049],\n",
      "        [28.3049],\n",
      "        [28.3049],\n",
      "        [28.3049]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535],\n",
      "        [28.4535]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6007],\n",
      "        [28.6008],\n",
      "        [28.6008],\n",
      "        [28.6008],\n",
      "        [28.6008],\n",
      "        [28.6007],\n",
      "        [28.6007]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[28.7460],\n",
      "        [28.7459],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7459],\n",
      "        [28.7459],\n",
      "        [28.7459],\n",
      "        [28.7459],\n",
      "        [28.7459],\n",
      "        [28.7459],\n",
      "        [28.7459],\n",
      "        [28.7459],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7460],\n",
      "        [28.7460]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8883],\n",
      "        [28.8884],\n",
      "        [28.8884],\n",
      "        [28.8883],\n",
      "        [28.8884],\n",
      "        [28.8883]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303],\n",
      "        [29.0303]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720],\n",
      "        [29.1720]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137],\n",
      "        [29.3137]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551],\n",
      "        [29.4551]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[29.5960],\n",
      "        [29.5960],\n",
      "        [29.5960],\n",
      "        [29.5960],\n",
      "        [29.5960],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5960],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961],\n",
      "        [29.5961]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370],\n",
      "        [29.7370]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778],\n",
      "        [29.8778]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0194],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0194],\n",
      "        [30.0194],\n",
      "        [30.0194],\n",
      "        [30.0194],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195],\n",
      "        [30.0195]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1605],\n",
      "        [30.1606],\n",
      "        [30.1606],\n",
      "        [30.1606],\n",
      "        [30.1606],\n",
      "        [30.1606],\n",
      "        [30.1605],\n",
      "        [30.1606],\n",
      "        [30.1605]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[30.3012],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3011],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3011],\n",
      "        [30.3011],\n",
      "        [30.3011],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3011],\n",
      "        [30.3011],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3012],\n",
      "        [30.3012]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4403],\n",
      "        [30.4404],\n",
      "        [30.4404],\n",
      "        [30.4404],\n",
      "        [30.4404],\n",
      "        [30.4404],\n",
      "        [30.4404],\n",
      "        [30.4404],\n",
      "        [30.4404],\n",
      "        [30.4404]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[30.5766],\n",
      "        [30.5766],\n",
      "        [30.5766],\n",
      "        [30.5766],\n",
      "        [30.5765],\n",
      "        [30.5766],\n",
      "        [30.5765],\n",
      "        [30.5765],\n",
      "        [30.5765],\n",
      "        [30.5765],\n",
      "        [30.5765],\n",
      "        [30.5765],\n",
      "        [30.5765],\n",
      "        [30.5765],\n",
      "        [30.5766],\n",
      "        [30.5766],\n",
      "        [30.5766],\n",
      "        [30.5766],\n",
      "        [30.5766],\n",
      "        [30.5766],\n",
      "        [30.5766],\n",
      "        [30.5766],\n",
      "        [30.5766],\n",
      "        [30.5766]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7109],\n",
      "        [30.7110],\n",
      "        [30.7110],\n",
      "        [30.7110],\n",
      "        [30.7110],\n",
      "        [30.7110],\n",
      "        [30.7110],\n",
      "        [30.7110],\n",
      "        [30.7110],\n",
      "        [30.7110]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[30.8444],\n",
      "        [30.8444],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443],\n",
      "        [30.8443]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[30.9762],\n",
      "        [30.9762],\n",
      "        [30.9762],\n",
      "        [30.9762],\n",
      "        [30.9762],\n",
      "        [30.9762],\n",
      "        [30.9762],\n",
      "        [30.9761],\n",
      "        [30.9761],\n",
      "        [30.9761],\n",
      "        [30.9761],\n",
      "        [30.9761],\n",
      "        [30.9761],\n",
      "        [30.9762],\n",
      "        [30.9762],\n",
      "        [30.9763],\n",
      "        [30.9763],\n",
      "        [30.9763],\n",
      "        [30.9763],\n",
      "        [30.9763],\n",
      "        [30.9762],\n",
      "        [30.9763],\n",
      "        [30.9763],\n",
      "        [30.9762]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061],\n",
      "        [31.1061]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2327],\n",
      "        [31.2327],\n",
      "        [31.2327],\n",
      "        [31.2327],\n",
      "        [31.2327],\n",
      "        [31.2327],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328],\n",
      "        [31.2328]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3560],\n",
      "        [31.3560],\n",
      "        [31.3560],\n",
      "        [31.3560],\n",
      "        [31.3560],\n",
      "        [31.3560],\n",
      "        [31.3560],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561],\n",
      "        [31.3561]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[31.4746],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4745],\n",
      "        [31.4746],\n",
      "        [31.4745],\n",
      "        [31.4746],\n",
      "        [31.4745],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4746],\n",
      "        [31.4747],\n",
      "        [31.4747],\n",
      "        [31.4747],\n",
      "        [31.4746],\n",
      "        [31.4746]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[31.5917],\n",
      "        [31.5917],\n",
      "        [31.5917],\n",
      "        [31.5916],\n",
      "        [31.5916],\n",
      "        [31.5917],\n",
      "        [31.5916],\n",
      "        [31.5916],\n",
      "        [31.5916],\n",
      "        [31.5917],\n",
      "        [31.5916],\n",
      "        [31.5917],\n",
      "        [31.5916],\n",
      "        [31.5916],\n",
      "        [31.5916],\n",
      "        [31.5917],\n",
      "        [31.5917],\n",
      "        [31.5917],\n",
      "        [31.5917],\n",
      "        [31.5917],\n",
      "        [31.5917],\n",
      "        [31.5917],\n",
      "        [31.5917],\n",
      "        [31.5917]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7086],\n",
      "        [31.7086],\n",
      "        [31.7086],\n",
      "        [31.7086],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087],\n",
      "        [31.7087]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[31.8254],\n",
      "        [31.8254],\n",
      "        [31.8253],\n",
      "        [31.8254],\n",
      "        [31.8253],\n",
      "        [31.8254],\n",
      "        [31.8253],\n",
      "        [31.8254],\n",
      "        [31.8254],\n",
      "        [31.8253],\n",
      "        [31.8253],\n",
      "        [31.8253],\n",
      "        [31.8254],\n",
      "        [31.8253],\n",
      "        [31.8254],\n",
      "        [31.8254],\n",
      "        [31.8254],\n",
      "        [31.8254],\n",
      "        [31.8254],\n",
      "        [31.8254],\n",
      "        [31.8254],\n",
      "        [31.8254],\n",
      "        [31.8254],\n",
      "        [31.8254]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[31.9414],\n",
      "        [31.9415],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9415],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414],\n",
      "        [31.9414]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0578],\n",
      "        [32.0579],\n",
      "        [32.0579],\n",
      "        [32.0579],\n",
      "        [32.0579],\n",
      "        [32.0579],\n",
      "        [32.0579],\n",
      "        [32.0579],\n",
      "        [32.0578]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[32.1726],\n",
      "        [32.1726],\n",
      "        [32.1726],\n",
      "        [32.1726],\n",
      "        [32.1726],\n",
      "        [32.1726],\n",
      "        [32.1725],\n",
      "        [32.1725],\n",
      "        [32.1725],\n",
      "        [32.1725],\n",
      "        [32.1726],\n",
      "        [32.1725],\n",
      "        [32.1726],\n",
      "        [32.1726],\n",
      "        [32.1726],\n",
      "        [32.1726],\n",
      "        [32.1726],\n",
      "        [32.1727],\n",
      "        [32.1727],\n",
      "        [32.1727],\n",
      "        [32.1726],\n",
      "        [32.1727],\n",
      "        [32.1726],\n",
      "        [32.1726]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2843],\n",
      "        [32.2844],\n",
      "        [32.2844],\n",
      "        [32.2844],\n",
      "        [32.2844],\n",
      "        [32.2844],\n",
      "        [32.2844],\n",
      "        [32.2844],\n",
      "        [32.2844],\n",
      "        [32.2844],\n",
      "        [32.2844],\n",
      "        [32.2844]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959],\n",
      "        [32.3959]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5085],\n",
      "        [32.5085],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084],\n",
      "        [32.5084]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6224],\n",
      "        [32.6223],\n",
      "        [32.6223],\n",
      "        [32.6224],\n",
      "        [32.6223],\n",
      "        [32.6224],\n",
      "        [32.6223]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374],\n",
      "        [32.7374]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8509],\n",
      "        [32.8510],\n",
      "        [32.8510],\n",
      "        [32.8510],\n",
      "        [32.8510],\n",
      "        [32.8510],\n",
      "        [32.8510],\n",
      "        [32.8510],\n",
      "        [32.8509]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9613],\n",
      "        [32.9613],\n",
      "        [32.9613],\n",
      "        [32.9613],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614],\n",
      "        [32.9614]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[33.0717],\n",
      "        [33.0717],\n",
      "        [33.0717],\n",
      "        [33.0717],\n",
      "        [33.0717],\n",
      "        [33.0717],\n",
      "        [33.0717]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/10], Loss: 14425.7114\n",
      "outputs: tensor([[33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1854],\n",
      "        [33.1854],\n",
      "        [33.1854],\n",
      "        [33.1854],\n",
      "        [33.1854],\n",
      "        [33.1854],\n",
      "        [33.1854],\n",
      "        [33.1854],\n",
      "        [33.1854],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853],\n",
      "        [33.1853]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[33.3008],\n",
      "        [33.3008],\n",
      "        [33.3007],\n",
      "        [33.3007],\n",
      "        [33.3007],\n",
      "        [33.3007],\n",
      "        [33.3006],\n",
      "        [33.3006],\n",
      "        [33.3006],\n",
      "        [33.3008],\n",
      "        [33.3008],\n",
      "        [33.3008],\n",
      "        [33.3008],\n",
      "        [33.3008],\n",
      "        [33.3008],\n",
      "        [33.3008],\n",
      "        [33.3007],\n",
      "        [33.3007],\n",
      "        [33.3008],\n",
      "        [33.3008],\n",
      "        [33.3008],\n",
      "        [33.3008],\n",
      "        [33.3008],\n",
      "        [33.3008]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4205],\n",
      "        [33.4204],\n",
      "        [33.4205],\n",
      "        [33.4205],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204],\n",
      "        [33.4204]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[33.5423],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5424],\n",
      "        [33.5424],\n",
      "        [33.5424],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5424],\n",
      "        [33.5424],\n",
      "        [33.5424],\n",
      "        [33.5423],\n",
      "        [33.5424],\n",
      "        [33.5423],\n",
      "        [33.5423],\n",
      "        [33.5423]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6684],\n",
      "        [33.6684],\n",
      "        [33.6684],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683],\n",
      "        [33.6683]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7944],\n",
      "        [33.7944],\n",
      "        [33.7944],\n",
      "        [33.7944],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7943],\n",
      "        [33.7944],\n",
      "        [33.7944],\n",
      "        [33.7944]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[33.9203],\n",
      "        [33.9203],\n",
      "        [33.9204],\n",
      "        [33.9203],\n",
      "        [33.9203],\n",
      "        [33.9203],\n",
      "        [33.9203],\n",
      "        [33.9203],\n",
      "        [33.9203],\n",
      "        [33.9204],\n",
      "        [33.9204],\n",
      "        [33.9204],\n",
      "        [33.9204],\n",
      "        [33.9204],\n",
      "        [33.9204],\n",
      "        [33.9204],\n",
      "        [33.9204],\n",
      "        [33.9204],\n",
      "        [33.9204],\n",
      "        [33.9203],\n",
      "        [33.9203],\n",
      "        [33.9203],\n",
      "        [33.9203],\n",
      "        [33.9203]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0436],\n",
      "        [34.0436],\n",
      "        [34.0436],\n",
      "        [34.0436],\n",
      "        [34.0436],\n",
      "        [34.0436],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435],\n",
      "        [34.0435]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[34.1672],\n",
      "        [34.1672],\n",
      "        [34.1672],\n",
      "        [34.1672],\n",
      "        [34.1671],\n",
      "        [34.1671],\n",
      "        [34.1671],\n",
      "        [34.1672],\n",
      "        [34.1672],\n",
      "        [34.1673],\n",
      "        [34.1673],\n",
      "        [34.1673],\n",
      "        [34.1673],\n",
      "        [34.1672],\n",
      "        [34.1673],\n",
      "        [34.1673],\n",
      "        [34.1673],\n",
      "        [34.1672],\n",
      "        [34.1672],\n",
      "        [34.1672],\n",
      "        [34.1672],\n",
      "        [34.1672],\n",
      "        [34.1672],\n",
      "        [34.1672]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[34.2932],\n",
      "        [34.2932],\n",
      "        [34.2932],\n",
      "        [34.2931],\n",
      "        [34.2932],\n",
      "        [34.2931],\n",
      "        [34.2932],\n",
      "        [34.2932],\n",
      "        [34.2932],\n",
      "        [34.2932],\n",
      "        [34.2932],\n",
      "        [34.2933],\n",
      "        [34.2933],\n",
      "        [34.2933],\n",
      "        [34.2933],\n",
      "        [34.2933],\n",
      "        [34.2933],\n",
      "        [34.2932],\n",
      "        [34.2932],\n",
      "        [34.2932],\n",
      "        [34.2932],\n",
      "        [34.2932],\n",
      "        [34.2931],\n",
      "        [34.2931]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4216],\n",
      "        [34.4216],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4216],\n",
      "        [34.4217],\n",
      "        [34.4218],\n",
      "        [34.4218],\n",
      "        [34.4218],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217],\n",
      "        [34.4217]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[34.5511],\n",
      "        [34.5511],\n",
      "        [34.5511],\n",
      "        [34.5511],\n",
      "        [34.5511],\n",
      "        [34.5511],\n",
      "        [34.5511],\n",
      "        [34.5511],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512],\n",
      "        [34.5512]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[34.6823],\n",
      "        [34.6823],\n",
      "        [34.6824],\n",
      "        [34.6823],\n",
      "        [34.6823],\n",
      "        [34.6823],\n",
      "        [34.6823],\n",
      "        [34.6824],\n",
      "        [34.6824],\n",
      "        [34.6824],\n",
      "        [34.6825],\n",
      "        [34.6825],\n",
      "        [34.6825],\n",
      "        [34.6825],\n",
      "        [34.6825],\n",
      "        [34.6825],\n",
      "        [34.6824],\n",
      "        [34.6824],\n",
      "        [34.6824],\n",
      "        [34.6824],\n",
      "        [34.6823],\n",
      "        [34.6823],\n",
      "        [34.6823],\n",
      "        [34.6823]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[34.8153],\n",
      "        [34.8153],\n",
      "        [34.8153],\n",
      "        [34.8152],\n",
      "        [34.8153],\n",
      "        [34.8154],\n",
      "        [34.8154],\n",
      "        [34.8154],\n",
      "        [34.8154],\n",
      "        [34.8153],\n",
      "        [34.8155],\n",
      "        [34.8155],\n",
      "        [34.8155],\n",
      "        [34.8155],\n",
      "        [34.8155],\n",
      "        [34.8155],\n",
      "        [34.8155],\n",
      "        [34.8154],\n",
      "        [34.8154],\n",
      "        [34.8154],\n",
      "        [34.8154],\n",
      "        [34.8154],\n",
      "        [34.8154],\n",
      "        [34.8154]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9481],\n",
      "        [34.9480],\n",
      "        [34.9481],\n",
      "        [34.9481],\n",
      "        [34.9481],\n",
      "        [34.9481],\n",
      "        [34.9481],\n",
      "        [34.9481],\n",
      "        [34.9481],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480],\n",
      "        [34.9480]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0797],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0799],\n",
      "        [35.0799],\n",
      "        [35.0799],\n",
      "        [35.0799],\n",
      "        [35.0799],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798],\n",
      "        [35.0798]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[35.2119],\n",
      "        [35.2119],\n",
      "        [35.2119],\n",
      "        [35.2119],\n",
      "        [35.2119],\n",
      "        [35.2119],\n",
      "        [35.2119],\n",
      "        [35.2119],\n",
      "        [35.2119],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2120],\n",
      "        [35.2119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3432],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3431],\n",
      "        [35.3430],\n",
      "        [35.3430],\n",
      "        [35.3430],\n",
      "        [35.3430],\n",
      "        [35.3430],\n",
      "        [35.3430],\n",
      "        [35.3430]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[35.4659],\n",
      "        [35.4658],\n",
      "        [35.4658],\n",
      "        [35.4658],\n",
      "        [35.4658],\n",
      "        [35.4658],\n",
      "        [35.4658],\n",
      "        [35.4658],\n",
      "        [35.4659],\n",
      "        [35.4659],\n",
      "        [35.4660],\n",
      "        [35.4660],\n",
      "        [35.4660],\n",
      "        [35.4660],\n",
      "        [35.4660],\n",
      "        [35.4660],\n",
      "        [35.4659],\n",
      "        [35.4659],\n",
      "        [35.4659],\n",
      "        [35.4659],\n",
      "        [35.4659],\n",
      "        [35.4659],\n",
      "        [35.4659],\n",
      "        [35.4659]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[35.5905],\n",
      "        [35.5904],\n",
      "        [35.5905],\n",
      "        [35.5905],\n",
      "        [35.5905],\n",
      "        [35.5905],\n",
      "        [35.5905],\n",
      "        [35.5905],\n",
      "        [35.5905],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906],\n",
      "        [35.5906]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7128],\n",
      "        [35.7128],\n",
      "        [35.7128],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127],\n",
      "        [35.7127]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[35.8361],\n",
      "        [35.8361],\n",
      "        [35.8361],\n",
      "        [35.8361],\n",
      "        [35.8361],\n",
      "        [35.8361],\n",
      "        [35.8361],\n",
      "        [35.8361],\n",
      "        [35.8361],\n",
      "        [35.8362],\n",
      "        [35.8362],\n",
      "        [35.8362],\n",
      "        [35.8362],\n",
      "        [35.8362],\n",
      "        [35.8362],\n",
      "        [35.8361],\n",
      "        [35.8361],\n",
      "        [35.8362],\n",
      "        [35.8362],\n",
      "        [35.8362],\n",
      "        [35.8361],\n",
      "        [35.8361],\n",
      "        [35.8361],\n",
      "        [35.8361]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575],\n",
      "        [35.9575]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808],\n",
      "        [36.0808]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[36.2077],\n",
      "        [36.2077],\n",
      "        [36.2077],\n",
      "        [36.2077],\n",
      "        [36.2077],\n",
      "        [36.2077],\n",
      "        [36.2077],\n",
      "        [36.2077],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078],\n",
      "        [36.2078]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3356],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357],\n",
      "        [36.3357]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4649],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4651],\n",
      "        [36.4651],\n",
      "        [36.4651],\n",
      "        [36.4651],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650],\n",
      "        [36.4650]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[36.5884],\n",
      "        [36.5884],\n",
      "        [36.5884],\n",
      "        [36.5884],\n",
      "        [36.5884],\n",
      "        [36.5884],\n",
      "        [36.5884],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885],\n",
      "        [36.5885]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[36.7091],\n",
      "        [36.7091],\n",
      "        [36.7090],\n",
      "        [36.7090],\n",
      "        [36.7090],\n",
      "        [36.7090],\n",
      "        [36.7090],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7091],\n",
      "        [36.7090],\n",
      "        [36.7090],\n",
      "        [36.7090]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8331],\n",
      "        [36.8330],\n",
      "        [36.8331],\n",
      "        [36.8331],\n",
      "        [36.8331],\n",
      "        [36.8331],\n",
      "        [36.8331],\n",
      "        [36.8331],\n",
      "        [36.8331],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330],\n",
      "        [36.8330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547],\n",
      "        [36.9547]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785],\n",
      "        [37.0785]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2045],\n",
      "        [37.2045],\n",
      "        [37.2045],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046],\n",
      "        [37.2046]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3328],\n",
      "        [37.3327],\n",
      "        [37.3328],\n",
      "        [37.3328],\n",
      "        [37.3328],\n",
      "        [37.3328],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327],\n",
      "        [37.3327]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615],\n",
      "        [37.4615]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[37.5912],\n",
      "        [37.5913],\n",
      "        [37.5912],\n",
      "        [37.5912],\n",
      "        [37.5912],\n",
      "        [37.5912],\n",
      "        [37.5912],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5913],\n",
      "        [37.5912],\n",
      "        [37.5913],\n",
      "        [37.5912],\n",
      "        [37.5912],\n",
      "        [37.5912]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[37.7216],\n",
      "        [37.7216],\n",
      "        [37.7216],\n",
      "        [37.7216],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7216],\n",
      "        [37.7216],\n",
      "        [37.7217],\n",
      "        [37.7217],\n",
      "        [37.7217]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8530],\n",
      "        [37.8530],\n",
      "        [37.8530],\n",
      "        [37.8530],\n",
      "        [37.8530],\n",
      "        [37.8530],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529],\n",
      "        [37.8529]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[37.9827],\n",
      "        [37.9826],\n",
      "        [37.9826],\n",
      "        [37.9826],\n",
      "        [37.9826],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827],\n",
      "        [37.9827]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[38.1106],\n",
      "        [38.1105],\n",
      "        [38.1105],\n",
      "        [38.1105],\n",
      "        [38.1105],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106],\n",
      "        [38.1106]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[38.2373],\n",
      "        [38.2373],\n",
      "        [38.2373],\n",
      "        [38.2373],\n",
      "        [38.2373],\n",
      "        [38.2373],\n",
      "        [38.2373],\n",
      "        [38.2373],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2373],\n",
      "        [38.2374],\n",
      "        [38.2374],\n",
      "        [38.2373],\n",
      "        [38.2373]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3622],\n",
      "        [38.3622],\n",
      "        [38.3622],\n",
      "        [38.3622],\n",
      "        [38.3622],\n",
      "        [38.3622],\n",
      "        [38.3622],\n",
      "        [38.3622],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621],\n",
      "        [38.3621]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[38.4838],\n",
      "        [38.4838],\n",
      "        [38.4838],\n",
      "        [38.4838],\n",
      "        [38.4838],\n",
      "        [38.4838],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839],\n",
      "        [38.4839]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6023],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6024],\n",
      "        [38.6023],\n",
      "        [38.6023],\n",
      "        [38.6024]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7232],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233],\n",
      "        [38.7233]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8447],\n",
      "        [38.8447],\n",
      "        [38.8446],\n",
      "        [38.8447],\n",
      "        [38.8447],\n",
      "        [38.8447],\n",
      "        [38.8447],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446],\n",
      "        [38.8446]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[38.9653],\n",
      "        [38.9653],\n",
      "        [38.9653],\n",
      "        [38.9653],\n",
      "        [38.9653],\n",
      "        [38.9652],\n",
      "        [38.9653],\n",
      "        [38.9653],\n",
      "        [38.9654],\n",
      "        [38.9654],\n",
      "        [38.9654],\n",
      "        [38.9654],\n",
      "        [38.9654],\n",
      "        [38.9654],\n",
      "        [38.9654],\n",
      "        [38.9654],\n",
      "        [38.9653],\n",
      "        [38.9654],\n",
      "        [38.9654],\n",
      "        [38.9653],\n",
      "        [38.9653],\n",
      "        [38.9653],\n",
      "        [38.9653],\n",
      "        [38.9653]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[39.0833],\n",
      "        [39.0833],\n",
      "        [39.0833],\n",
      "        [39.0833],\n",
      "        [39.0833],\n",
      "        [39.0833],\n",
      "        [39.0833],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834],\n",
      "        [39.0834]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1978],\n",
      "        [39.1978],\n",
      "        [39.1978],\n",
      "        [39.1978],\n",
      "        [39.1978],\n",
      "        [39.1978],\n",
      "        [39.1978],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977],\n",
      "        [39.1977]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[39.3127],\n",
      "        [39.3127],\n",
      "        [39.3127],\n",
      "        [39.3127],\n",
      "        [39.3127],\n",
      "        [39.3127],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3128],\n",
      "        [39.3127],\n",
      "        [39.3128],\n",
      "        [39.3127],\n",
      "        [39.3128],\n",
      "        [39.3127],\n",
      "        [39.3127]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[39.4280],\n",
      "        [39.4280],\n",
      "        [39.4280],\n",
      "        [39.4280],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4281],\n",
      "        [39.4280],\n",
      "        [39.4280]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446],\n",
      "        [39.5446]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[39.6628],\n",
      "        [39.6628],\n",
      "        [39.6628],\n",
      "        [39.6628],\n",
      "        [39.6628],\n",
      "        [39.6628],\n",
      "        [39.6628],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6629],\n",
      "        [39.6628],\n",
      "        [39.6628],\n",
      "        [39.6628],\n",
      "        [39.6628],\n",
      "        [39.6628]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[39.7781],\n",
      "        [39.7780],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7781],\n",
      "        [39.7780],\n",
      "        [39.7781],\n",
      "        [39.7780],\n",
      "        [39.7780],\n",
      "        [39.7780],\n",
      "        [39.7780],\n",
      "        [39.7780]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8909],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8911],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8911],\n",
      "        [39.8911],\n",
      "        [39.8911],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910],\n",
      "        [39.8910]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055],\n",
      "        [40.0055]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[40.1183],\n",
      "        [40.1183],\n",
      "        [40.1183],\n",
      "        [40.1183],\n",
      "        [40.1183],\n",
      "        [40.1183],\n",
      "        [40.1183],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184],\n",
      "        [40.1184]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2253],\n",
      "        [40.2253],\n",
      "        [40.2253],\n",
      "        [40.2253],\n",
      "        [40.2253],\n",
      "        [40.2253],\n",
      "        [40.2253],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252],\n",
      "        [40.2252]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3338],\n",
      "        [40.3338],\n",
      "        [40.3338],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337],\n",
      "        [40.3337]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[40.4431],\n",
      "        [40.4431],\n",
      "        [40.4432],\n",
      "        [40.4431],\n",
      "        [40.4431],\n",
      "        [40.4431],\n",
      "        [40.4431],\n",
      "        [40.4431],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4432],\n",
      "        [40.4431]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[40.5526],\n",
      "        [40.5526],\n",
      "        [40.5526],\n",
      "        [40.5526],\n",
      "        [40.5526],\n",
      "        [40.5526],\n",
      "        [40.5526],\n",
      "        [40.5526],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5526],\n",
      "        [40.5527],\n",
      "        [40.5527],\n",
      "        [40.5526],\n",
      "        [40.5526]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6584],\n",
      "        [40.6583],\n",
      "        [40.6584]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[40.7623],\n",
      "        [40.7623],\n",
      "        [40.7623],\n",
      "        [40.7623],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624],\n",
      "        [40.7624]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8639],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8640],\n",
      "        [40.8639],\n",
      "        [40.8639]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[40.9579],\n",
      "        [40.9579],\n",
      "        [40.9579],\n",
      "        [40.9579],\n",
      "        [40.9579],\n",
      "        [40.9579],\n",
      "        [40.9579],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9580],\n",
      "        [40.9579],\n",
      "        [40.9580]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.0531],\n",
      "        [41.0531],\n",
      "        [41.0531],\n",
      "        [41.0531],\n",
      "        [41.0531],\n",
      "        [41.0531],\n",
      "        [41.0531],\n",
      "        [41.0531],\n",
      "        [41.0531],\n",
      "        [41.0532],\n",
      "        [41.0531],\n",
      "        [41.0532],\n",
      "        [41.0532],\n",
      "        [41.0532],\n",
      "        [41.0532],\n",
      "        [41.0532],\n",
      "        [41.0532],\n",
      "        [41.0532],\n",
      "        [41.0532],\n",
      "        [41.0532],\n",
      "        [41.0531],\n",
      "        [41.0531],\n",
      "        [41.0531],\n",
      "        [41.0531]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.1422],\n",
      "        [41.1422],\n",
      "        [41.1422],\n",
      "        [41.1422],\n",
      "        [41.1422],\n",
      "        [41.1422],\n",
      "        [41.1423],\n",
      "        [41.1422],\n",
      "        [41.1423],\n",
      "        [41.1423],\n",
      "        [41.1423],\n",
      "        [41.1423],\n",
      "        [41.1423],\n",
      "        [41.1423],\n",
      "        [41.1423],\n",
      "        [41.1423],\n",
      "        [41.1423],\n",
      "        [41.1422],\n",
      "        [41.1422],\n",
      "        [41.1422],\n",
      "        [41.1422],\n",
      "        [41.1422],\n",
      "        [41.1422],\n",
      "        [41.1422]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.2346],\n",
      "        [41.2346],\n",
      "        [41.2346],\n",
      "        [41.2346],\n",
      "        [41.2346],\n",
      "        [41.2346],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2347],\n",
      "        [41.2346],\n",
      "        [41.2347],\n",
      "        [41.2346],\n",
      "        [41.2346],\n",
      "        [41.2346]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.3240],\n",
      "        [41.3240],\n",
      "        [41.3240],\n",
      "        [41.3240],\n",
      "        [41.3240],\n",
      "        [41.3240],\n",
      "        [41.3240],\n",
      "        [41.3240],\n",
      "        [41.3241],\n",
      "        [41.3241],\n",
      "        [41.3241],\n",
      "        [41.3241],\n",
      "        [41.3241],\n",
      "        [41.3241],\n",
      "        [41.3241],\n",
      "        [41.3241],\n",
      "        [41.3241],\n",
      "        [41.3241],\n",
      "        [41.3240],\n",
      "        [41.3240],\n",
      "        [41.3240],\n",
      "        [41.3240],\n",
      "        [41.3240],\n",
      "        [41.3240]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.4083],\n",
      "        [41.4083],\n",
      "        [41.4083],\n",
      "        [41.4083],\n",
      "        [41.4083],\n",
      "        [41.4083],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4084],\n",
      "        [41.4083],\n",
      "        [41.4083],\n",
      "        [41.4083],\n",
      "        [41.4083],\n",
      "        [41.4083],\n",
      "        [41.4083]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891],\n",
      "        [41.4891]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.5672],\n",
      "        [41.5672],\n",
      "        [41.5671],\n",
      "        [41.5672],\n",
      "        [41.5671],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5672],\n",
      "        [41.5671],\n",
      "        [41.5671],\n",
      "        [41.5671],\n",
      "        [41.5671]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.6417],\n",
      "        [41.6417],\n",
      "        [41.6417],\n",
      "        [41.6417],\n",
      "        [41.6417],\n",
      "        [41.6417],\n",
      "        [41.6417],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6418],\n",
      "        [41.6417]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.7151],\n",
      "        [41.7151],\n",
      "        [41.7151],\n",
      "        [41.7151],\n",
      "        [41.7151],\n",
      "        [41.7151],\n",
      "        [41.7151],\n",
      "        [41.7151],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7152],\n",
      "        [41.7151]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7821],\n",
      "        [41.7820],\n",
      "        [41.7821],\n",
      "        [41.7821],\n",
      "        [41.7821],\n",
      "        [41.7821],\n",
      "        [41.7821],\n",
      "        [41.7821],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820],\n",
      "        [41.7820]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.8385],\n",
      "        [41.8384],\n",
      "        [41.8384],\n",
      "        [41.8384],\n",
      "        [41.8384],\n",
      "        [41.8384],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385],\n",
      "        [41.8385]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.8923],\n",
      "        [41.8923],\n",
      "        [41.8923],\n",
      "        [41.8923],\n",
      "        [41.8923],\n",
      "        [41.8922],\n",
      "        [41.8923],\n",
      "        [41.8923],\n",
      "        [41.8923],\n",
      "        [41.8922],\n",
      "        [41.8922],\n",
      "        [41.8922],\n",
      "        [41.8922],\n",
      "        [41.8922],\n",
      "        [41.8922],\n",
      "        [41.8922],\n",
      "        [41.8923],\n",
      "        [41.8922],\n",
      "        [41.8923],\n",
      "        [41.8923],\n",
      "        [41.8923],\n",
      "        [41.8923],\n",
      "        [41.8923],\n",
      "        [41.8923]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9454],\n",
      "        [41.9454],\n",
      "        [41.9454],\n",
      "        [41.9454],\n",
      "        [41.9454],\n",
      "        [41.9454],\n",
      "        [41.9454],\n",
      "        [41.9454],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455],\n",
      "        [41.9455]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[41.9998],\n",
      "        [41.9998],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9997],\n",
      "        [41.9998],\n",
      "        [41.9998],\n",
      "        [41.9997]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0585],\n",
      "        [42.0586],\n",
      "        [42.0585],\n",
      "        [42.0585],\n",
      "        [42.0585],\n",
      "        [42.0585],\n",
      "        [42.0585],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0586],\n",
      "        [42.0587],\n",
      "        [42.0587]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.1224],\n",
      "        [42.1224],\n",
      "        [42.1224],\n",
      "        [42.1224],\n",
      "        [42.1224],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1223],\n",
      "        [42.1224],\n",
      "        [42.1224],\n",
      "        [42.1224],\n",
      "        [42.1224],\n",
      "        [42.1224],\n",
      "        [42.1224]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.1848],\n",
      "        [42.1848],\n",
      "        [42.1848],\n",
      "        [42.1848],\n",
      "        [42.1848],\n",
      "        [42.1847],\n",
      "        [42.1847],\n",
      "        [42.1847],\n",
      "        [42.1847],\n",
      "        [42.1847],\n",
      "        [42.1847],\n",
      "        [42.1847],\n",
      "        [42.1847],\n",
      "        [42.1848],\n",
      "        [42.1847],\n",
      "        [42.1847],\n",
      "        [42.1848],\n",
      "        [42.1848],\n",
      "        [42.1848],\n",
      "        [42.1848],\n",
      "        [42.1848],\n",
      "        [42.1848],\n",
      "        [42.1848],\n",
      "        [42.1848]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.2461],\n",
      "        [42.2461],\n",
      "        [42.2461],\n",
      "        [42.2461],\n",
      "        [42.2460],\n",
      "        [42.2460],\n",
      "        [42.2460],\n",
      "        [42.2460],\n",
      "        [42.2460],\n",
      "        [42.2460],\n",
      "        [42.2460],\n",
      "        [42.2460],\n",
      "        [42.2460],\n",
      "        [42.2460],\n",
      "        [42.2460],\n",
      "        [42.2461],\n",
      "        [42.2461],\n",
      "        [42.2461],\n",
      "        [42.2461],\n",
      "        [42.2461],\n",
      "        [42.2461],\n",
      "        [42.2461],\n",
      "        [42.2461],\n",
      "        [42.2461]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3035],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036],\n",
      "        [42.3036]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.3617],\n",
      "        [42.3617],\n",
      "        [42.3617],\n",
      "        [42.3617],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3616],\n",
      "        [42.3617],\n",
      "        [42.3617],\n",
      "        [42.3617],\n",
      "        [42.3617]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4197],\n",
      "        [42.4197],\n",
      "        [42.4197],\n",
      "        [42.4197],\n",
      "        [42.4197],\n",
      "        [42.4197],\n",
      "        [42.4197],\n",
      "        [42.4197],\n",
      "        [42.4197],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198],\n",
      "        [42.4198]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4824],\n",
      "        [42.4824],\n",
      "        [42.4823],\n",
      "        [42.4823],\n",
      "        [42.4824],\n",
      "        [42.4823]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5512],\n",
      "        [42.5512],\n",
      "        [42.5512],\n",
      "        [42.5512],\n",
      "        [42.5512],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513],\n",
      "        [42.5513]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6254],\n",
      "        [42.6255],\n",
      "        [42.6255],\n",
      "        [42.6255],\n",
      "        [42.6255],\n",
      "        [42.6254]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.6991],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6990],\n",
      "        [42.6990],\n",
      "        [42.6991],\n",
      "        [42.6990],\n",
      "        [42.6990],\n",
      "        [42.6990],\n",
      "        [42.6990],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6990],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6991],\n",
      "        [42.6991]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.7714],\n",
      "        [42.7714],\n",
      "        [42.7714],\n",
      "        [42.7714],\n",
      "        [42.7714],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7713],\n",
      "        [42.7714],\n",
      "        [42.7714],\n",
      "        [42.7714],\n",
      "        [42.7714],\n",
      "        [42.7714]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450],\n",
      "        [42.8450]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[42.9212],\n",
      "        [42.9212],\n",
      "        [42.9212],\n",
      "        [42.9212],\n",
      "        [42.9211],\n",
      "        [42.9211],\n",
      "        [42.9211],\n",
      "        [42.9212],\n",
      "        [42.9211],\n",
      "        [42.9211],\n",
      "        [42.9211],\n",
      "        [42.9211],\n",
      "        [42.9211],\n",
      "        [42.9211],\n",
      "        [42.9211],\n",
      "        [42.9211],\n",
      "        [42.9211],\n",
      "        [42.9212],\n",
      "        [42.9212],\n",
      "        [42.9212],\n",
      "        [42.9212],\n",
      "        [42.9212],\n",
      "        [42.9212],\n",
      "        [42.9212]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0013],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014],\n",
      "        [43.0014]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858],\n",
      "        [43.0858]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729],\n",
      "        [43.1729]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.2627],\n",
      "        [43.2627],\n",
      "        [43.2627],\n",
      "        [43.2627],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2626],\n",
      "        [43.2627],\n",
      "        [43.2627],\n",
      "        [43.2627],\n",
      "        [43.2627],\n",
      "        [43.2627],\n",
      "        [43.2627],\n",
      "        [43.2627]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530],\n",
      "        [43.3530]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4444],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4444],\n",
      "        [43.4444],\n",
      "        [43.4444],\n",
      "        [43.4444],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445],\n",
      "        [43.4445]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5379],\n",
      "        [43.5379],\n",
      "        [43.5379],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380],\n",
      "        [43.5380]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.6342],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6341],\n",
      "        [43.6342],\n",
      "        [43.6342]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324],\n",
      "        [43.7324]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.8325],\n",
      "        [43.8325],\n",
      "        [43.8325],\n",
      "        [43.8325],\n",
      "        [43.8325],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8324],\n",
      "        [43.8325],\n",
      "        [43.8325],\n",
      "        [43.8325],\n",
      "        [43.8325],\n",
      "        [43.8325],\n",
      "        [43.8325],\n",
      "        [43.8325]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9335],\n",
      "        [43.9336],\n",
      "        [43.9336],\n",
      "        [43.9336],\n",
      "        [43.9336],\n",
      "        [43.9336]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337],\n",
      "        [44.0337]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[44.1348],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1347],\n",
      "        [44.1348],\n",
      "        [44.1348]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2376],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377],\n",
      "        [44.2377]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421],\n",
      "        [44.3421]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[44.4474],\n",
      "        [44.4474],\n",
      "        [44.4474],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4473],\n",
      "        [44.4474],\n",
      "        [44.4474],\n",
      "        [44.4474],\n",
      "        [44.4474],\n",
      "        [44.4474],\n",
      "        [44.4473]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536],\n",
      "        [44.5536]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607],\n",
      "        [44.6607]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669],\n",
      "        [44.7669]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734],\n",
      "        [44.8734]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806],\n",
      "        [44.9806]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888],\n",
      "        [45.0888]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1978],\n",
      "        [45.1979],\n",
      "        [45.1979],\n",
      "        [45.1979],\n",
      "        [45.1979],\n",
      "        [45.1979]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[45.3071],\n",
      "        [45.3071],\n",
      "        [45.3070],\n",
      "        [45.3071],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3070],\n",
      "        [45.3071],\n",
      "        [45.3071],\n",
      "        [45.3071],\n",
      "        [45.3071],\n",
      "        [45.3071],\n",
      "        [45.3071],\n",
      "        [45.3071],\n",
      "        [45.3071]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163],\n",
      "        [45.4163]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247],\n",
      "        [45.5247]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336],\n",
      "        [45.6336]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434],\n",
      "        [45.7434]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[45.8532],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8532],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8531],\n",
      "        [45.8532],\n",
      "        [45.8532],\n",
      "        [45.8532],\n",
      "        [45.8532],\n",
      "        [45.8532],\n",
      "        [45.8532],\n",
      "        [45.8532],\n",
      "        [45.8532],\n",
      "        [45.8532]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630],\n",
      "        [45.9630]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733],\n",
      "        [46.0733]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842],\n",
      "        [46.1842]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946],\n",
      "        [46.2946]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053],\n",
      "        [46.4053]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169],\n",
      "        [46.5169]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6290],\n",
      "        [46.6291],\n",
      "        [46.6291],\n",
      "        [46.6291],\n",
      "        [46.6291],\n",
      "        [46.6291],\n",
      "        [46.6291],\n",
      "        [46.6290]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419],\n",
      "        [46.7419]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8558],\n",
      "        [46.8558],\n",
      "        [46.8558],\n",
      "        [46.8558],\n",
      "        [46.8558],\n",
      "        [46.8558],\n",
      "        [46.8558],\n",
      "        [46.8559],\n",
      "        [46.8558],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559],\n",
      "        [46.8559]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702],\n",
      "        [46.9702]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0831],\n",
      "        [47.0831],\n",
      "        [47.0831],\n",
      "        [47.0831],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832],\n",
      "        [47.0832]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960],\n",
      "        [47.1960]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089],\n",
      "        [47.3089]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217],\n",
      "        [47.4217]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348],\n",
      "        [47.5348]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489],\n",
      "        [47.6489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629],\n",
      "        [47.7629]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8765],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766],\n",
      "        [47.8766]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899],\n",
      "        [47.9899]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039],\n",
      "        [48.1039]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183],\n",
      "        [48.2183]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331],\n",
      "        [48.3331]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4487],\n",
      "        [48.4487],\n",
      "        [48.4487],\n",
      "        [48.4487],\n",
      "        [48.4487],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488],\n",
      "        [48.4488]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644],\n",
      "        [48.5644]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795],\n",
      "        [48.6795]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943],\n",
      "        [48.7943]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092],\n",
      "        [48.9092]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245],\n",
      "        [49.0245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405],\n",
      "        [49.1405]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582],\n",
      "        [49.2582]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3768],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769],\n",
      "        [49.3769]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963],\n",
      "        [49.4963]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170],\n",
      "        [49.6170]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401],\n",
      "        [49.7401]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651],\n",
      "        [49.8651]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926],\n",
      "        [49.9926]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215],\n",
      "        [50.1215]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2513],\n",
      "        [50.2513],\n",
      "        [50.2513],\n",
      "        [50.2513],\n",
      "        [50.2513],\n",
      "        [50.2513],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514],\n",
      "        [50.2514]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808],\n",
      "        [50.3808]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5112],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113],\n",
      "        [50.5113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437],\n",
      "        [50.6437]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770],\n",
      "        [50.7770]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113],\n",
      "        [50.9113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454],\n",
      "        [51.0454]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794],\n",
      "        [51.1794]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123],\n",
      "        [51.3123]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[51.4450],\n",
      "        [51.4449],\n",
      "        [51.4450],\n",
      "        [51.4449],\n",
      "        [51.4449],\n",
      "        [51.4450],\n",
      "        [51.4449],\n",
      "        [51.4450],\n",
      "        [51.4449],\n",
      "        [51.4449],\n",
      "        [51.4449],\n",
      "        [51.4449],\n",
      "        [51.4449],\n",
      "        [51.4449],\n",
      "        [51.4450],\n",
      "        [51.4450],\n",
      "        [51.4450],\n",
      "        [51.4450],\n",
      "        [51.4450],\n",
      "        [51.4450],\n",
      "        [51.4450],\n",
      "        [51.4450],\n",
      "        [51.4450],\n",
      "        [51.4450]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5786],\n",
      "        [51.5787],\n",
      "        [51.5787],\n",
      "        [51.5787],\n",
      "        [51.5787],\n",
      "        [51.5787],\n",
      "        [51.5787],\n",
      "        [51.5787],\n",
      "        [51.5786]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125],\n",
      "        [51.7125]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462],\n",
      "        [51.8462]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9797],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798],\n",
      "        [51.9798]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1119],\n",
      "        [52.1120],\n",
      "        [52.1120],\n",
      "        [52.1120],\n",
      "        [52.1120],\n",
      "        [52.1120],\n",
      "        [52.1119],\n",
      "        [52.1119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[52.2427],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2426],\n",
      "        [52.2427],\n",
      "        [52.2427],\n",
      "        [52.2427],\n",
      "        [52.2427],\n",
      "        [52.2427],\n",
      "        [52.2427],\n",
      "        [52.2427],\n",
      "        [52.2427],\n",
      "        [52.2427]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3730],\n",
      "        [52.3729],\n",
      "        [52.3730],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729],\n",
      "        [52.3729]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033],\n",
      "        [52.5033]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6330],\n",
      "        [52.6331],\n",
      "        [52.6331],\n",
      "        [52.6331],\n",
      "        [52.6331],\n",
      "        [52.6331],\n",
      "        [52.6331],\n",
      "        [52.6331],\n",
      "        [52.6330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610],\n",
      "        [52.7610]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876],\n",
      "        [52.8876]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133],\n",
      "        [53.0133]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1376],\n",
      "        [53.1376],\n",
      "        [53.1376],\n",
      "        [53.1377],\n",
      "        [53.1376],\n",
      "        [53.1376],\n",
      "        [53.1376],\n",
      "        [53.1376],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377],\n",
      "        [53.1377]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620],\n",
      "        [53.2620]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863],\n",
      "        [53.3863]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101],\n",
      "        [53.5101]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[53.6333],\n",
      "        [53.6333],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6332],\n",
      "        [53.6333],\n",
      "        [53.6333],\n",
      "        [53.6333],\n",
      "        [53.6333],\n",
      "        [53.6333],\n",
      "        [53.6333],\n",
      "        [53.6333],\n",
      "        [53.6333],\n",
      "        [53.6333],\n",
      "        [53.6333]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563],\n",
      "        [53.7563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797],\n",
      "        [53.8797]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025],\n",
      "        [54.0025]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254],\n",
      "        [54.1254]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[54.2493],\n",
      "        [54.2493],\n",
      "        [54.2493],\n",
      "        [54.2493],\n",
      "        [54.2494],\n",
      "        [54.2494],\n",
      "        [54.2493],\n",
      "        [54.2493],\n",
      "        [54.2493],\n",
      "        [54.2493],\n",
      "        [54.2493],\n",
      "        [54.2493],\n",
      "        [54.2493],\n",
      "        [54.2493],\n",
      "        [54.2494],\n",
      "        [54.2494],\n",
      "        [54.2494],\n",
      "        [54.2494],\n",
      "        [54.2494],\n",
      "        [54.2494],\n",
      "        [54.2494],\n",
      "        [54.2494],\n",
      "        [54.2494],\n",
      "        [54.2494]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741],\n",
      "        [54.3741]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000],\n",
      "        [54.5000]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6270],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6270],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271],\n",
      "        [54.6271]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548],\n",
      "        [54.7548]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811],\n",
      "        [54.8811]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053],\n",
      "        [55.0053]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263],\n",
      "        [55.1263]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470],\n",
      "        [55.2470]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675],\n",
      "        [55.3675]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882],\n",
      "        [55.4882]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086],\n",
      "        [55.6086]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287],\n",
      "        [55.7287]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8488],\n",
      "        [55.8488],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489],\n",
      "        [55.8489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9689],\n",
      "        [55.9689],\n",
      "        [55.9689],\n",
      "        [55.9689],\n",
      "        [55.9689],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690],\n",
      "        [55.9690]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0902],\n",
      "        [56.0903],\n",
      "        [56.0903],\n",
      "        [56.0903],\n",
      "        [56.0903],\n",
      "        [56.0903],\n",
      "        [56.0902],\n",
      "        [56.0902]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109],\n",
      "        [56.2109]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3312],\n",
      "        [56.3313],\n",
      "        [56.3313],\n",
      "        [56.3313],\n",
      "        [56.3313],\n",
      "        [56.3313],\n",
      "        [56.3313],\n",
      "        [56.3313],\n",
      "        [56.3313],\n",
      "        [56.3313],\n",
      "        [56.3313]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[56.4500],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4499],\n",
      "        [56.4500],\n",
      "        [56.4500],\n",
      "        [56.4500],\n",
      "        [56.4500],\n",
      "        [56.4500],\n",
      "        [56.4500],\n",
      "        [56.4500],\n",
      "        [56.4500],\n",
      "        [56.4500],\n",
      "        [56.4500]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654],\n",
      "        [56.5654]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6788],\n",
      "        [56.6789],\n",
      "        [56.6789],\n",
      "        [56.6789],\n",
      "        [56.6789],\n",
      "        [56.6789],\n",
      "        [56.6789],\n",
      "        [56.6789],\n",
      "        [56.6789],\n",
      "        [56.6789]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912],\n",
      "        [56.7912]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020],\n",
      "        [56.9020]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105],\n",
      "        [57.0105]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1154],\n",
      "        [57.1155],\n",
      "        [57.1154],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155],\n",
      "        [57.1155]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166],\n",
      "        [57.2166]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3123],\n",
      "        [57.3124],\n",
      "        [57.3124],\n",
      "        [57.3124],\n",
      "        [57.3124],\n",
      "        [57.3124],\n",
      "        [57.3124],\n",
      "        [57.3124],\n",
      "        [57.3124],\n",
      "        [57.3124]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.4065],\n",
      "        [57.4065],\n",
      "        [57.4065],\n",
      "        [57.4064],\n",
      "        [57.4064],\n",
      "        [57.4064],\n",
      "        [57.4064],\n",
      "        [57.4064],\n",
      "        [57.4064],\n",
      "        [57.4064],\n",
      "        [57.4064],\n",
      "        [57.4065],\n",
      "        [57.4064],\n",
      "        [57.4064],\n",
      "        [57.4064],\n",
      "        [57.4065],\n",
      "        [57.4065],\n",
      "        [57.4065],\n",
      "        [57.4065],\n",
      "        [57.4065],\n",
      "        [57.4065],\n",
      "        [57.4065],\n",
      "        [57.4065],\n",
      "        [57.4065]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005],\n",
      "        [57.5005]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.5943],\n",
      "        [57.5942],\n",
      "        [57.5942],\n",
      "        [57.5942],\n",
      "        [57.5942],\n",
      "        [57.5942],\n",
      "        [57.5942],\n",
      "        [57.5942],\n",
      "        [57.5943],\n",
      "        [57.5942],\n",
      "        [57.5942],\n",
      "        [57.5942],\n",
      "        [57.5942],\n",
      "        [57.5942],\n",
      "        [57.5943],\n",
      "        [57.5943],\n",
      "        [57.5943],\n",
      "        [57.5943],\n",
      "        [57.5943],\n",
      "        [57.5943],\n",
      "        [57.5943],\n",
      "        [57.5943],\n",
      "        [57.5943],\n",
      "        [57.5943]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873],\n",
      "        [57.6873]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7807],\n",
      "        [57.7808],\n",
      "        [57.7808],\n",
      "        [57.7808],\n",
      "        [57.7808],\n",
      "        [57.7808],\n",
      "        [57.7808],\n",
      "        [57.7808],\n",
      "        [57.7808]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.8724],\n",
      "        [57.8724],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8723],\n",
      "        [57.8724],\n",
      "        [57.8724],\n",
      "        [57.8724],\n",
      "        [57.8724],\n",
      "        [57.8724],\n",
      "        [57.8724],\n",
      "        [57.8724],\n",
      "        [57.8724],\n",
      "        [57.8724]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9605],\n",
      "        [57.9606],\n",
      "        [57.9606],\n",
      "        [57.9606],\n",
      "        [57.9606],\n",
      "        [57.9606],\n",
      "        [57.9606],\n",
      "        [57.9606],\n",
      "        [57.9606],\n",
      "        [57.9605]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0486],\n",
      "        [58.0486],\n",
      "        [58.0486],\n",
      "        [58.0485],\n",
      "        [58.0485],\n",
      "        [58.0485]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376],\n",
      "        [58.1376]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283],\n",
      "        [58.2283]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203],\n",
      "        [58.3203]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106],\n",
      "        [58.4106]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4974],\n",
      "        [58.4974],\n",
      "        [58.4974],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975],\n",
      "        [58.4975]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[58.5841],\n",
      "        [58.5841],\n",
      "        [58.5841],\n",
      "        [58.5841],\n",
      "        [58.5841],\n",
      "        [58.5841],\n",
      "        [58.5841]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [2/10], Loss: 8704.0015\n",
      "outputs: tensor([[58.6746],\n",
      "        [58.6746],\n",
      "        [58.6746],\n",
      "        [58.6746],\n",
      "        [58.6746],\n",
      "        [58.6746],\n",
      "        [58.6746],\n",
      "        [58.6746],\n",
      "        [58.6747],\n",
      "        [58.6747],\n",
      "        [58.6747],\n",
      "        [58.6747],\n",
      "        [58.6747],\n",
      "        [58.6747],\n",
      "        [58.6747],\n",
      "        [58.6747],\n",
      "        [58.6747],\n",
      "        [58.6747],\n",
      "        [58.6747],\n",
      "        [58.6746],\n",
      "        [58.6746],\n",
      "        [58.6746],\n",
      "        [58.6746],\n",
      "        [58.6746]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7671],\n",
      "        [58.7671],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672],\n",
      "        [58.7672]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8646],\n",
      "        [58.8645],\n",
      "        [58.8645]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[58.9646],\n",
      "        [58.9645],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9645],\n",
      "        [58.9646],\n",
      "        [58.9645],\n",
      "        [58.9645],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646],\n",
      "        [58.9646]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[59.0692],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0693],\n",
      "        [59.0693],\n",
      "        [59.0693],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0693],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0693],\n",
      "        [59.0693],\n",
      "        [59.0693],\n",
      "        [59.0692],\n",
      "        [59.0692],\n",
      "        [59.0692]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[59.1740],\n",
      "        [59.1740],\n",
      "        [59.1740],\n",
      "        [59.1740],\n",
      "        [59.1740],\n",
      "        [59.1740],\n",
      "        [59.1740],\n",
      "        [59.1740],\n",
      "        [59.1740],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1740],\n",
      "        [59.1741],\n",
      "        [59.1741],\n",
      "        [59.1741]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789],\n",
      "        [59.2789]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[59.3805],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3805],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3806],\n",
      "        [59.3805],\n",
      "        [59.3805],\n",
      "        [59.3805],\n",
      "        [59.3805]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4829],\n",
      "        [59.4828],\n",
      "        [59.4829],\n",
      "        [59.4828],\n",
      "        [59.4829],\n",
      "        [59.4829],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828],\n",
      "        [59.4828]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878],\n",
      "        [59.5878]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6957],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958],\n",
      "        [59.6958]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8049],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8049],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8049],\n",
      "        [59.8049],\n",
      "        [59.8049],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048],\n",
      "        [59.8048]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[59.9160],\n",
      "        [59.9159],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9159],\n",
      "        [59.9159],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9160],\n",
      "        [59.9159],\n",
      "        [59.9159],\n",
      "        [59.9159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[60.0292],\n",
      "        [60.0292],\n",
      "        [60.0292],\n",
      "        [60.0292],\n",
      "        [60.0292],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293],\n",
      "        [60.0293]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1422],\n",
      "        [60.1421],\n",
      "        [60.1422]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2543],\n",
      "        [60.2543],\n",
      "        [60.2543],\n",
      "        [60.2543],\n",
      "        [60.2543],\n",
      "        [60.2543],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542],\n",
      "        [60.2542]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667],\n",
      "        [60.3667]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4782],\n",
      "        [60.4782],\n",
      "        [60.4782],\n",
      "        [60.4781],\n",
      "        [60.4782],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781],\n",
      "        [60.4781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[60.5802],\n",
      "        [60.5801],\n",
      "        [60.5801],\n",
      "        [60.5801],\n",
      "        [60.5801],\n",
      "        [60.5801],\n",
      "        [60.5801],\n",
      "        [60.5801],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802],\n",
      "        [60.5802]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[60.6842],\n",
      "        [60.6842],\n",
      "        [60.6842],\n",
      "        [60.6842],\n",
      "        [60.6842],\n",
      "        [60.6842],\n",
      "        [60.6842],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843],\n",
      "        [60.6843]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856],\n",
      "        [60.7856]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[60.8884],\n",
      "        [60.8884],\n",
      "        [60.8884],\n",
      "        [60.8884],\n",
      "        [60.8884],\n",
      "        [60.8884],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885],\n",
      "        [60.8885]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890],\n",
      "        [60.9890]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918],\n",
      "        [61.0918]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988],\n",
      "        [61.1988]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070],\n",
      "        [61.3070]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4168],\n",
      "        [61.4168],\n",
      "        [61.4168],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169],\n",
      "        [61.4169]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[61.5200],\n",
      "        [61.5200],\n",
      "        [61.5200],\n",
      "        [61.5200],\n",
      "        [61.5200],\n",
      "        [61.5200],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201],\n",
      "        [61.5201]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201],\n",
      "        [61.6201]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7239],\n",
      "        [61.7239],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240],\n",
      "        [61.7240]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[61.8252],\n",
      "        [61.8252],\n",
      "        [61.8252],\n",
      "        [61.8252],\n",
      "        [61.8252],\n",
      "        [61.8252],\n",
      "        [61.8252],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8253],\n",
      "        [61.8252],\n",
      "        [61.8253]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9291],\n",
      "        [61.9291],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290],\n",
      "        [61.9290]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355],\n",
      "        [62.0355]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444],\n",
      "        [62.1444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541],\n",
      "        [62.2541]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3650],\n",
      "        [62.3650],\n",
      "        [62.3650],\n",
      "        [62.3650],\n",
      "        [62.3650],\n",
      "        [62.3650],\n",
      "        [62.3650],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649],\n",
      "        [62.3649]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766],\n",
      "        [62.4766]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893],\n",
      "        [62.5893]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7004],\n",
      "        [62.7004],\n",
      "        [62.7004],\n",
      "        [62.7004],\n",
      "        [62.7004],\n",
      "        [62.7004],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7003],\n",
      "        [62.7004]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[62.8093],\n",
      "        [62.8092],\n",
      "        [62.8092],\n",
      "        [62.8092],\n",
      "        [62.8092],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093],\n",
      "        [62.8093]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9169],\n",
      "        [62.9170],\n",
      "        [62.9169],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170],\n",
      "        [62.9170]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[63.0225],\n",
      "        [63.0224],\n",
      "        [63.0224],\n",
      "        [63.0224],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225],\n",
      "        [63.0225]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[63.1244],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1244],\n",
      "        [63.1244],\n",
      "        [63.1244],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245],\n",
      "        [63.1245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2229],\n",
      "        [63.2229],\n",
      "        [63.2229],\n",
      "        [63.2229],\n",
      "        [63.2229],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228],\n",
      "        [63.2228]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240],\n",
      "        [63.3240]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257],\n",
      "        [63.4257]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5266],\n",
      "        [63.5266],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5267],\n",
      "        [63.5266]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[63.6246],\n",
      "        [63.6246],\n",
      "        [63.6246],\n",
      "        [63.6246],\n",
      "        [63.6246],\n",
      "        [63.6246],\n",
      "        [63.6246],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6247],\n",
      "        [63.6246],\n",
      "        [63.6246],\n",
      "        [63.6247],\n",
      "        [63.6246],\n",
      "        [63.6247]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184],\n",
      "        [63.7184]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130],\n",
      "        [63.8130]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079],\n",
      "        [63.9079]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0042],\n",
      "        [64.0042],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0043],\n",
      "        [64.0042],\n",
      "        [64.0043],\n",
      "        [64.0042],\n",
      "        [64.0042],\n",
      "        [64.0042],\n",
      "        [64.0042]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.1025],\n",
      "        [64.1025],\n",
      "        [64.1025],\n",
      "        [64.1025],\n",
      "        [64.1025],\n",
      "        [64.1025],\n",
      "        [64.1025],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1026],\n",
      "        [64.1025],\n",
      "        [64.1025],\n",
      "        [64.1025],\n",
      "        [64.1025],\n",
      "        [64.1025]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.1975],\n",
      "        [64.1974],\n",
      "        [64.1974],\n",
      "        [64.1975],\n",
      "        [64.1974],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1975],\n",
      "        [64.1974],\n",
      "        [64.1975],\n",
      "        [64.1974],\n",
      "        [64.1974],\n",
      "        [64.1974],\n",
      "        [64.1974],\n",
      "        [64.1974]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.2898],\n",
      "        [64.2898],\n",
      "        [64.2897],\n",
      "        [64.2897],\n",
      "        [64.2897],\n",
      "        [64.2897],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2897],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898],\n",
      "        [64.2898]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.3838],\n",
      "        [64.3838],\n",
      "        [64.3838],\n",
      "        [64.3838],\n",
      "        [64.3838],\n",
      "        [64.3839],\n",
      "        [64.3838],\n",
      "        [64.3838],\n",
      "        [64.3839],\n",
      "        [64.3839],\n",
      "        [64.3839],\n",
      "        [64.3839],\n",
      "        [64.3839],\n",
      "        [64.3839],\n",
      "        [64.3839],\n",
      "        [64.3839],\n",
      "        [64.3839],\n",
      "        [64.3839],\n",
      "        [64.3838],\n",
      "        [64.3838],\n",
      "        [64.3838],\n",
      "        [64.3838],\n",
      "        [64.3838],\n",
      "        [64.3838]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4762],\n",
      "        [64.4762],\n",
      "        [64.4762],\n",
      "        [64.4761],\n",
      "        [64.4762],\n",
      "        [64.4762],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761],\n",
      "        [64.4761]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.5615],\n",
      "        [64.5615],\n",
      "        [64.5615],\n",
      "        [64.5615],\n",
      "        [64.5615],\n",
      "        [64.5615],\n",
      "        [64.5615],\n",
      "        [64.5616],\n",
      "        [64.5615],\n",
      "        [64.5616],\n",
      "        [64.5616],\n",
      "        [64.5616],\n",
      "        [64.5616],\n",
      "        [64.5616],\n",
      "        [64.5616],\n",
      "        [64.5616],\n",
      "        [64.5616],\n",
      "        [64.5615],\n",
      "        [64.5615],\n",
      "        [64.5615],\n",
      "        [64.5615],\n",
      "        [64.5615],\n",
      "        [64.5615],\n",
      "        [64.5615]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6489],\n",
      "        [64.6489],\n",
      "        [64.6489],\n",
      "        [64.6489],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488],\n",
      "        [64.6488]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7373],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372],\n",
      "        [64.7372]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257],\n",
      "        [64.8257]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099],\n",
      "        [64.9099]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[64.9921],\n",
      "        [64.9920],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921],\n",
      "        [64.9921]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715],\n",
      "        [65.0715]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.1423],\n",
      "        [65.1423],\n",
      "        [65.1423],\n",
      "        [65.1423],\n",
      "        [65.1423],\n",
      "        [65.1423],\n",
      "        [65.1423],\n",
      "        [65.1423],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1424],\n",
      "        [65.1423],\n",
      "        [65.1424]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145],\n",
      "        [65.2145]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798],\n",
      "        [65.2798]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488],\n",
      "        [65.3488]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4143],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144],\n",
      "        [65.4144]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742],\n",
      "        [65.4742]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299],\n",
      "        [65.5299]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826],\n",
      "        [65.5826]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.6313],\n",
      "        [65.6313],\n",
      "        [65.6313],\n",
      "        [65.6313],\n",
      "        [65.6313],\n",
      "        [65.6313],\n",
      "        [65.6313],\n",
      "        [65.6313],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6314],\n",
      "        [65.6313],\n",
      "        [65.6313],\n",
      "        [65.6313],\n",
      "        [65.6313]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787],\n",
      "        [65.6787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7187],\n",
      "        [65.7186],\n",
      "        [65.7187],\n",
      "        [65.7186],\n",
      "        [65.7186]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7469],\n",
      "        [65.7470],\n",
      "        [65.7470],\n",
      "        [65.7470],\n",
      "        [65.7470],\n",
      "        [65.7470],\n",
      "        [65.7470],\n",
      "        [65.7470]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.7722],\n",
      "        [65.7722],\n",
      "        [65.7722],\n",
      "        [65.7722],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7721],\n",
      "        [65.7722],\n",
      "        [65.7722],\n",
      "        [65.7722],\n",
      "        [65.7722],\n",
      "        [65.7722]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7966],\n",
      "        [65.7966],\n",
      "        [65.7966],\n",
      "        [65.7967],\n",
      "        [65.7966],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967],\n",
      "        [65.7967]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.8224],\n",
      "        [65.8224],\n",
      "        [65.8224],\n",
      "        [65.8224],\n",
      "        [65.8224],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8223],\n",
      "        [65.8224],\n",
      "        [65.8223],\n",
      "        [65.8224],\n",
      "        [65.8224],\n",
      "        [65.8224],\n",
      "        [65.8224]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8532],\n",
      "        [65.8533],\n",
      "        [65.8533],\n",
      "        [65.8533],\n",
      "        [65.8533]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8895],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8895],\n",
      "        [65.8895],\n",
      "        [65.8895],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896],\n",
      "        [65.8896]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9243],\n",
      "        [65.9243],\n",
      "        [65.9243],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9243],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244],\n",
      "        [65.9244]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9578],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579],\n",
      "        [65.9579]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[65.9872],\n",
      "        [65.9872],\n",
      "        [65.9872],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9871],\n",
      "        [65.9872]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170],\n",
      "        [66.0170]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0468],\n",
      "        [66.0468],\n",
      "        [66.0468],\n",
      "        [66.0468],\n",
      "        [66.0468],\n",
      "        [66.0468],\n",
      "        [66.0468],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469],\n",
      "        [66.0469]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817],\n",
      "        [66.0817]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.1238],\n",
      "        [66.1238],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1237],\n",
      "        [66.1238],\n",
      "        [66.1238],\n",
      "        [66.1238],\n",
      "        [66.1238]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716],\n",
      "        [66.1716]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189],\n",
      "        [66.2189]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646],\n",
      "        [66.2646]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3118],\n",
      "        [66.3118],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3118],\n",
      "        [66.3119],\n",
      "        [66.3118],\n",
      "        [66.3118],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119],\n",
      "        [66.3119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619],\n",
      "        [66.3619]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4165],\n",
      "        [66.4165],\n",
      "        [66.4165],\n",
      "        [66.4165],\n",
      "        [66.4165],\n",
      "        [66.4165],\n",
      "        [66.4165],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166],\n",
      "        [66.4166]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759],\n",
      "        [66.4759]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383],\n",
      "        [66.5383]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6036],\n",
      "        [66.6037],\n",
      "        [66.6037],\n",
      "        [66.6037],\n",
      "        [66.6037],\n",
      "        [66.6037]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6696],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6696],\n",
      "        [66.6696],\n",
      "        [66.6696],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697],\n",
      "        [66.6697]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.7369],\n",
      "        [66.7370],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7369],\n",
      "        [66.7370],\n",
      "        [66.7370],\n",
      "        [66.7370]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8065],\n",
      "        [66.8065],\n",
      "        [66.8066],\n",
      "        [66.8065],\n",
      "        [66.8065],\n",
      "        [66.8065],\n",
      "        [66.8065],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066],\n",
      "        [66.8066]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791],\n",
      "        [66.8791]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541],\n",
      "        [66.9541]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.0311],\n",
      "        [67.0312],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0311],\n",
      "        [67.0312],\n",
      "        [67.0312],\n",
      "        [67.0312],\n",
      "        [67.0312]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093],\n",
      "        [67.1093]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865],\n",
      "        [67.1865]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.2647],\n",
      "        [67.2647],\n",
      "        [67.2647],\n",
      "        [67.2647],\n",
      "        [67.2647],\n",
      "        [67.2647],\n",
      "        [67.2646],\n",
      "        [67.2646],\n",
      "        [67.2646],\n",
      "        [67.2646],\n",
      "        [67.2646],\n",
      "        [67.2646],\n",
      "        [67.2646],\n",
      "        [67.2646],\n",
      "        [67.2646],\n",
      "        [67.2646],\n",
      "        [67.2647],\n",
      "        [67.2647],\n",
      "        [67.2647],\n",
      "        [67.2647],\n",
      "        [67.2647],\n",
      "        [67.2647],\n",
      "        [67.2647],\n",
      "        [67.2647]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450],\n",
      "        [67.3450]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270],\n",
      "        [67.4270]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100],\n",
      "        [67.5100]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941],\n",
      "        [67.5941]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792],\n",
      "        [67.6792]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634],\n",
      "        [67.7634]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478],\n",
      "        [67.8478]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331],\n",
      "        [67.9331]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.0196],\n",
      "        [68.0196],\n",
      "        [68.0196],\n",
      "        [68.0196],\n",
      "        [68.0195],\n",
      "        [68.0195],\n",
      "        [68.0195],\n",
      "        [68.0195],\n",
      "        [68.0195],\n",
      "        [68.0195],\n",
      "        [68.0195],\n",
      "        [68.0195],\n",
      "        [68.0195],\n",
      "        [68.0195],\n",
      "        [68.0195],\n",
      "        [68.0196],\n",
      "        [68.0196],\n",
      "        [68.0196],\n",
      "        [68.0196],\n",
      "        [68.0196],\n",
      "        [68.0196],\n",
      "        [68.0196],\n",
      "        [68.0196],\n",
      "        [68.0196]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.1070],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1070],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1069],\n",
      "        [68.1070],\n",
      "        [68.1070],\n",
      "        [68.1070],\n",
      "        [68.1070],\n",
      "        [68.1070],\n",
      "        [68.1070]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946],\n",
      "        [68.1946]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823],\n",
      "        [68.2823]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.3691],\n",
      "        [68.3691],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3690],\n",
      "        [68.3691],\n",
      "        [68.3691],\n",
      "        [68.3691],\n",
      "        [68.3691],\n",
      "        [68.3691],\n",
      "        [68.3691],\n",
      "        [68.3691],\n",
      "        [68.3691],\n",
      "        [68.3691]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563],\n",
      "        [68.4563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447],\n",
      "        [68.5447]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331],\n",
      "        [68.6331]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216],\n",
      "        [68.7216]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.8107],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8106],\n",
      "        [68.8107],\n",
      "        [68.8107],\n",
      "        [68.8107],\n",
      "        [68.8107],\n",
      "        [68.8107],\n",
      "        [68.8107],\n",
      "        [68.8107],\n",
      "        [68.8107]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003],\n",
      "        [68.9003]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896],\n",
      "        [68.9896]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792],\n",
      "        [69.0792]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697],\n",
      "        [69.1697]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610],\n",
      "        [69.2610]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531],\n",
      "        [69.3531]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464],\n",
      "        [69.4464]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402],\n",
      "        [69.5402]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326],\n",
      "        [69.6326]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248],\n",
      "        [69.7248]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171],\n",
      "        [69.8171]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092],\n",
      "        [69.9092]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018],\n",
      "        [70.0018]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955],\n",
      "        [70.0955]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892],\n",
      "        [70.1892]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825],\n",
      "        [70.2825]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754],\n",
      "        [70.3754]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692],\n",
      "        [70.4692]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.5634],\n",
      "        [70.5634],\n",
      "        [70.5634],\n",
      "        [70.5634],\n",
      "        [70.5634],\n",
      "        [70.5633],\n",
      "        [70.5633],\n",
      "        [70.5634],\n",
      "        [70.5633],\n",
      "        [70.5633],\n",
      "        [70.5633],\n",
      "        [70.5633],\n",
      "        [70.5633],\n",
      "        [70.5633],\n",
      "        [70.5633],\n",
      "        [70.5633],\n",
      "        [70.5634],\n",
      "        [70.5634],\n",
      "        [70.5634],\n",
      "        [70.5634],\n",
      "        [70.5634],\n",
      "        [70.5634],\n",
      "        [70.5634],\n",
      "        [70.5634]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6580],\n",
      "        [70.6581],\n",
      "        [70.6581],\n",
      "        [70.6581],\n",
      "        [70.6581],\n",
      "        [70.6581],\n",
      "        [70.6581],\n",
      "        [70.6581],\n",
      "        [70.6581]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538],\n",
      "        [70.7538]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496],\n",
      "        [70.8496]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447],\n",
      "        [70.9447]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395],\n",
      "        [71.0395]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345],\n",
      "        [71.1345]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300],\n",
      "        [71.2300]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262],\n",
      "        [71.3262]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245],\n",
      "        [71.4245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239],\n",
      "        [71.5239]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242],\n",
      "        [71.6242]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260],\n",
      "        [71.7260]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306],\n",
      "        [71.8306]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374],\n",
      "        [71.9374]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[72.0470],\n",
      "        [72.0471],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0470],\n",
      "        [72.0471],\n",
      "        [72.0471],\n",
      "        [72.0471],\n",
      "        [72.0471],\n",
      "        [72.0471],\n",
      "        [72.0471],\n",
      "        [72.0471],\n",
      "        [72.0471]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1584],\n",
      "        [72.1584],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1584],\n",
      "        [72.1584],\n",
      "        [72.1584],\n",
      "        [72.1584],\n",
      "        [72.1584],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585],\n",
      "        [72.1585]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709],\n",
      "        [72.2709]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830],\n",
      "        [72.3830]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963],\n",
      "        [72.4963]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119],\n",
      "        [72.6119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286],\n",
      "        [72.7286]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464],\n",
      "        [72.8464]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641],\n",
      "        [72.9641]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817],\n",
      "        [73.0817]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982],\n",
      "        [73.1982]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144],\n",
      "        [73.3144]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319],\n",
      "        [73.4319]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496],\n",
      "        [73.5496]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672],\n",
      "        [73.6672]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847],\n",
      "        [73.7847]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[73.9007],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9006],\n",
      "        [73.9007],\n",
      "        [73.9007],\n",
      "        [73.9007],\n",
      "        [73.9007],\n",
      "        [73.9007],\n",
      "        [73.9007],\n",
      "        [73.9007],\n",
      "        [73.9007],\n",
      "        [73.9007]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150],\n",
      "        [74.0150]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289],\n",
      "        [74.1289]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430],\n",
      "        [74.2430]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563],\n",
      "        [74.3563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677],\n",
      "        [74.4677]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776],\n",
      "        [74.5776]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865],\n",
      "        [74.6865]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938],\n",
      "        [74.7938]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9012],\n",
      "        [74.9013],\n",
      "        [74.9013],\n",
      "        [74.9013],\n",
      "        [74.9013],\n",
      "        [74.9013],\n",
      "        [74.9013],\n",
      "        [74.9013]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0086],\n",
      "        [75.0087],\n",
      "        [75.0087],\n",
      "        [75.0087],\n",
      "        [75.0087],\n",
      "        [75.0087],\n",
      "        [75.0086],\n",
      "        [75.0086]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155],\n",
      "        [75.1155]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217],\n",
      "        [75.2217]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278],\n",
      "        [75.3278]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343],\n",
      "        [75.4343]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402],\n",
      "        [75.5402]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462],\n",
      "        [75.6462]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535],\n",
      "        [75.7535]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617],\n",
      "        [75.8617]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713],\n",
      "        [75.9713]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823],\n",
      "        [76.0823]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941],\n",
      "        [76.1941]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3043],\n",
      "        [76.3043],\n",
      "        [76.3043],\n",
      "        [76.3042],\n",
      "        [76.3042],\n",
      "        [76.3042]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120],\n",
      "        [76.4120]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5162],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163],\n",
      "        [76.5163]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201],\n",
      "        [76.6201]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238],\n",
      "        [76.7238]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277],\n",
      "        [76.8277]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314],\n",
      "        [76.9314]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347],\n",
      "        [77.0347]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381],\n",
      "        [77.1381]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415],\n",
      "        [77.2415]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463],\n",
      "        [77.3463]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504],\n",
      "        [77.4504]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[77.5542],\n",
      "        [77.5542],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5541],\n",
      "        [77.5542],\n",
      "        [77.5542],\n",
      "        [77.5542],\n",
      "        [77.5542],\n",
      "        [77.5542],\n",
      "        [77.5542],\n",
      "        [77.5542],\n",
      "        [77.5542],\n",
      "        [77.5542],\n",
      "        [77.5542]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561],\n",
      "        [77.6561]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543],\n",
      "        [77.7543]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502],\n",
      "        [77.8502]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450],\n",
      "        [77.9450]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379],\n",
      "        [78.0379]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282],\n",
      "        [78.1282]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145],\n",
      "        [78.2145]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964],\n",
      "        [78.2964]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722],\n",
      "        [78.3722]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461],\n",
      "        [78.4461]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5200],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5200],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199],\n",
      "        [78.5199]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934],\n",
      "        [78.5934]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661],\n",
      "        [78.6661]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393],\n",
      "        [78.7393]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8104],\n",
      "        [78.8104],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103],\n",
      "        [78.8103]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775],\n",
      "        [78.8775]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444],\n",
      "        [78.9444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126],\n",
      "        [79.0126]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826],\n",
      "        [79.0826]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542],\n",
      "        [79.1542]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238],\n",
      "        [79.2238]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895],\n",
      "        [79.2895]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.3549],\n",
      "        [79.3549],\n",
      "        [79.3549],\n",
      "        [79.3549],\n",
      "        [79.3549],\n",
      "        [79.3549],\n",
      "        [79.3549]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [3/10], Loss: 5405.0052\n",
      "outputs: tensor([[79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248],\n",
      "        [79.4248]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4970],\n",
      "        [79.4970],\n",
      "        [79.4970],\n",
      "        [79.4970],\n",
      "        [79.4970],\n",
      "        [79.4970],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4970],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971],\n",
      "        [79.4971]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748],\n",
      "        [79.5748]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556],\n",
      "        [79.6556]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417],\n",
      "        [79.7417]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281],\n",
      "        [79.8281]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9145],\n",
      "        [79.9144]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[79.9972],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9972],\n",
      "        [79.9972],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9972],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9973],\n",
      "        [79.9972],\n",
      "        [79.9972],\n",
      "        [79.9972],\n",
      "        [79.9972],\n",
      "        [79.9972]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0808],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0808],\n",
      "        [80.0808],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807],\n",
      "        [80.0807]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1674],\n",
      "        [80.1674],\n",
      "        [80.1674],\n",
      "        [80.1674],\n",
      "        [80.1674],\n",
      "        [80.1674],\n",
      "        [80.1674],\n",
      "        [80.1674],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673],\n",
      "        [80.1673]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[80.2574],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2574],\n",
      "        [80.2574],\n",
      "        [80.2574],\n",
      "        [80.2574],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2574],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2575],\n",
      "        [80.2574],\n",
      "        [80.2575]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[80.3488],\n",
      "        [80.3488],\n",
      "        [80.3487],\n",
      "        [80.3488],\n",
      "        [80.3487],\n",
      "        [80.3487],\n",
      "        [80.3487],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488],\n",
      "        [80.3488]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4426],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425],\n",
      "        [80.4425]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388],\n",
      "        [80.5388]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6347],\n",
      "        [80.6347],\n",
      "        [80.6347],\n",
      "        [80.6347],\n",
      "        [80.6347],\n",
      "        [80.6347],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346],\n",
      "        [80.6346]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[80.7295],\n",
      "        [80.7295],\n",
      "        [80.7295],\n",
      "        [80.7295],\n",
      "        [80.7295],\n",
      "        [80.7295],\n",
      "        [80.7295],\n",
      "        [80.7295],\n",
      "        [80.7296],\n",
      "        [80.7295],\n",
      "        [80.7296],\n",
      "        [80.7296],\n",
      "        [80.7296],\n",
      "        [80.7296],\n",
      "        [80.7296],\n",
      "        [80.7296],\n",
      "        [80.7295],\n",
      "        [80.7295],\n",
      "        [80.7296],\n",
      "        [80.7296],\n",
      "        [80.7295],\n",
      "        [80.7296],\n",
      "        [80.7296],\n",
      "        [80.7296]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249],\n",
      "        [80.8249]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9192],\n",
      "        [80.9191],\n",
      "        [80.9192],\n",
      "        [80.9191],\n",
      "        [80.9191]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.0027],\n",
      "        [81.0027],\n",
      "        [81.0026],\n",
      "        [81.0026],\n",
      "        [81.0026],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027],\n",
      "        [81.0027]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885],\n",
      "        [81.0885]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713],\n",
      "        [81.1713]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557],\n",
      "        [81.2557]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376],\n",
      "        [81.3376]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.4220],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4220],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4220],\n",
      "        [81.4220],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4221],\n",
      "        [81.4220],\n",
      "        [81.4220],\n",
      "        [81.4220],\n",
      "        [81.4220],\n",
      "        [81.4220]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114],\n",
      "        [81.5114]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.6020],\n",
      "        [81.6020],\n",
      "        [81.6020],\n",
      "        [81.6020],\n",
      "        [81.6020],\n",
      "        [81.6020],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6021],\n",
      "        [81.6020],\n",
      "        [81.6020],\n",
      "        [81.6020],\n",
      "        [81.6020],\n",
      "        [81.6020]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947],\n",
      "        [81.6947]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797],\n",
      "        [81.7797]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8612],\n",
      "        [81.8612],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611],\n",
      "        [81.8611]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470],\n",
      "        [81.9470]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298],\n",
      "        [82.0298]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156],\n",
      "        [82.1156]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.2045],\n",
      "        [82.2044],\n",
      "        [82.2045],\n",
      "        [82.2044],\n",
      "        [82.2044],\n",
      "        [82.2044],\n",
      "        [82.2044],\n",
      "        [82.2044],\n",
      "        [82.2044],\n",
      "        [82.2044],\n",
      "        [82.2044],\n",
      "        [82.2045],\n",
      "        [82.2045],\n",
      "        [82.2044],\n",
      "        [82.2045],\n",
      "        [82.2045],\n",
      "        [82.2045],\n",
      "        [82.2045],\n",
      "        [82.2045],\n",
      "        [82.2045],\n",
      "        [82.2045],\n",
      "        [82.2045],\n",
      "        [82.2044],\n",
      "        [82.2044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.2961],\n",
      "        [82.2961],\n",
      "        [82.2961],\n",
      "        [82.2961],\n",
      "        [82.2961],\n",
      "        [82.2961],\n",
      "        [82.2961],\n",
      "        [82.2962],\n",
      "        [82.2962],\n",
      "        [82.2962],\n",
      "        [82.2962],\n",
      "        [82.2962],\n",
      "        [82.2962],\n",
      "        [82.2962],\n",
      "        [82.2962],\n",
      "        [82.2962],\n",
      "        [82.2962],\n",
      "        [82.2961],\n",
      "        [82.2961],\n",
      "        [82.2961],\n",
      "        [82.2961],\n",
      "        [82.2961],\n",
      "        [82.2961],\n",
      "        [82.2961]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.3888],\n",
      "        [82.3888],\n",
      "        [82.3887],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3888],\n",
      "        [82.3887],\n",
      "        [82.3888]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.4827],\n",
      "        [82.4827],\n",
      "        [82.4827],\n",
      "        [82.4827],\n",
      "        [82.4827],\n",
      "        [82.4827],\n",
      "        [82.4827],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4828],\n",
      "        [82.4827],\n",
      "        [82.4827],\n",
      "        [82.4827],\n",
      "        [82.4827],\n",
      "        [82.4827]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777],\n",
      "        [82.5777]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6739],\n",
      "        [82.6739],\n",
      "        [82.6739],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738],\n",
      "        [82.6738]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7682],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681],\n",
      "        [82.7681]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600],\n",
      "        [82.8600]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505],\n",
      "        [82.9505]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.0385],\n",
      "        [83.0384],\n",
      "        [83.0384],\n",
      "        [83.0384],\n",
      "        [83.0384],\n",
      "        [83.0385],\n",
      "        [83.0384],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385],\n",
      "        [83.0385]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224],\n",
      "        [83.1224]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2022],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2023],\n",
      "        [83.2022],\n",
      "        [83.2023],\n",
      "        [83.2023]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853],\n",
      "        [83.2853]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690],\n",
      "        [83.3690]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.4519],\n",
      "        [83.4518],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4518],\n",
      "        [83.4518],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4519],\n",
      "        [83.4518]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313],\n",
      "        [83.5313]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059],\n",
      "        [83.6059]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815],\n",
      "        [83.6815]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574],\n",
      "        [83.7574]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351],\n",
      "        [83.8351]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149],\n",
      "        [83.9149]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909],\n",
      "        [83.9909]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0639],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640],\n",
      "        [84.0640]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1391],\n",
      "        [84.1391],\n",
      "        [84.1391],\n",
      "        [84.1391],\n",
      "        [84.1391],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390],\n",
      "        [84.1390]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.2120],\n",
      "        [84.2120],\n",
      "        [84.2120],\n",
      "        [84.2120],\n",
      "        [84.2120],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121],\n",
      "        [84.2121]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772],\n",
      "        [84.2772]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3446],\n",
      "        [84.3446],\n",
      "        [84.3446],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445],\n",
      "        [84.3445]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131],\n",
      "        [84.4131]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4819],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818],\n",
      "        [84.4818]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456],\n",
      "        [84.5456]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071],\n",
      "        [84.6071]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655],\n",
      "        [84.6655]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140],\n",
      "        [84.7140]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.7641],\n",
      "        [84.7641],\n",
      "        [84.7640],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7641],\n",
      "        [84.7640]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.8062],\n",
      "        [84.8062],\n",
      "        [84.8062],\n",
      "        [84.8062],\n",
      "        [84.8062],\n",
      "        [84.8062],\n",
      "        [84.8063],\n",
      "        [84.8062],\n",
      "        [84.8063],\n",
      "        [84.8063],\n",
      "        [84.8063],\n",
      "        [84.8063],\n",
      "        [84.8063],\n",
      "        [84.8063],\n",
      "        [84.8063],\n",
      "        [84.8063],\n",
      "        [84.8063],\n",
      "        [84.8062],\n",
      "        [84.8062],\n",
      "        [84.8062],\n",
      "        [84.8062],\n",
      "        [84.8062],\n",
      "        [84.8062],\n",
      "        [84.8062]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527],\n",
      "        [84.8527]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952],\n",
      "        [84.8952]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311],\n",
      "        [84.9311]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624],\n",
      "        [84.9624]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902],\n",
      "        [84.9902]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135],\n",
      "        [85.0135]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352],\n",
      "        [85.0352]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0485],\n",
      "        [85.0486],\n",
      "        [85.0486],\n",
      "        [85.0486],\n",
      "        [85.0486],\n",
      "        [85.0486],\n",
      "        [85.0486],\n",
      "        [85.0486]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0450],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0450],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451],\n",
      "        [85.0451]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408],\n",
      "        [85.0408]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379],\n",
      "        [85.0379]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409],\n",
      "        [85.0409]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501],\n",
      "        [85.0501]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0575],\n",
      "        [85.0575],\n",
      "        [85.0575],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0575],\n",
      "        [85.0575],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576],\n",
      "        [85.0576]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0636],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0635],\n",
      "        [85.0635],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0635],\n",
      "        [85.0636],\n",
      "        [85.0635],\n",
      "        [85.0635],\n",
      "        [85.0635],\n",
      "        [85.0635],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0636],\n",
      "        [85.0636]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0647],\n",
      "        [85.0647],\n",
      "        [85.0647],\n",
      "        [85.0647],\n",
      "        [85.0647],\n",
      "        [85.0647],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648],\n",
      "        [85.0648]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666],\n",
      "        [85.0666]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685],\n",
      "        [85.0685]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761],\n",
      "        [85.0761]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918],\n",
      "        [85.0918]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142],\n",
      "        [85.1142]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359],\n",
      "        [85.1359]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559],\n",
      "        [85.1559]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776],\n",
      "        [85.1776]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2025],\n",
      "        [85.2025],\n",
      "        [85.2025],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026],\n",
      "        [85.2026]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327],\n",
      "        [85.2327]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682],\n",
      "        [85.2682]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072],\n",
      "        [85.3072]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496],\n",
      "        [85.3496]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927],\n",
      "        [85.3927]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373],\n",
      "        [85.4373]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846],\n",
      "        [85.4846]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352],\n",
      "        [85.5352]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5886],\n",
      "        [85.5887],\n",
      "        [85.5886],\n",
      "        [85.5886],\n",
      "        [85.5886],\n",
      "        [85.5886],\n",
      "        [85.5886],\n",
      "        [85.5886],\n",
      "        [85.5886],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887],\n",
      "        [85.5887]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444],\n",
      "        [85.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015],\n",
      "        [85.7015]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575],\n",
      "        [85.7575]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145],\n",
      "        [85.8145]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742],\n",
      "        [85.8742]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357],\n",
      "        [85.9357]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983],\n",
      "        [85.9983]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0622],\n",
      "        [86.0623],\n",
      "        [86.0622],\n",
      "        [86.0622]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273],\n",
      "        [86.1273]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913],\n",
      "        [86.1913]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557],\n",
      "        [86.2557]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211],\n",
      "        [86.3211]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.3878],\n",
      "        [86.3878],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3877],\n",
      "        [86.3878],\n",
      "        [86.3878],\n",
      "        [86.3878],\n",
      "        [86.3878],\n",
      "        [86.3878],\n",
      "        [86.3878],\n",
      "        [86.3878]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555],\n",
      "        [86.4555]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236],\n",
      "        [86.5236]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918],\n",
      "        [86.5918]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589],\n",
      "        [86.6589]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266],\n",
      "        [86.7266]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956],\n",
      "        [86.7956]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646],\n",
      "        [86.8646]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337],\n",
      "        [86.9337]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036],\n",
      "        [87.0036]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741],\n",
      "        [87.0741]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442],\n",
      "        [87.1442]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146],\n",
      "        [87.2146]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862],\n",
      "        [87.2862]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.3587],\n",
      "        [87.3586],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3586],\n",
      "        [87.3587],\n",
      "        [87.3586],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587],\n",
      "        [87.3587]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321],\n",
      "        [87.4321]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069],\n",
      "        [87.5069]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823],\n",
      "        [87.5823]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560],\n",
      "        [87.6560]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7295],\n",
      "        [87.7296],\n",
      "        [87.7296],\n",
      "        [87.7296],\n",
      "        [87.7296],\n",
      "        [87.7296]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033],\n",
      "        [87.8033]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768],\n",
      "        [87.8768]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509],\n",
      "        [87.9509]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263],\n",
      "        [88.0263]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1016],\n",
      "        [88.1017],\n",
      "        [88.1017],\n",
      "        [88.1016],\n",
      "        [88.1017],\n",
      "        [88.1016]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765],\n",
      "        [88.1765]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511],\n",
      "        [88.2511]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266],\n",
      "        [88.3266]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026],\n",
      "        [88.4026]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792],\n",
      "        [88.4792]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571],\n",
      "        [88.5571]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349],\n",
      "        [88.6349]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121],\n",
      "        [88.7121]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889],\n",
      "        [88.7889]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660],\n",
      "        [88.8660]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436],\n",
      "        [88.9436]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221],\n",
      "        [89.0221]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030],\n",
      "        [89.1030]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852],\n",
      "        [89.1852]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684],\n",
      "        [89.2684]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534],\n",
      "        [89.3534]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415],\n",
      "        [89.4415]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322],\n",
      "        [89.5322]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263],\n",
      "        [89.6263]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223],\n",
      "        [89.7223]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196],\n",
      "        [89.8196]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165],\n",
      "        [89.9165]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148],\n",
      "        [90.0148]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158],\n",
      "        [90.1158]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181],\n",
      "        [90.2181]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217],\n",
      "        [90.3217]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251],\n",
      "        [90.4251]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286],\n",
      "        [90.5286]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307],\n",
      "        [90.6307]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326],\n",
      "        [90.7326]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360],\n",
      "        [90.8360]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396],\n",
      "        [90.9396]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432],\n",
      "        [91.0432]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1466],\n",
      "        [91.1467],\n",
      "        [91.1466],\n",
      "        [91.1466],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1466],\n",
      "        [91.1467],\n",
      "        [91.1466],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467],\n",
      "        [91.1467]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484],\n",
      "        [91.2484]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483],\n",
      "        [91.3483]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477],\n",
      "        [91.4477]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474],\n",
      "        [91.5474]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463],\n",
      "        [91.6463]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429],\n",
      "        [91.7429]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379],\n",
      "        [91.8379]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9316],\n",
      "        [91.9316],\n",
      "        [91.9316],\n",
      "        [91.9316],\n",
      "        [91.9316],\n",
      "        [91.9316],\n",
      "        [91.9316],\n",
      "        [91.9316],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317],\n",
      "        [91.9317]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237],\n",
      "        [92.0237]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159],\n",
      "        [92.1159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081],\n",
      "        [92.2081]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997],\n",
      "        [92.2997]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905],\n",
      "        [92.3905]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4812],\n",
      "        [92.4812],\n",
      "        [92.4812],\n",
      "        [92.4812],\n",
      "        [92.4812],\n",
      "        [92.4812],\n",
      "        [92.4812],\n",
      "        [92.4812],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813],\n",
      "        [92.4813]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725],\n",
      "        [92.5725]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631],\n",
      "        [92.6631]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7539],\n",
      "        [92.7539],\n",
      "        [92.7539],\n",
      "        [92.7539],\n",
      "        [92.7538],\n",
      "        [92.7538],\n",
      "        [92.7538]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460],\n",
      "        [92.8460]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393],\n",
      "        [92.9393]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342],\n",
      "        [93.0342]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307],\n",
      "        [93.1307]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282],\n",
      "        [93.2282]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3238],\n",
      "        [93.3239],\n",
      "        [93.3239],\n",
      "        [93.3239],\n",
      "        [93.3239],\n",
      "        [93.3239],\n",
      "        [93.3239],\n",
      "        [93.3239],\n",
      "        [93.3238]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168],\n",
      "        [93.4168]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056],\n",
      "        [93.5056]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941],\n",
      "        [93.5941]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824],\n",
      "        [93.6824]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710],\n",
      "        [93.7710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593],\n",
      "        [93.8593]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472],\n",
      "        [93.9472]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353],\n",
      "        [94.0353]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233],\n",
      "        [94.1233]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130],\n",
      "        [94.2130]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019],\n",
      "        [94.3019]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3904],\n",
      "        [94.3905],\n",
      "        [94.3905],\n",
      "        [94.3905],\n",
      "        [94.3905],\n",
      "        [94.3904],\n",
      "        [94.3904]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769],\n",
      "        [94.4769]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591],\n",
      "        [94.5591]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387],\n",
      "        [94.6387]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170],\n",
      "        [94.7170]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932],\n",
      "        [94.7932]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664],\n",
      "        [94.8664]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350],\n",
      "        [94.9350]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986],\n",
      "        [94.9986]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552],\n",
      "        [95.0552]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096],\n",
      "        [95.1096]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640],\n",
      "        [95.1640]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180],\n",
      "        [95.2180]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711],\n",
      "        [95.2711]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247],\n",
      "        [95.3247]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3759],\n",
      "        [95.3760],\n",
      "        [95.3760],\n",
      "        [95.3760],\n",
      "        [95.3760],\n",
      "        [95.3760],\n",
      "        [95.3760],\n",
      "        [95.3760],\n",
      "        [95.3760],\n",
      "        [95.3760]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227],\n",
      "        [95.4227]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4692],\n",
      "        [95.4692],\n",
      "        [95.4692],\n",
      "        [95.4692],\n",
      "        [95.4692],\n",
      "        [95.4692],\n",
      "        [95.4692],\n",
      "        [95.4692],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693],\n",
      "        [95.4693]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172],\n",
      "        [95.5172]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673],\n",
      "        [95.5673]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191],\n",
      "        [95.6191]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688],\n",
      "        [95.6688]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.7140],\n",
      "        [95.7140],\n",
      "        [95.7140],\n",
      "        [95.7140],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7139],\n",
      "        [95.7140],\n",
      "        [95.7140],\n",
      "        [95.7140],\n",
      "        [95.7140],\n",
      "        [95.7140],\n",
      "        [95.7140],\n",
      "        [95.7140],\n",
      "        [95.7140]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.7588],\n",
      "        [95.7588],\n",
      "        [95.7588],\n",
      "        [95.7588],\n",
      "        [95.7588],\n",
      "        [95.7588],\n",
      "        [95.7588]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [4/10], Loss: 3527.1831\n",
      "outputs: tensor([[95.8089],\n",
      "        [95.8088],\n",
      "        [95.8088],\n",
      "        [95.8088],\n",
      "        [95.8088],\n",
      "        [95.8089],\n",
      "        [95.8088],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8089],\n",
      "        [95.8088],\n",
      "        [95.8088],\n",
      "        [95.8088]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8615],\n",
      "        [95.8615],\n",
      "        [95.8615],\n",
      "        [95.8615],\n",
      "        [95.8615],\n",
      "        [95.8615],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8615],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616],\n",
      "        [95.8616]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206],\n",
      "        [95.9206]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831],\n",
      "        [95.9831]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518],\n",
      "        [96.0518]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.1207],\n",
      "        [96.1207],\n",
      "        [96.1207],\n",
      "        [96.1207],\n",
      "        [96.1207],\n",
      "        [96.1207],\n",
      "        [96.1207],\n",
      "        [96.1207],\n",
      "        [96.1207],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1207],\n",
      "        [96.1208],\n",
      "        [96.1208],\n",
      "        [96.1208]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898],\n",
      "        [96.1898]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547],\n",
      "        [96.2547]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204],\n",
      "        [96.3204]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897],\n",
      "        [96.3897]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631],\n",
      "        [96.4631]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.5378],\n",
      "        [96.5378],\n",
      "        [96.5378],\n",
      "        [96.5378],\n",
      "        [96.5378],\n",
      "        [96.5378],\n",
      "        [96.5378],\n",
      "        [96.5378],\n",
      "        [96.5378],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5379],\n",
      "        [96.5378]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6155],\n",
      "        [96.6155],\n",
      "        [96.6155],\n",
      "        [96.6155],\n",
      "        [96.6155],\n",
      "        [96.6155],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154],\n",
      "        [96.6154]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.6959],\n",
      "        [96.6959],\n",
      "        [96.6959],\n",
      "        [96.6959],\n",
      "        [96.6959],\n",
      "        [96.6960],\n",
      "        [96.6959],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6959],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960],\n",
      "        [96.6960]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7760],\n",
      "        [96.7759],\n",
      "        [96.7760]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.8549],\n",
      "        [96.8549],\n",
      "        [96.8549],\n",
      "        [96.8549],\n",
      "        [96.8549],\n",
      "        [96.8549],\n",
      "        [96.8549],\n",
      "        [96.8549],\n",
      "        [96.8550],\n",
      "        [96.8549],\n",
      "        [96.8550],\n",
      "        [96.8550],\n",
      "        [96.8550],\n",
      "        [96.8550],\n",
      "        [96.8550],\n",
      "        [96.8550],\n",
      "        [96.8549],\n",
      "        [96.8549],\n",
      "        [96.8550],\n",
      "        [96.8549],\n",
      "        [96.8549],\n",
      "        [96.8549],\n",
      "        [96.8549],\n",
      "        [96.8550]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345],\n",
      "        [96.9345]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127],\n",
      "        [97.0127]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787],\n",
      "        [97.0787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.1474],\n",
      "        [97.1473],\n",
      "        [97.1473],\n",
      "        [97.1473],\n",
      "        [97.1473],\n",
      "        [97.1473],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474],\n",
      "        [97.1474]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125],\n",
      "        [97.2125]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796],\n",
      "        [97.2796]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3437],\n",
      "        [97.3437],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3438],\n",
      "        [97.3437],\n",
      "        [97.3437],\n",
      "        [97.3438]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109],\n",
      "        [97.4109]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.4837],\n",
      "        [97.4836],\n",
      "        [97.4836],\n",
      "        [97.4836],\n",
      "        [97.4836],\n",
      "        [97.4836],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837],\n",
      "        [97.4837]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.5579],\n",
      "        [97.5579],\n",
      "        [97.5579],\n",
      "        [97.5579],\n",
      "        [97.5579],\n",
      "        [97.5579],\n",
      "        [97.5580],\n",
      "        [97.5579],\n",
      "        [97.5579],\n",
      "        [97.5580],\n",
      "        [97.5580],\n",
      "        [97.5580],\n",
      "        [97.5580],\n",
      "        [97.5580],\n",
      "        [97.5580],\n",
      "        [97.5580],\n",
      "        [97.5580],\n",
      "        [97.5580],\n",
      "        [97.5579],\n",
      "        [97.5579],\n",
      "        [97.5579],\n",
      "        [97.5579],\n",
      "        [97.5579],\n",
      "        [97.5579]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.6345],\n",
      "        [97.6345],\n",
      "        [97.6345],\n",
      "        [97.6345],\n",
      "        [97.6345],\n",
      "        [97.6345],\n",
      "        [97.6345],\n",
      "        [97.6345],\n",
      "        [97.6346],\n",
      "        [97.6346],\n",
      "        [97.6346],\n",
      "        [97.6346],\n",
      "        [97.6346],\n",
      "        [97.6346],\n",
      "        [97.6346],\n",
      "        [97.6346],\n",
      "        [97.6346],\n",
      "        [97.6346],\n",
      "        [97.6345],\n",
      "        [97.6345],\n",
      "        [97.6345],\n",
      "        [97.6345],\n",
      "        [97.6345],\n",
      "        [97.6345]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024],\n",
      "        [97.7024]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7661],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662],\n",
      "        [97.7662]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350],\n",
      "        [97.8350]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004],\n",
      "        [97.9004]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692],\n",
      "        [97.9692]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416],\n",
      "        [98.0416]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172],\n",
      "        [98.1172]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939],\n",
      "        [98.1939]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.2722],\n",
      "        [98.2722],\n",
      "        [98.2722],\n",
      "        [98.2722],\n",
      "        [98.2722],\n",
      "        [98.2722],\n",
      "        [98.2722],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2723],\n",
      "        [98.2722],\n",
      "        [98.2722],\n",
      "        [98.2722],\n",
      "        [98.2722],\n",
      "        [98.2722]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.3516],\n",
      "        [98.3516],\n",
      "        [98.3516],\n",
      "        [98.3516],\n",
      "        [98.3516],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3517],\n",
      "        [98.3516],\n",
      "        [98.3516],\n",
      "        [98.3516],\n",
      "        [98.3516],\n",
      "        [98.3517]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325],\n",
      "        [98.4325]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112],\n",
      "        [98.5112]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872],\n",
      "        [98.5872]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616],\n",
      "        [98.6616]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331],\n",
      "        [98.7331]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000],\n",
      "        [98.8000]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622],\n",
      "        [98.8622]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.9281],\n",
      "        [98.9281],\n",
      "        [98.9281],\n",
      "        [98.9281],\n",
      "        [98.9281],\n",
      "        [98.9281],\n",
      "        [98.9281],\n",
      "        [98.9281],\n",
      "        [98.9282],\n",
      "        [98.9282],\n",
      "        [98.9282],\n",
      "        [98.9282],\n",
      "        [98.9282],\n",
      "        [98.9282],\n",
      "        [98.9282],\n",
      "        [98.9282],\n",
      "        [98.9282],\n",
      "        [98.9282],\n",
      "        [98.9281],\n",
      "        [98.9282],\n",
      "        [98.9281],\n",
      "        [98.9281],\n",
      "        [98.9281],\n",
      "        [98.9281]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948],\n",
      "        [98.9948]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.0606],\n",
      "        [99.0605],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0605],\n",
      "        [99.0605],\n",
      "        [99.0605],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0606],\n",
      "        [99.0605],\n",
      "        [99.0606],\n",
      "        [99.0605]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224],\n",
      "        [99.1224]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1787],\n",
      "        [99.1787],\n",
      "        [99.1787],\n",
      "        [99.1787],\n",
      "        [99.1787],\n",
      "        [99.1787],\n",
      "        [99.1787],\n",
      "        [99.1787],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786],\n",
      "        [99.1786]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361],\n",
      "        [99.2361]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2940],\n",
      "        [99.2940],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939],\n",
      "        [99.2939]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538],\n",
      "        [99.3538]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161],\n",
      "        [99.4161]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741],\n",
      "        [99.4741]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287],\n",
      "        [99.5287]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856],\n",
      "        [99.5856]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402],\n",
      "        [99.6402]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858],\n",
      "        [99.6858]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339],\n",
      "        [99.7339]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7835],\n",
      "        [99.7835],\n",
      "        [99.7835],\n",
      "        [99.7835],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834],\n",
      "        [99.7834]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331],\n",
      "        [99.8331]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772],\n",
      "        [99.8772]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187],\n",
      "        [99.9187]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566],\n",
      "        [99.9566]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832],\n",
      "        [99.9832]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116],\n",
      "        [100.0116]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310],\n",
      "        [100.0310]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0554],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553],\n",
      "        [100.0553]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0751],\n",
      "        [100.0751],\n",
      "        [100.0751],\n",
      "        [100.0751],\n",
      "        [100.0751],\n",
      "        [100.0751],\n",
      "        [100.0751],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752],\n",
      "        [100.0752]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0875],\n",
      "        [100.0875],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874],\n",
      "        [100.0874]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0944],\n",
      "        [100.0944],\n",
      "        [100.0944],\n",
      "        [100.0944],\n",
      "        [100.0944],\n",
      "        [100.0944],\n",
      "        [100.0944],\n",
      "        [100.0944],\n",
      "        [100.0944],\n",
      "        [100.0944],\n",
      "        [100.0945],\n",
      "        [100.0944],\n",
      "        [100.0945],\n",
      "        [100.0945],\n",
      "        [100.0945],\n",
      "        [100.0945],\n",
      "        [100.0945],\n",
      "        [100.0945],\n",
      "        [100.0945],\n",
      "        [100.0944],\n",
      "        [100.0945],\n",
      "        [100.0945],\n",
      "        [100.0945],\n",
      "        [100.0944]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975],\n",
      "        [100.0975]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954],\n",
      "        [100.0954]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916],\n",
      "        [100.0916]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781],\n",
      "        [100.0781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496],\n",
      "        [100.0496]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171],\n",
      "        [100.0171]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.9838],\n",
      "        [99.9838],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9837],\n",
      "        [99.9838],\n",
      "        [99.9838],\n",
      "        [99.9838],\n",
      "        [99.9838]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519],\n",
      "        [99.9519]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.9269],\n",
      "        [99.9269],\n",
      "        [99.9269],\n",
      "        [99.9269],\n",
      "        [99.9269],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9268],\n",
      "        [99.9269],\n",
      "        [99.9269],\n",
      "        [99.9269],\n",
      "        [99.9269],\n",
      "        [99.9269],\n",
      "        [99.9269],\n",
      "        [99.9269]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089],\n",
      "        [99.9089]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890],\n",
      "        [99.8890]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8674],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8674],\n",
      "        [99.8675],\n",
      "        [99.8674],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675],\n",
      "        [99.8675]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405],\n",
      "        [99.8405]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143],\n",
      "        [99.8143]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7882],\n",
      "        [99.7882],\n",
      "        [99.7882],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7881],\n",
      "        [99.7882],\n",
      "        [99.7882],\n",
      "        [99.7882],\n",
      "        [99.7882],\n",
      "        [99.7882],\n",
      "        [99.7882],\n",
      "        [99.7882]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685],\n",
      "        [99.7685]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7581],\n",
      "        [99.7581],\n",
      "        [99.7581],\n",
      "        [99.7581],\n",
      "        [99.7581],\n",
      "        [99.7582],\n",
      "        [99.7581],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582],\n",
      "        [99.7582]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554],\n",
      "        [99.7554]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520],\n",
      "        [99.7520]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466],\n",
      "        [99.7466]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432],\n",
      "        [99.7432]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435],\n",
      "        [99.7435]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497],\n",
      "        [99.7497]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621],\n",
      "        [99.7621]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7785],\n",
      "        [99.7785],\n",
      "        [99.7785],\n",
      "        [99.7785],\n",
      "        [99.7785],\n",
      "        [99.7785],\n",
      "        [99.7785],\n",
      "        [99.7785],\n",
      "        [99.7784],\n",
      "        [99.7784],\n",
      "        [99.7784],\n",
      "        [99.7784],\n",
      "        [99.7784],\n",
      "        [99.7784],\n",
      "        [99.7784],\n",
      "        [99.7784],\n",
      "        [99.7784],\n",
      "        [99.7784],\n",
      "        [99.7785],\n",
      "        [99.7785],\n",
      "        [99.7785],\n",
      "        [99.7785],\n",
      "        [99.7785],\n",
      "        [99.7785]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987],\n",
      "        [99.7987]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8198],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199],\n",
      "        [99.8199]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427],\n",
      "        [99.8427]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686],\n",
      "        [99.8686]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.8984],\n",
      "        [99.8984],\n",
      "        [99.8984],\n",
      "        [99.8984],\n",
      "        [99.8984],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8983],\n",
      "        [99.8984],\n",
      "        [99.8984],\n",
      "        [99.8984],\n",
      "        [99.8984],\n",
      "        [99.8984],\n",
      "        [99.8984]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313],\n",
      "        [99.9313]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669],\n",
      "        [99.9669]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041],\n",
      "        [100.0041]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0401],\n",
      "        [100.0401],\n",
      "        [100.0401],\n",
      "        [100.0401],\n",
      "        [100.0401],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0400],\n",
      "        [100.0401],\n",
      "        [100.0401],\n",
      "        [100.0401],\n",
      "        [100.0401]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.0773],\n",
      "        [100.0773],\n",
      "        [100.0773],\n",
      "        [100.0773],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0772],\n",
      "        [100.0773],\n",
      "        [100.0773],\n",
      "        [100.0773],\n",
      "        [100.0773],\n",
      "        [100.0773],\n",
      "        [100.0773]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174],\n",
      "        [100.1174]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597],\n",
      "        [100.1597]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033],\n",
      "        [100.2033]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484],\n",
      "        [100.2484]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948],\n",
      "        [100.2948]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401],\n",
      "        [100.3401]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858],\n",
      "        [100.3858]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326],\n",
      "        [100.4326]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810],\n",
      "        [100.4810]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306],\n",
      "        [100.5306]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806],\n",
      "        [100.5806]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307],\n",
      "        [100.6307]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796],\n",
      "        [100.6796]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292],\n",
      "        [100.7292]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804],\n",
      "        [100.7804]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315],\n",
      "        [100.8315]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828],\n",
      "        [100.8828]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349],\n",
      "        [100.9349]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878],\n",
      "        [100.9878]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403],\n",
      "        [101.0403]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931],\n",
      "        [101.0931]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473],\n",
      "        [101.1473]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025],\n",
      "        [101.2025]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588],\n",
      "        [101.2588]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168],\n",
      "        [101.3168]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.3753],\n",
      "        [101.3754],\n",
      "        [101.3754],\n",
      "        [101.3754],\n",
      "        [101.3753],\n",
      "        [101.3753],\n",
      "        [101.3753],\n",
      "        [101.3753],\n",
      "        [101.3753],\n",
      "        [101.3753],\n",
      "        [101.3753],\n",
      "        [101.3753],\n",
      "        [101.3753],\n",
      "        [101.3753],\n",
      "        [101.3753],\n",
      "        [101.3754],\n",
      "        [101.3754],\n",
      "        [101.3754],\n",
      "        [101.3754],\n",
      "        [101.3754],\n",
      "        [101.3754],\n",
      "        [101.3754],\n",
      "        [101.3754],\n",
      "        [101.3754]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321],\n",
      "        [101.4321]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4886],\n",
      "        [101.4887],\n",
      "        [101.4886],\n",
      "        [101.4887],\n",
      "        [101.4886]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454],\n",
      "        [101.5454]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.6019],\n",
      "        [101.6019],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6019],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020],\n",
      "        [101.6020]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592],\n",
      "        [101.6592]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179],\n",
      "        [101.7179]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766],\n",
      "        [101.7766]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348],\n",
      "        [101.8348]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927],\n",
      "        [101.8927]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516],\n",
      "        [101.9516]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111],\n",
      "        [102.0111]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713],\n",
      "        [102.0713]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330],\n",
      "        [102.1330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947],\n",
      "        [102.1947]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556],\n",
      "        [102.2556]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161],\n",
      "        [102.3161]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3769],\n",
      "        [102.3770],\n",
      "        [102.3770],\n",
      "        [102.3770],\n",
      "        [102.3770],\n",
      "        [102.3769],\n",
      "        [102.3769]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385],\n",
      "        [102.4385]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010],\n",
      "        [102.5010]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662],\n",
      "        [102.5662]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330],\n",
      "        [102.6330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009],\n",
      "        [102.7009]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709],\n",
      "        [102.7709]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8446],\n",
      "        [102.8446],\n",
      "        [102.8446],\n",
      "        [102.8445],\n",
      "        [102.8445],\n",
      "        [102.8446],\n",
      "        [102.8445]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211],\n",
      "        [102.9211]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015],\n",
      "        [103.0015]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.0843],\n",
      "        [103.0843],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0842],\n",
      "        [103.0843],\n",
      "        [103.0843],\n",
      "        [103.0843],\n",
      "        [103.0843],\n",
      "        [103.0843],\n",
      "        [103.0843],\n",
      "        [103.0843],\n",
      "        [103.0843],\n",
      "        [103.0843]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684],\n",
      "        [103.1684]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2521],\n",
      "        [103.2522],\n",
      "        [103.2522],\n",
      "        [103.2522],\n",
      "        [103.2522],\n",
      "        [103.2522],\n",
      "        [103.2522],\n",
      "        [103.2522],\n",
      "        [103.2521]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375],\n",
      "        [103.3375]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260],\n",
      "        [103.4260]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159],\n",
      "        [103.5159]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074],\n",
      "        [103.6074]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.6988],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6988],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6987],\n",
      "        [103.6988],\n",
      "        [103.6988],\n",
      "        [103.6988],\n",
      "        [103.6988],\n",
      "        [103.6988],\n",
      "        [103.6988],\n",
      "        [103.6988],\n",
      "        [103.6988],\n",
      "        [103.6988]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901],\n",
      "        [103.7901]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800],\n",
      "        [103.8800]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697],\n",
      "        [103.9697]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610],\n",
      "        [104.0610]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527],\n",
      "        [104.1527]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2442],\n",
      "        [104.2442],\n",
      "        [104.2442],\n",
      "        [104.2442],\n",
      "        [104.2442],\n",
      "        [104.2442],\n",
      "        [104.2442],\n",
      "        [104.2442],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443],\n",
      "        [104.2443]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358],\n",
      "        [104.3358]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254],\n",
      "        [104.4254]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129],\n",
      "        [104.5129]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998],\n",
      "        [104.5998]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871],\n",
      "        [104.6871]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734],\n",
      "        [104.7734]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573],\n",
      "        [104.8573]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392],\n",
      "        [104.9392]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198],\n",
      "        [105.0198]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985],\n",
      "        [105.0985]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773],\n",
      "        [105.1773]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561],\n",
      "        [105.2561]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343],\n",
      "        [105.3343]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116],\n",
      "        [105.4116]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4889],\n",
      "        [105.4889],\n",
      "        [105.4889],\n",
      "        [105.4888],\n",
      "        [105.4888],\n",
      "        [105.4888]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667],\n",
      "        [105.5667]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437],\n",
      "        [105.6437]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211],\n",
      "        [105.7211]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000],\n",
      "        [105.8000]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802],\n",
      "        [105.8802]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624],\n",
      "        [105.9624]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463],\n",
      "        [106.0463]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314],\n",
      "        [106.1314]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144],\n",
      "        [106.2144]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943],\n",
      "        [106.2943]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696],\n",
      "        [106.3696]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445],\n",
      "        [106.4445]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191],\n",
      "        [106.5191]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941],\n",
      "        [106.5941]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689],\n",
      "        [106.6689]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431],\n",
      "        [106.7431]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176],\n",
      "        [106.8176]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8921],\n",
      "        [106.8920],\n",
      "        [106.8920],\n",
      "        [106.8920]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684],\n",
      "        [106.9684]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439],\n",
      "        [107.0439]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190],\n",
      "        [107.1190]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917],\n",
      "        [107.1917]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596],\n",
      "        [107.2596]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245],\n",
      "        [107.3245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879],\n",
      "        [107.3879]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490],\n",
      "        [107.4490]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066],\n",
      "        [107.5066]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590],\n",
      "        [107.5590]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057],\n",
      "        [107.6057]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444],\n",
      "        [107.6444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806],\n",
      "        [107.6806]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168],\n",
      "        [107.7168]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526],\n",
      "        [107.7526]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873],\n",
      "        [107.7873]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227],\n",
      "        [107.8227]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8553],\n",
      "        [107.8554],\n",
      "        [107.8554],\n",
      "        [107.8554],\n",
      "        [107.8554],\n",
      "        [107.8554],\n",
      "        [107.8554],\n",
      "        [107.8554],\n",
      "        [107.8554],\n",
      "        [107.8554]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829],\n",
      "        [107.8829]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102],\n",
      "        [107.9102]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392],\n",
      "        [107.9392]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706],\n",
      "        [107.9706]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040],\n",
      "        [108.0040]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350],\n",
      "        [108.0350]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608],\n",
      "        [108.0608]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.0863],\n",
      "        [108.0863],\n",
      "        [108.0863],\n",
      "        [108.0863],\n",
      "        [108.0863],\n",
      "        [108.0863],\n",
      "        [108.0863]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [5/10], Loss: 2549.3871\n",
      "outputs: tensor([[108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1178],\n",
      "        [108.1177],\n",
      "        [108.1178],\n",
      "        [108.1178],\n",
      "        [108.1178],\n",
      "        [108.1178],\n",
      "        [108.1178],\n",
      "        [108.1178],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177],\n",
      "        [108.1177]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1522],\n",
      "        [108.1522],\n",
      "        [108.1522],\n",
      "        [108.1522],\n",
      "        [108.1522],\n",
      "        [108.1522],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1522],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523],\n",
      "        [108.1523]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940],\n",
      "        [108.1940]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2398],\n",
      "        [108.2398],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397],\n",
      "        [108.2397]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926],\n",
      "        [108.2926]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457],\n",
      "        [108.3457]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990],\n",
      "        [108.3990]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.4475],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4475],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4476],\n",
      "        [108.4475],\n",
      "        [108.4475]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4970],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971],\n",
      "        [108.4971]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507],\n",
      "        [108.5507]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6091],\n",
      "        [108.6091],\n",
      "        [108.6091],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090],\n",
      "        [108.6090]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6690],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689],\n",
      "        [108.6689]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321],\n",
      "        [108.7321]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.7986],\n",
      "        [108.7986],\n",
      "        [108.7986],\n",
      "        [108.7986],\n",
      "        [108.7986],\n",
      "        [108.7986],\n",
      "        [108.7986],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7986],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987],\n",
      "        [108.7987]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646],\n",
      "        [108.8646]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.9294],\n",
      "        [108.9294],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9294],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295],\n",
      "        [108.9295]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949],\n",
      "        [108.9949]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0590],\n",
      "        [109.0589],\n",
      "        [109.0589],\n",
      "        [109.0589],\n",
      "        [109.0589],\n",
      "        [109.0589]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090],\n",
      "        [109.1090]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621],\n",
      "        [109.1621]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112],\n",
      "        [109.2112]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626],\n",
      "        [109.2626]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106],\n",
      "        [109.3106]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620],\n",
      "        [109.3620]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199],\n",
      "        [109.4199]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796],\n",
      "        [109.4796]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419],\n",
      "        [109.5419]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943],\n",
      "        [109.5943]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.6420],\n",
      "        [109.6419],\n",
      "        [109.6419],\n",
      "        [109.6419],\n",
      "        [109.6419],\n",
      "        [109.6419],\n",
      "        [109.6419],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6420],\n",
      "        [109.6419],\n",
      "        [109.6419],\n",
      "        [109.6419]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955],\n",
      "        [109.6955]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451],\n",
      "        [109.7451]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986],\n",
      "        [109.7986]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562],\n",
      "        [109.8562]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9176],\n",
      "        [109.9176],\n",
      "        [109.9176],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175],\n",
      "        [109.9175]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801],\n",
      "        [109.9801]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446],\n",
      "        [110.0446]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103],\n",
      "        [110.1103]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777],\n",
      "        [110.1777]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427],\n",
      "        [110.2427]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045],\n",
      "        [110.3045]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646],\n",
      "        [110.3646]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.4214],\n",
      "        [110.4213],\n",
      "        [110.4213],\n",
      "        [110.4213],\n",
      "        [110.4213],\n",
      "        [110.4214],\n",
      "        [110.4213],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4730],\n",
      "        [110.4730],\n",
      "        [110.4730],\n",
      "        [110.4730],\n",
      "        [110.4730],\n",
      "        [110.4730],\n",
      "        [110.4730],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729],\n",
      "        [110.4729]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191],\n",
      "        [110.5191]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696],\n",
      "        [110.5696]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209],\n",
      "        [110.6209]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712],\n",
      "        [110.6712]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7171],\n",
      "        [110.7171],\n",
      "        [110.7171],\n",
      "        [110.7171],\n",
      "        [110.7171],\n",
      "        [110.7171],\n",
      "        [110.7170],\n",
      "        [110.7171],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170],\n",
      "        [110.7170]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565],\n",
      "        [110.7565]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974],\n",
      "        [110.7974]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387],\n",
      "        [110.8387]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823],\n",
      "        [110.8823]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.9288],\n",
      "        [110.9288],\n",
      "        [110.9288],\n",
      "        [110.9289],\n",
      "        [110.9288],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289],\n",
      "        [110.9289]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704],\n",
      "        [110.9704]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.0080],\n",
      "        [111.0080],\n",
      "        [111.0080],\n",
      "        [111.0080],\n",
      "        [111.0080],\n",
      "        [111.0080],\n",
      "        [111.0080],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0081],\n",
      "        [111.0080],\n",
      "        [111.0080],\n",
      "        [111.0080],\n",
      "        [111.0080],\n",
      "        [111.0080]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484],\n",
      "        [111.0484]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0862],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861],\n",
      "        [111.0861]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136],\n",
      "        [111.1136]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1440],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439],\n",
      "        [111.1439]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760],\n",
      "        [111.1760]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082],\n",
      "        [111.2082]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340],\n",
      "        [111.2340]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2569],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568],\n",
      "        [111.2568]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756],\n",
      "        [111.2756]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816],\n",
      "        [111.2816]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896],\n",
      "        [111.2896]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2875],\n",
      "        [111.2875],\n",
      "        [111.2875],\n",
      "        [111.2875],\n",
      "        [111.2875],\n",
      "        [111.2875],\n",
      "        [111.2875],\n",
      "        [111.2875],\n",
      "        [111.2875],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874],\n",
      "        [111.2874]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2909],\n",
      "        [111.2909],\n",
      "        [111.2909],\n",
      "        [111.2909],\n",
      "        [111.2909],\n",
      "        [111.2909],\n",
      "        [111.2909],\n",
      "        [111.2909],\n",
      "        [111.2909],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908],\n",
      "        [111.2908]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2891],\n",
      "        [111.2891],\n",
      "        [111.2891],\n",
      "        [111.2891],\n",
      "        [111.2891],\n",
      "        [111.2891],\n",
      "        [111.2891],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2891],\n",
      "        [111.2892],\n",
      "        [111.2892],\n",
      "        [111.2891],\n",
      "        [111.2891]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789],\n",
      "        [111.2789]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627],\n",
      "        [111.2627]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420],\n",
      "        [111.2420]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155],\n",
      "        [111.2155]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870],\n",
      "        [111.1870]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476],\n",
      "        [111.1476]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912],\n",
      "        [111.0912]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303],\n",
      "        [111.0303]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685],\n",
      "        [110.9685]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085],\n",
      "        [110.9085]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562],\n",
      "        [110.8562]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120],\n",
      "        [110.8120]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7656],\n",
      "        [110.7657],\n",
      "        [110.7656],\n",
      "        [110.7657],\n",
      "        [110.7657],\n",
      "        [110.7657]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174],\n",
      "        [110.7174]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631],\n",
      "        [110.6631]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.6098],\n",
      "        [110.6098],\n",
      "        [110.6098],\n",
      "        [110.6098],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6097],\n",
      "        [110.6098],\n",
      "        [110.6098],\n",
      "        [110.6098],\n",
      "        [110.6098]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565],\n",
      "        [110.5565]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106],\n",
      "        [110.5106]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754],\n",
      "        [110.4754]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488],\n",
      "        [110.4488]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.4215],\n",
      "        [110.4215],\n",
      "        [110.4215],\n",
      "        [110.4215],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4215],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4214],\n",
      "        [110.4215],\n",
      "        [110.4215],\n",
      "        [110.4215],\n",
      "        [110.4215],\n",
      "        [110.4215],\n",
      "        [110.4215]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919],\n",
      "        [110.3919]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647],\n",
      "        [110.3647]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417],\n",
      "        [110.3417]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3255],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3254],\n",
      "        [110.3255],\n",
      "        [110.3255],\n",
      "        [110.3255]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162],\n",
      "        [110.3162]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3116],\n",
      "        [110.3116],\n",
      "        [110.3116],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115],\n",
      "        [110.3115]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113],\n",
      "        [110.3113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122],\n",
      "        [110.3122]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149],\n",
      "        [110.3149]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212],\n",
      "        [110.3212]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319],\n",
      "        [110.3319]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463],\n",
      "        [110.3463]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637],\n",
      "        [110.3637]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829],\n",
      "        [110.3829]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007],\n",
      "        [110.4007]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200],\n",
      "        [110.4200]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4426],\n",
      "        [110.4427],\n",
      "        [110.4426],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427],\n",
      "        [110.4427]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678],\n",
      "        [110.4678]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944],\n",
      "        [110.4944]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228],\n",
      "        [110.5228]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527],\n",
      "        [110.5527]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813],\n",
      "        [110.5813]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104],\n",
      "        [110.6104]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408],\n",
      "        [110.6408]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730],\n",
      "        [110.6730]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066],\n",
      "        [110.7066]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407],\n",
      "        [110.7407]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749],\n",
      "        [110.7749]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079],\n",
      "        [110.8079]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416],\n",
      "        [110.8416]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771],\n",
      "        [110.8771]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126],\n",
      "        [110.9126]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483],\n",
      "        [110.9483]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849],\n",
      "        [110.9849]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225],\n",
      "        [111.0225]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596],\n",
      "        [111.0596]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972],\n",
      "        [111.0972]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1363],\n",
      "        [111.1363],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362],\n",
      "        [111.1362]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765],\n",
      "        [111.1765]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181],\n",
      "        [111.2181]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615],\n",
      "        [111.2615]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056],\n",
      "        [111.3056]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477],\n",
      "        [111.3477]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896],\n",
      "        [111.3896]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318],\n",
      "        [111.4318]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737],\n",
      "        [111.4737]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5164],\n",
      "        [111.5165],\n",
      "        [111.5164],\n",
      "        [111.5165],\n",
      "        [111.5165],\n",
      "        [111.5165],\n",
      "        [111.5165],\n",
      "        [111.5165]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609],\n",
      "        [111.5609]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054],\n",
      "        [111.6054]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492],\n",
      "        [111.6492]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928],\n",
      "        [111.6928]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375],\n",
      "        [111.7375]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829],\n",
      "        [111.7829]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292],\n",
      "        [111.8292]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771],\n",
      "        [111.8771]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251],\n",
      "        [111.9251]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722],\n",
      "        [111.9722]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189],\n",
      "        [112.0189]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659],\n",
      "        [112.0659]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138],\n",
      "        [112.1138]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628],\n",
      "        [112.1628]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149],\n",
      "        [112.2149]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687],\n",
      "        [112.2687]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239],\n",
      "        [112.3239]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815],\n",
      "        [112.3815]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432],\n",
      "        [112.4432]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083],\n",
      "        [112.5083]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778],\n",
      "        [112.5778]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499],\n",
      "        [112.6499]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7237],\n",
      "        [112.7237],\n",
      "        [112.7237],\n",
      "        [112.7237],\n",
      "        [112.7236],\n",
      "        [112.7236],\n",
      "        [112.7236]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969],\n",
      "        [112.7969]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721],\n",
      "        [112.8721]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508],\n",
      "        [112.9508]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312],\n",
      "        [113.0312]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133],\n",
      "        [113.1133]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954],\n",
      "        [113.1954]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775],\n",
      "        [113.2775]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579],\n",
      "        [113.3579]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381],\n",
      "        [113.4381]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201],\n",
      "        [113.5201]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027],\n",
      "        [113.6027]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851],\n",
      "        [113.6851]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674],\n",
      "        [113.7674]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476],\n",
      "        [113.8476]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254],\n",
      "        [113.9254]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027],\n",
      "        [114.0027]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802],\n",
      "        [114.0802]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568],\n",
      "        [114.1568]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306],\n",
      "        [114.2306]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021],\n",
      "        [114.3021]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722],\n",
      "        [114.3722]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401],\n",
      "        [114.4401]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082],\n",
      "        [114.5082]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5762],\n",
      "        [114.5763],\n",
      "        [114.5763],\n",
      "        [114.5763],\n",
      "        [114.5763],\n",
      "        [114.5763],\n",
      "        [114.5763],\n",
      "        [114.5763],\n",
      "        [114.5763],\n",
      "        [114.5763]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436],\n",
      "        [114.6436]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100],\n",
      "        [114.7100]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763],\n",
      "        [114.7763]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434],\n",
      "        [114.8434]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095],\n",
      "        [114.9095]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760],\n",
      "        [114.9760]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443],\n",
      "        [115.0443]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141],\n",
      "        [115.1141]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861],\n",
      "        [115.1861]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2601],\n",
      "        [115.2602],\n",
      "        [115.2602],\n",
      "        [115.2602],\n",
      "        [115.2602],\n",
      "        [115.2602],\n",
      "        [115.2601],\n",
      "        [115.2601]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355],\n",
      "        [115.3355]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085],\n",
      "        [115.4085]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781],\n",
      "        [115.4781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424],\n",
      "        [115.5424]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062],\n",
      "        [115.6062]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698],\n",
      "        [115.6698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7337],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338],\n",
      "        [115.7338]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975],\n",
      "        [115.7975]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606],\n",
      "        [115.8606]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241],\n",
      "        [115.9241]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876],\n",
      "        [115.9876]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532],\n",
      "        [116.0532]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178],\n",
      "        [116.1178]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820],\n",
      "        [116.1820]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435],\n",
      "        [116.2435]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996],\n",
      "        [116.2996]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523],\n",
      "        [116.3523]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033],\n",
      "        [116.4033]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516],\n",
      "        [116.4516]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961],\n",
      "        [116.4961]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346],\n",
      "        [116.5346]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5667],\n",
      "        [116.5667],\n",
      "        [116.5667],\n",
      "        [116.5667],\n",
      "        [116.5666],\n",
      "        [116.5666],\n",
      "        [116.5666]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5896],\n",
      "        [116.5897],\n",
      "        [116.5897],\n",
      "        [116.5897],\n",
      "        [116.5897],\n",
      "        [116.5897],\n",
      "        [116.5897],\n",
      "        [116.5897],\n",
      "        [116.5896]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099],\n",
      "        [116.6099]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301],\n",
      "        [116.6301]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498],\n",
      "        [116.6498]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683],\n",
      "        [116.6683]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877],\n",
      "        [116.6877]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039],\n",
      "        [116.7039]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144],\n",
      "        [116.7144]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246],\n",
      "        [116.7246]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.7368],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7367],\n",
      "        [116.7368],\n",
      "        [116.7368],\n",
      "        [116.7368],\n",
      "        [116.7368],\n",
      "        [116.7368],\n",
      "        [116.7368],\n",
      "        [116.7368],\n",
      "        [116.7368],\n",
      "        [116.7368],\n",
      "        [116.7367]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516],\n",
      "        [116.7516]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688],\n",
      "        [116.7688]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833],\n",
      "        [116.7833]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919],\n",
      "        [116.7919]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.8002],\n",
      "        [116.8002],\n",
      "        [116.8002],\n",
      "        [116.8002],\n",
      "        [116.8002],\n",
      "        [116.8002],\n",
      "        [116.8002]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [6/10], Loss: 2095.3205\n",
      "outputs: tensor([[116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153],\n",
      "        [116.8153]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338],\n",
      "        [116.8338]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606],\n",
      "        [116.8606]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920],\n",
      "        [116.8920]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314],\n",
      "        [116.9314]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712],\n",
      "        [116.9712]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111],\n",
      "        [117.0111]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458],\n",
      "        [117.0458]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815],\n",
      "        [117.0815]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220],\n",
      "        [117.1220]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.1677],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1677],\n",
      "        [117.1677],\n",
      "        [117.1677],\n",
      "        [117.1677],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1677],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1678],\n",
      "        [117.1677],\n",
      "        [117.1678]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.2153],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2154],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2154],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2154],\n",
      "        [117.2154],\n",
      "        [117.2154],\n",
      "        [117.2154],\n",
      "        [117.2154],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2153],\n",
      "        [117.2153]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667],\n",
      "        [117.2667]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.3218],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3219],\n",
      "        [117.3218],\n",
      "        [117.3219],\n",
      "        [117.3219],\n",
      "        [117.3219],\n",
      "        [117.3219],\n",
      "        [117.3219],\n",
      "        [117.3219],\n",
      "        [117.3219],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3218],\n",
      "        [117.3219]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764],\n",
      "        [117.3764]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297],\n",
      "        [117.4297]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837],\n",
      "        [117.4837]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361],\n",
      "        [117.5361]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.5727],\n",
      "        [117.5726],\n",
      "        [117.5726],\n",
      "        [117.5726],\n",
      "        [117.5726],\n",
      "        [117.5726],\n",
      "        [117.5726],\n",
      "        [117.5726],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727],\n",
      "        [117.5727]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127],\n",
      "        [117.6127]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482],\n",
      "        [117.6482]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864],\n",
      "        [117.6864]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207],\n",
      "        [117.7207]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7590],\n",
      "        [117.7589],\n",
      "        [117.7589],\n",
      "        [117.7589]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.8045],\n",
      "        [117.8045],\n",
      "        [117.8045],\n",
      "        [117.8045],\n",
      "        [117.8045],\n",
      "        [117.8045],\n",
      "        [117.8045],\n",
      "        [117.8045],\n",
      "        [117.8045],\n",
      "        [117.8045],\n",
      "        [117.8045],\n",
      "        [117.8046],\n",
      "        [117.8046],\n",
      "        [117.8046],\n",
      "        [117.8046],\n",
      "        [117.8046],\n",
      "        [117.8045],\n",
      "        [117.8045],\n",
      "        [117.8046],\n",
      "        [117.8045],\n",
      "        [117.8046],\n",
      "        [117.8046],\n",
      "        [117.8045],\n",
      "        [117.8045]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521],\n",
      "        [117.8521]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028],\n",
      "        [117.9028]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.9421],\n",
      "        [117.9421],\n",
      "        [117.9421],\n",
      "        [117.9421],\n",
      "        [117.9421],\n",
      "        [117.9421],\n",
      "        [117.9421],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422],\n",
      "        [117.9422]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762],\n",
      "        [117.9762]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0170],\n",
      "        [118.0170],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169],\n",
      "        [118.0169]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533],\n",
      "        [118.0533]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940],\n",
      "        [118.0940]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394],\n",
      "        [118.1394]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891],\n",
      "        [118.1891]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402],\n",
      "        [118.2402]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934],\n",
      "        [118.2934]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481],\n",
      "        [118.3481]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047],\n",
      "        [118.4047]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586],\n",
      "        [118.4586]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089],\n",
      "        [118.5089]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573],\n",
      "        [118.5573]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019],\n",
      "        [118.6019]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407],\n",
      "        [118.6407]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734],\n",
      "        [118.6734]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109],\n",
      "        [118.7109]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494],\n",
      "        [118.7494]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868],\n",
      "        [118.7868]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191],\n",
      "        [118.8191]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443],\n",
      "        [118.8443]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710],\n",
      "        [118.8710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983],\n",
      "        [118.8983]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282],\n",
      "        [118.9282]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614],\n",
      "        [118.9614]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890],\n",
      "        [118.9890]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122],\n",
      "        [119.0122]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385],\n",
      "        [119.0385]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618],\n",
      "        [119.0618]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735],\n",
      "        [119.0735]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885],\n",
      "        [119.0885]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054],\n",
      "        [119.1054]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225],\n",
      "        [119.1225]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325],\n",
      "        [119.1325]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.1391],\n",
      "        [119.1390],\n",
      "        [119.1390],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391],\n",
      "        [119.1391]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411],\n",
      "        [119.1411]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286],\n",
      "        [119.1286]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185],\n",
      "        [119.1185]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969],\n",
      "        [119.0969]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816],\n",
      "        [119.0816]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606],\n",
      "        [119.0606]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300],\n",
      "        [119.0300]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926],\n",
      "        [118.9926]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9503],\n",
      "        [118.9503],\n",
      "        [118.9503],\n",
      "        [118.9503],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502],\n",
      "        [118.9502]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.9014],\n",
      "        [118.9013],\n",
      "        [118.9013],\n",
      "        [118.9013],\n",
      "        [118.9013],\n",
      "        [118.9013],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014],\n",
      "        [118.9014]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.8502],\n",
      "        [118.8502],\n",
      "        [118.8502],\n",
      "        [118.8502],\n",
      "        [118.8502],\n",
      "        [118.8502],\n",
      "        [118.8502],\n",
      "        [118.8502],\n",
      "        [118.8502],\n",
      "        [118.8503],\n",
      "        [118.8503],\n",
      "        [118.8503],\n",
      "        [118.8503],\n",
      "        [118.8503],\n",
      "        [118.8503],\n",
      "        [118.8503],\n",
      "        [118.8503],\n",
      "        [118.8503],\n",
      "        [118.8503],\n",
      "        [118.8502],\n",
      "        [118.8502],\n",
      "        [118.8502],\n",
      "        [118.8502],\n",
      "        [118.8502]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7870],\n",
      "        [118.7870],\n",
      "        [118.7870],\n",
      "        [118.7870],\n",
      "        [118.7870],\n",
      "        [118.7870],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869],\n",
      "        [118.7869]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045],\n",
      "        [118.7045]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171],\n",
      "        [118.6171]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287],\n",
      "        [118.5287]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424],\n",
      "        [118.4424]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648],\n",
      "        [118.3648]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964],\n",
      "        [118.2964]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256],\n",
      "        [118.2256]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528],\n",
      "        [118.1528]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732],\n",
      "        [118.0732]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947],\n",
      "        [117.9947]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164],\n",
      "        [117.9164]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465],\n",
      "        [117.8465]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.7886],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7885],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7885],\n",
      "        [117.7885],\n",
      "        [117.7885],\n",
      "        [117.7885],\n",
      "        [117.7885],\n",
      "        [117.7885],\n",
      "        [117.7885],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7886],\n",
      "        [117.7886]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404],\n",
      "        [117.7404]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915],\n",
      "        [117.6915]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401],\n",
      "        [117.6401]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.5914],\n",
      "        [117.5915],\n",
      "        [117.5915],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5914],\n",
      "        [117.5915],\n",
      "        [117.5915]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475],\n",
      "        [117.5475]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113],\n",
      "        [117.5113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830],\n",
      "        [117.4830]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599],\n",
      "        [117.4599]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418],\n",
      "        [117.4418]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249],\n",
      "        [117.4249]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103],\n",
      "        [117.4103]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997],\n",
      "        [117.3997]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940],\n",
      "        [117.3940]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3925],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3925],\n",
      "        [117.3925],\n",
      "        [117.3926],\n",
      "        [117.3925],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926],\n",
      "        [117.3926]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946],\n",
      "        [117.3946]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986],\n",
      "        [117.3986]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011],\n",
      "        [117.4011]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4053],\n",
      "        [117.4053],\n",
      "        [117.4053],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4053],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054],\n",
      "        [117.4054]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134],\n",
      "        [117.4134]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242],\n",
      "        [117.4242]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368],\n",
      "        [117.4368]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514],\n",
      "        [117.4514]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677],\n",
      "        [117.4677]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826],\n",
      "        [117.4826]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980],\n",
      "        [117.4980]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150],\n",
      "        [117.5150]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340],\n",
      "        [117.5340]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547],\n",
      "        [117.5547]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758],\n",
      "        [117.5758]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972],\n",
      "        [117.5972]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171],\n",
      "        [117.6171]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380],\n",
      "        [117.6380]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609],\n",
      "        [117.6609]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838],\n",
      "        [117.6838]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069],\n",
      "        [117.7069]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7311],\n",
      "        [117.7311],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312],\n",
      "        [117.7312]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565],\n",
      "        [117.7565]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813],\n",
      "        [117.7813]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066],\n",
      "        [117.8066]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337],\n",
      "        [117.8337]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621],\n",
      "        [117.8621]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920],\n",
      "        [117.8920]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240],\n",
      "        [117.9240]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569],\n",
      "        [117.9569]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874],\n",
      "        [117.9874]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178],\n",
      "        [118.0178]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485],\n",
      "        [118.0485]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789],\n",
      "        [118.0789]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103],\n",
      "        [118.1103]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436],\n",
      "        [118.1436]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769],\n",
      "        [118.1769]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096],\n",
      "        [118.2096]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420],\n",
      "        [118.2420]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757],\n",
      "        [118.2757]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102],\n",
      "        [118.3102]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457],\n",
      "        [118.3457]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830],\n",
      "        [118.3830]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204],\n",
      "        [118.4204]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569],\n",
      "        [118.4569]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930],\n",
      "        [118.4930]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294],\n",
      "        [118.5294]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668],\n",
      "        [118.5668]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055],\n",
      "        [118.6055]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476],\n",
      "        [118.6476]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918],\n",
      "        [118.6918]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375],\n",
      "        [118.7375]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859],\n",
      "        [118.7859]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390],\n",
      "        [118.8390]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959],\n",
      "        [118.8959]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577],\n",
      "        [118.9577]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0225],\n",
      "        [119.0226],\n",
      "        [119.0226],\n",
      "        [119.0226],\n",
      "        [119.0226],\n",
      "        [119.0226],\n",
      "        [119.0226],\n",
      "        [119.0226],\n",
      "        [119.0226]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893],\n",
      "        [119.0893]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1554],\n",
      "        [119.1554],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555],\n",
      "        [119.1555]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238],\n",
      "        [119.2238]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961],\n",
      "        [119.2961]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704],\n",
      "        [119.3704]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466],\n",
      "        [119.4466]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227],\n",
      "        [119.5227]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989],\n",
      "        [119.5989]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733],\n",
      "        [119.6733]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473],\n",
      "        [119.7473]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235],\n",
      "        [119.8235]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002],\n",
      "        [119.9002]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768],\n",
      "        [119.9768]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534],\n",
      "        [120.0534]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.1276],\n",
      "        [120.1276],\n",
      "        [120.1275],\n",
      "        [120.1276],\n",
      "        [120.1275],\n",
      "        [120.1276],\n",
      "        [120.1276],\n",
      "        [120.1275],\n",
      "        [120.1276],\n",
      "        [120.1276],\n",
      "        [120.1275],\n",
      "        [120.1275],\n",
      "        [120.1275],\n",
      "        [120.1275],\n",
      "        [120.1276],\n",
      "        [120.1276],\n",
      "        [120.1276],\n",
      "        [120.1276],\n",
      "        [120.1276],\n",
      "        [120.1276],\n",
      "        [120.1276],\n",
      "        [120.1276],\n",
      "        [120.1276],\n",
      "        [120.1276]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990],\n",
      "        [120.1990]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2698],\n",
      "        [120.2699],\n",
      "        [120.2699],\n",
      "        [120.2699],\n",
      "        [120.2699],\n",
      "        [120.2699],\n",
      "        [120.2699],\n",
      "        [120.2699],\n",
      "        [120.2698]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411],\n",
      "        [120.3411]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112],\n",
      "        [120.4112]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781],\n",
      "        [120.4781]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425],\n",
      "        [120.5425]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054],\n",
      "        [120.6054]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658],\n",
      "        [120.6658]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264],\n",
      "        [120.7264]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870],\n",
      "        [120.7870]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467],\n",
      "        [120.8467]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055],\n",
      "        [120.9055]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9642],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641],\n",
      "        [120.9641]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236],\n",
      "        [121.0236]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821],\n",
      "        [121.0821]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409],\n",
      "        [121.1409]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2018],\n",
      "        [121.2019],\n",
      "        [121.2019],\n",
      "        [121.2019],\n",
      "        [121.2019],\n",
      "        [121.2019],\n",
      "        [121.2019],\n",
      "        [121.2019],\n",
      "        [121.2018]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645],\n",
      "        [121.2645]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296],\n",
      "        [121.3296]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970],\n",
      "        [121.3970]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659],\n",
      "        [121.4659]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322],\n",
      "        [121.5322]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946],\n",
      "        [121.5946]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511],\n",
      "        [121.6511]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070],\n",
      "        [121.7070]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627],\n",
      "        [121.7627]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189],\n",
      "        [121.8189]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748],\n",
      "        [121.8748]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300],\n",
      "        [121.9300]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857],\n",
      "        [121.9857]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413],\n",
      "        [122.0413]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993],\n",
      "        [122.0993]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563],\n",
      "        [122.1563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128],\n",
      "        [122.2128]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663],\n",
      "        [122.2663]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137],\n",
      "        [122.3137]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572],\n",
      "        [122.3572]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3988],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3989],\n",
      "        [122.3988]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376],\n",
      "        [122.4376]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719],\n",
      "        [122.4719]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996],\n",
      "        [122.4996]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200],\n",
      "        [122.5200]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302],\n",
      "        [122.5302]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373],\n",
      "        [122.5373]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445],\n",
      "        [122.5445]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510],\n",
      "        [122.5510]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563],\n",
      "        [122.5563]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625],\n",
      "        [122.5625]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653],\n",
      "        [122.5653]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616],\n",
      "        [122.5616]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576],\n",
      "        [122.5576]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557],\n",
      "        [122.5557]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570],\n",
      "        [122.5570]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610],\n",
      "        [122.5610]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5618],\n",
      "        [122.5619],\n",
      "        [122.5619],\n",
      "        [122.5619],\n",
      "        [122.5619],\n",
      "        [122.5619],\n",
      "        [122.5619],\n",
      "        [122.5619],\n",
      "        [122.5618]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561],\n",
      "        [122.5561]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5501],\n",
      "        [122.5501],\n",
      "        [122.5501],\n",
      "        [122.5501],\n",
      "        [122.5501],\n",
      "        [122.5501],\n",
      "        [122.5501]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [7/10], Loss: 1911.5301\n",
      "outputs: tensor([[122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517],\n",
      "        [122.5517]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573],\n",
      "        [122.5573]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721],\n",
      "        [122.5721]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921],\n",
      "        [122.5921]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212],\n",
      "        [122.6212]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507],\n",
      "        [122.6507]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804],\n",
      "        [122.6804]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042],\n",
      "        [122.7042]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7293],\n",
      "        [122.7292],\n",
      "        [122.7293],\n",
      "        [122.7292],\n",
      "        [122.7293],\n",
      "        [122.7293],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292],\n",
      "        [122.7292]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596],\n",
      "        [122.7596]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960],\n",
      "        [122.7960]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344],\n",
      "        [122.8344]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770],\n",
      "        [122.8770]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240],\n",
      "        [122.9240]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703],\n",
      "        [122.9703]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152],\n",
      "        [123.0152]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609],\n",
      "        [123.0609]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049],\n",
      "        [123.1049]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.1311],\n",
      "        [123.1311],\n",
      "        [123.1310],\n",
      "        [123.1310],\n",
      "        [123.1310],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311],\n",
      "        [123.1311]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.1612],\n",
      "        [123.1611],\n",
      "        [123.1611],\n",
      "        [123.1611],\n",
      "        [123.1611],\n",
      "        [123.1611],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612],\n",
      "        [123.1612]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862],\n",
      "        [123.1862]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142],\n",
      "        [123.2142]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379],\n",
      "        [123.2379]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661],\n",
      "        [123.2661]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025],\n",
      "        [123.3025]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412],\n",
      "        [123.3412]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833],\n",
      "        [123.3833]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128],\n",
      "        [123.4128]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363],\n",
      "        [123.4363]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.4673],\n",
      "        [123.4673],\n",
      "        [123.4674],\n",
      "        [123.4673],\n",
      "        [123.4673],\n",
      "        [123.4673],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674],\n",
      "        [123.4674]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935],\n",
      "        [123.4935]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5245],\n",
      "        [123.5245],\n",
      "        [123.5245],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5246],\n",
      "        [123.5245],\n",
      "        [123.5245],\n",
      "        [123.5246],\n",
      "        [123.5245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609],\n",
      "        [123.5609]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021],\n",
      "        [123.6021]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449],\n",
      "        [123.6449]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.6900],\n",
      "        [123.6900],\n",
      "        [123.6900],\n",
      "        [123.6900],\n",
      "        [123.6900],\n",
      "        [123.6900],\n",
      "        [123.6900],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6901],\n",
      "        [123.6900],\n",
      "        [123.6900],\n",
      "        [123.6900],\n",
      "        [123.6900],\n",
      "        [123.6900]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369],\n",
      "        [123.7369]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859],\n",
      "        [123.7859]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319],\n",
      "        [123.8319]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739],\n",
      "        [123.8739]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137],\n",
      "        [123.9137]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493],\n",
      "        [123.9493]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784],\n",
      "        [123.9784]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006],\n",
      "        [124.0006]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283],\n",
      "        [124.0283]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571],\n",
      "        [124.0571]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847],\n",
      "        [124.0847]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066],\n",
      "        [124.1066]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1205],\n",
      "        [124.1204],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205],\n",
      "        [124.1205]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361],\n",
      "        [124.1361]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524],\n",
      "        [124.1524]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716],\n",
      "        [124.1716]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946],\n",
      "        [124.1946]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113],\n",
      "        [124.2113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231],\n",
      "        [124.2231]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384],\n",
      "        [124.2384]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503],\n",
      "        [124.2503]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2492],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2493],\n",
      "        [124.2492],\n",
      "        [124.2492]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519],\n",
      "        [124.2519]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2568],\n",
      "        [124.2568],\n",
      "        [124.2568],\n",
      "        [124.2568],\n",
      "        [124.2568],\n",
      "        [124.2568],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2568],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567],\n",
      "        [124.2567]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2619],\n",
      "        [124.2619],\n",
      "        [124.2619],\n",
      "        [124.2619],\n",
      "        [124.2619],\n",
      "        [124.2619],\n",
      "        [124.2619],\n",
      "        [124.2619],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618],\n",
      "        [124.2618]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589],\n",
      "        [124.2589]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522],\n",
      "        [124.2522]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404],\n",
      "        [124.2404]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125],\n",
      "        [124.2125]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1872],\n",
      "        [124.1872],\n",
      "        [124.1872],\n",
      "        [124.1872],\n",
      "        [124.1872],\n",
      "        [124.1872],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871],\n",
      "        [124.1871]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490],\n",
      "        [124.1490]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179],\n",
      "        [124.1179]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805],\n",
      "        [124.0805]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323],\n",
      "        [124.0323]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767],\n",
      "        [123.9767]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155],\n",
      "        [123.9155]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470],\n",
      "        [123.8470]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761],\n",
      "        [123.7761]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6917],\n",
      "        [123.6916]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.5859],\n",
      "        [123.5859],\n",
      "        [123.5859],\n",
      "        [123.5859],\n",
      "        [123.5859],\n",
      "        [123.5859],\n",
      "        [123.5859],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5859],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5859],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5860],\n",
      "        [123.5860]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748],\n",
      "        [123.4748]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.3626],\n",
      "        [123.3626],\n",
      "        [123.3626],\n",
      "        [123.3626],\n",
      "        [123.3626],\n",
      "        [123.3625],\n",
      "        [123.3626],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3625],\n",
      "        [123.3626],\n",
      "        [123.3626],\n",
      "        [123.3626],\n",
      "        [123.3626],\n",
      "        [123.3626]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2526],\n",
      "        [123.2526],\n",
      "        [123.2527],\n",
      "        [123.2526],\n",
      "        [123.2526],\n",
      "        [123.2527],\n",
      "        [123.2526],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527],\n",
      "        [123.2527]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526],\n",
      "        [123.1526]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629],\n",
      "        [123.0629]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9705],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706],\n",
      "        [122.9706]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760],\n",
      "        [122.8760]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740],\n",
      "        [122.7740]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.6733],\n",
      "        [122.6733],\n",
      "        [122.6733],\n",
      "        [122.6733],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6732],\n",
      "        [122.6733],\n",
      "        [122.6733],\n",
      "        [122.6733],\n",
      "        [122.6733]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728],\n",
      "        [122.5728]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817],\n",
      "        [122.4817]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041],\n",
      "        [122.4041]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3374],\n",
      "        [122.3375],\n",
      "        [122.3375],\n",
      "        [122.3375],\n",
      "        [122.3375],\n",
      "        [122.3374]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700],\n",
      "        [122.2700]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998],\n",
      "        [122.1998]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327],\n",
      "        [122.1327]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710],\n",
      "        [122.0710]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179],\n",
      "        [122.0179]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9736],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9736],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737],\n",
      "        [121.9737]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352],\n",
      "        [121.9352]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025],\n",
      "        [121.9025]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712],\n",
      "        [121.8712]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424],\n",
      "        [121.8424]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181],\n",
      "        [121.8181]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994],\n",
      "        [121.7994]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853],\n",
      "        [121.7853]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752],\n",
      "        [121.7752]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7674],\n",
      "        [121.7674],\n",
      "        [121.7674],\n",
      "        [121.7674],\n",
      "        [121.7674],\n",
      "        [121.7674],\n",
      "        [121.7674],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675],\n",
      "        [121.7675]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580],\n",
      "        [121.7580]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505],\n",
      "        [121.7505]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472],\n",
      "        [121.7472]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471],\n",
      "        [121.7471]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490],\n",
      "        [121.7490]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532],\n",
      "        [121.7532]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593],\n",
      "        [121.7593]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638],\n",
      "        [121.7638]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690],\n",
      "        [121.7690]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760],\n",
      "        [121.7760]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852],\n",
      "        [121.7852]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963],\n",
      "        [121.7963]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080],\n",
      "        [121.8080]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199],\n",
      "        [121.8199]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302],\n",
      "        [121.8302]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417],\n",
      "        [121.8417]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553],\n",
      "        [121.8553]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8691],\n",
      "        [121.8690],\n",
      "        [121.8690],\n",
      "        [121.8690],\n",
      "        [121.8690],\n",
      "        [121.8690],\n",
      "        [121.8690],\n",
      "        [121.8690],\n",
      "        [121.8690],\n",
      "        [121.8690],\n",
      "        [121.8691],\n",
      "        [121.8690],\n",
      "        [121.8690],\n",
      "        [121.8690],\n",
      "        [121.8691],\n",
      "        [121.8691],\n",
      "        [121.8691],\n",
      "        [121.8691],\n",
      "        [121.8691],\n",
      "        [121.8691],\n",
      "        [121.8691],\n",
      "        [121.8691],\n",
      "        [121.8691],\n",
      "        [121.8691]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830],\n",
      "        [121.8830]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983],\n",
      "        [121.8983]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148],\n",
      "        [121.9148]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307],\n",
      "        [121.9307]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473],\n",
      "        [121.9473]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658],\n",
      "        [121.9658]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858],\n",
      "        [121.9858]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075],\n",
      "        [122.0075]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316],\n",
      "        [122.0316]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566],\n",
      "        [122.0566]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791],\n",
      "        [122.0791]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014],\n",
      "        [122.1014]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240],\n",
      "        [122.1240]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464],\n",
      "        [122.1464]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699],\n",
      "        [122.1699]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955],\n",
      "        [122.1955]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212],\n",
      "        [122.2212]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462],\n",
      "        [122.2462]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708],\n",
      "        [122.2708]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969],\n",
      "        [122.2969]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240],\n",
      "        [122.3240]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522],\n",
      "        [122.3522]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824],\n",
      "        [122.3824]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128],\n",
      "        [122.4128]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421],\n",
      "        [122.4421]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709],\n",
      "        [122.4709]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002],\n",
      "        [122.5002]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306],\n",
      "        [122.5306]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624],\n",
      "        [122.5624]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981],\n",
      "        [122.5981]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361],\n",
      "        [122.6361]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758],\n",
      "        [122.6758]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185],\n",
      "        [122.7185]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665],\n",
      "        [122.7665]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8186],\n",
      "        [122.8187],\n",
      "        [122.8186],\n",
      "        [122.8187],\n",
      "        [122.8186],\n",
      "        [122.8187],\n",
      "        [122.8187],\n",
      "        [122.8186]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8764],\n",
      "        [122.8764],\n",
      "        [122.8764],\n",
      "        [122.8764],\n",
      "        [122.8763],\n",
      "        [122.8763],\n",
      "        [122.8763]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374],\n",
      "        [122.9374]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006],\n",
      "        [123.0006]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632],\n",
      "        [123.0632]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282],\n",
      "        [123.1282]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977],\n",
      "        [123.1977]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693],\n",
      "        [123.2693]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431],\n",
      "        [123.3431]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169],\n",
      "        [123.4169]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907],\n",
      "        [123.4907]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624],\n",
      "        [123.5624]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6338],\n",
      "        [123.6339],\n",
      "        [123.6339],\n",
      "        [123.6339],\n",
      "        [123.6339],\n",
      "        [123.6339],\n",
      "        [123.6339],\n",
      "        [123.6339]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077],\n",
      "        [123.7077]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821],\n",
      "        [123.7821]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564],\n",
      "        [123.8564]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307],\n",
      "        [123.9307]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022],\n",
      "        [124.0022]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708],\n",
      "        [124.0708]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387],\n",
      "        [124.1387]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070],\n",
      "        [124.2070]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741],\n",
      "        [124.2741]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376],\n",
      "        [124.3376]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984],\n",
      "        [124.3984]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574],\n",
      "        [124.4574]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137],\n",
      "        [124.5137]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701],\n",
      "        [124.5701]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6266],\n",
      "        [124.6267],\n",
      "        [124.6267],\n",
      "        [124.6267],\n",
      "        [124.6267],\n",
      "        [124.6267],\n",
      "        [124.6266],\n",
      "        [124.6266]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822],\n",
      "        [124.6822]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367],\n",
      "        [124.7367]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910],\n",
      "        [124.7910]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463],\n",
      "        [124.8463]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004],\n",
      "        [124.9004]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550],\n",
      "        [124.9550]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119],\n",
      "        [125.0119]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707],\n",
      "        [125.0707]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323],\n",
      "        [125.1323]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964],\n",
      "        [125.1964]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623],\n",
      "        [125.2623]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252],\n",
      "        [125.3252]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837],\n",
      "        [125.3837]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357],\n",
      "        [125.4357]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871],\n",
      "        [125.4871]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382],\n",
      "        [125.5382]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899],\n",
      "        [125.5899]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412],\n",
      "        [125.6412]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919],\n",
      "        [125.6919]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429],\n",
      "        [125.7429]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940],\n",
      "        [125.7940]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477],\n",
      "        [125.8477]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9003],\n",
      "        [125.9003],\n",
      "        [125.9003],\n",
      "        [125.9003],\n",
      "        [125.9003],\n",
      "        [125.9003],\n",
      "        [125.9004],\n",
      "        [125.9003],\n",
      "        [125.9003],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004],\n",
      "        [125.9004]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524],\n",
      "        [125.9524]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011],\n",
      "        [126.0011]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430],\n",
      "        [126.0430]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806],\n",
      "        [126.0806]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162],\n",
      "        [126.1162]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485],\n",
      "        [126.1485]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759],\n",
      "        [126.1759]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959],\n",
      "        [126.1959]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078],\n",
      "        [126.2078]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084],\n",
      "        [126.2084]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056],\n",
      "        [126.2056]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028],\n",
      "        [126.2028]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1994],\n",
      "        [126.1993],\n",
      "        [126.1993],\n",
      "        [126.1993],\n",
      "        [126.1993],\n",
      "        [126.1993],\n",
      "        [126.1993],\n",
      "        [126.1993],\n",
      "        [126.1994],\n",
      "        [126.1993],\n",
      "        [126.1993],\n",
      "        [126.1993],\n",
      "        [126.1993],\n",
      "        [126.1993],\n",
      "        [126.1994],\n",
      "        [126.1994],\n",
      "        [126.1994],\n",
      "        [126.1994],\n",
      "        [126.1994],\n",
      "        [126.1994],\n",
      "        [126.1994],\n",
      "        [126.1994],\n",
      "        [126.1994],\n",
      "        [126.1994]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946],\n",
      "        [126.1946]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907],\n",
      "        [126.1907]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831],\n",
      "        [126.1831]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683],\n",
      "        [126.1683]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532],\n",
      "        [126.1532]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1405],\n",
      "        [126.1406],\n",
      "        [126.1406],\n",
      "        [126.1406],\n",
      "        [126.1406],\n",
      "        [126.1405],\n",
      "        [126.1406],\n",
      "        [126.1405],\n",
      "        [126.1405]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314],\n",
      "        [126.1314]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251],\n",
      "        [126.1251]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1155],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156],\n",
      "        [126.1156]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987],\n",
      "        [126.0987]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0814],\n",
      "        [126.0814],\n",
      "        [126.0814],\n",
      "        [126.0814],\n",
      "        [126.0814],\n",
      "        [126.0814],\n",
      "        [126.0814]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [8/10], Loss: 1848.5576\n",
      "outputs: tensor([[126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727],\n",
      "        [126.0727]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684],\n",
      "        [126.0684]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744],\n",
      "        [126.0744]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0863],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862],\n",
      "        [126.0862]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082],\n",
      "        [126.1082]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306],\n",
      "        [126.1306]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533],\n",
      "        [126.1533]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694],\n",
      "        [126.1694]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869],\n",
      "        [126.1869]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2103],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2104],\n",
      "        [126.2103],\n",
      "        [126.2103]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405],\n",
      "        [126.2405]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2730],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2730],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2730],\n",
      "        [126.2730],\n",
      "        [126.2730],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729],\n",
      "        [126.2729]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101],\n",
      "        [126.3101]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521],\n",
      "        [126.3521]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934],\n",
      "        [126.3934]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331],\n",
      "        [126.4331]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737],\n",
      "        [126.4737]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5125],\n",
      "        [126.5125],\n",
      "        [126.5125],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124],\n",
      "        [126.5124]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314],\n",
      "        [126.5314]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547],\n",
      "        [126.5547]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724],\n",
      "        [126.5724]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934],\n",
      "        [126.5934]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097],\n",
      "        [126.6097]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309],\n",
      "        [126.6309]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613],\n",
      "        [126.6613]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943],\n",
      "        [126.6943]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7310],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311],\n",
      "        [126.7311]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538],\n",
      "        [126.7538]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700],\n",
      "        [126.7700]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945],\n",
      "        [126.7945]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135],\n",
      "        [126.8135]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381],\n",
      "        [126.8381]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8686],\n",
      "        [126.8686],\n",
      "        [126.8686],\n",
      "        [126.8686],\n",
      "        [126.8686],\n",
      "        [126.8685],\n",
      "        [126.8685],\n",
      "        [126.8685]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044],\n",
      "        [126.9044]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420],\n",
      "        [126.9420]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9824],\n",
      "        [126.9824],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823],\n",
      "        [126.9823]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245],\n",
      "        [127.0245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691],\n",
      "        [127.0691]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103],\n",
      "        [127.1103]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471],\n",
      "        [127.1471]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815],\n",
      "        [127.1815]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113],\n",
      "        [127.2113]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338],\n",
      "        [127.2338]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696],\n",
      "        [127.2696]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2919],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918],\n",
      "        [127.2918]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127],\n",
      "        [127.3127]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273],\n",
      "        [127.3273]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330],\n",
      "        [127.3330]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407],\n",
      "        [127.3407]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491],\n",
      "        [127.3491]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3607],\n",
      "        [127.3607],\n",
      "        [127.3608],\n",
      "        [127.3608],\n",
      "        [127.3607],\n",
      "        [127.3607],\n",
      "        [127.3607],\n",
      "        [127.3607],\n",
      "        [127.3608],\n",
      "        [127.3608],\n",
      "        [127.3608],\n",
      "        [127.3608],\n",
      "        [127.3608],\n",
      "        [127.3608],\n",
      "        [127.3608],\n",
      "        [127.3608],\n",
      "        [127.3608],\n",
      "        [127.3607],\n",
      "        [127.3607],\n",
      "        [127.3607],\n",
      "        [127.3607],\n",
      "        [127.3607],\n",
      "        [127.3607],\n",
      "        [127.3607]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766],\n",
      "        [127.3766]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855],\n",
      "        [127.3855]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889],\n",
      "        [127.3889]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963],\n",
      "        [127.3963]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999],\n",
      "        [127.3999]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892],\n",
      "        [127.3892]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3826],\n",
      "        [127.3826],\n",
      "        [127.3826],\n",
      "        [127.3826],\n",
      "        [127.3826],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825],\n",
      "        [127.3825]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784],\n",
      "        [127.3784]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745],\n",
      "        [127.3745]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617],\n",
      "        [127.3617]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448],\n",
      "        [127.3448]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223],\n",
      "        [127.3223]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818],\n",
      "        [127.2818]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444],\n",
      "        [127.2444]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927],\n",
      "        [127.1927]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489],\n",
      "        [127.1489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981],\n",
      "        [127.0981]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354],\n",
      "        [127.0354]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645],\n",
      "        [126.9645]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874],\n",
      "        [126.8874]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024],\n",
      "        [126.8024]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.7147],\n",
      "        [126.7147],\n",
      "        [126.7147],\n",
      "        [126.7147],\n",
      "        [126.7147],\n",
      "        [126.7147],\n",
      "        [126.7147],\n",
      "        [126.7147],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7148],\n",
      "        [126.7147]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6121],\n",
      "        [126.6121],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6122],\n",
      "        [126.6121],\n",
      "        [126.6122],\n",
      "        [126.6121],\n",
      "        [126.6121]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862],\n",
      "        [126.4862]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.3543],\n",
      "        [126.3543],\n",
      "        [126.3543],\n",
      "        [126.3543],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3542],\n",
      "        [126.3543],\n",
      "        [126.3543],\n",
      "        [126.3543],\n",
      "        [126.3543],\n",
      "        [126.3543]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2213],\n",
      "        [126.2213],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2212],\n",
      "        [126.2213],\n",
      "        [126.2213],\n",
      "        [126.2213]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0908],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909],\n",
      "        [126.0909]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714],\n",
      "        [125.9714]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634],\n",
      "        [125.8634]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526],\n",
      "        [125.7526]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394],\n",
      "        [125.6394]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5180],\n",
      "        [125.5180],\n",
      "        [125.5180],\n",
      "        [125.5180],\n",
      "        [125.5180],\n",
      "        [125.5180],\n",
      "        [125.5180],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181],\n",
      "        [125.5181]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982],\n",
      "        [125.3982]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787],\n",
      "        [125.2787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1695],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696],\n",
      "        [125.1696]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754],\n",
      "        [125.0754]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934],\n",
      "        [124.9934]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105],\n",
      "        [124.9105]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247],\n",
      "        [124.8247]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424],\n",
      "        [124.7424]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660],\n",
      "        [124.6660]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992],\n",
      "        [124.5992]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422],\n",
      "        [124.5422]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917],\n",
      "        [124.4917]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475],\n",
      "        [124.4475]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049],\n",
      "        [124.4049]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651],\n",
      "        [124.3651]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304],\n",
      "        [124.3304]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018],\n",
      "        [124.3018]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785],\n",
      "        [124.2785]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595],\n",
      "        [124.2595]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431],\n",
      "        [124.2431]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249],\n",
      "        [124.2249]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089],\n",
      "        [124.2089]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976],\n",
      "        [124.1976]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898],\n",
      "        [124.1898]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842],\n",
      "        [124.1842]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812],\n",
      "        [124.1812]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804],\n",
      "        [124.1804]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778],\n",
      "        [124.1778]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760],\n",
      "        [124.1760]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762],\n",
      "        [124.1762]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788],\n",
      "        [124.1788]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836],\n",
      "        [124.1836]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890],\n",
      "        [124.1890]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947],\n",
      "        [124.1947]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987],\n",
      "        [124.1987]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040],\n",
      "        [124.2040]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2117],\n",
      "        [124.2117],\n",
      "        [124.2117],\n",
      "        [124.2117],\n",
      "        [124.2117],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2117],\n",
      "        [124.2117],\n",
      "        [124.2116],\n",
      "        [124.2116],\n",
      "        [124.2116]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2195],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2194],\n",
      "        [124.2195],\n",
      "        [124.2195],\n",
      "        [124.2195],\n",
      "        [124.2195],\n",
      "        [124.2195],\n",
      "        [124.2195],\n",
      "        [124.2195],\n",
      "        [124.2195],\n",
      "        [124.2195]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275],\n",
      "        [124.2275]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371],\n",
      "        [124.2371]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480],\n",
      "        [124.2480]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583],\n",
      "        [124.2583]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693],\n",
      "        [124.2693]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824],\n",
      "        [124.2824]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972],\n",
      "        [124.2972]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140],\n",
      "        [124.3140]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333],\n",
      "        [124.3333]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537],\n",
      "        [124.3537]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714],\n",
      "        [124.3714]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888],\n",
      "        [124.3888]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066],\n",
      "        [124.4066]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242],\n",
      "        [124.4242]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429],\n",
      "        [124.4429]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641],\n",
      "        [124.4641]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854],\n",
      "        [124.4854]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059],\n",
      "        [124.5059]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259],\n",
      "        [124.5259]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477],\n",
      "        [124.5477]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705],\n",
      "        [124.5705]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945],\n",
      "        [124.5945]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208],\n",
      "        [124.6208]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473],\n",
      "        [124.6473]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.6727],\n",
      "        [124.6726],\n",
      "        [124.6727],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6726],\n",
      "        [124.6727],\n",
      "        [124.6727],\n",
      "        [124.6727],\n",
      "        [124.6727],\n",
      "        [124.6727],\n",
      "        [124.6727],\n",
      "        [124.6727],\n",
      "        [124.6727]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974],\n",
      "        [124.6974]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227],\n",
      "        [124.7227]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493],\n",
      "        [124.7493]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774],\n",
      "        [124.7774]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098],\n",
      "        [124.8098]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448],\n",
      "        [124.8448]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816],\n",
      "        [124.8816]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218],\n",
      "        [124.9218]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[124.9678],\n",
      "        [124.9677],\n",
      "        [124.9678],\n",
      "        [124.9678],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9677],\n",
      "        [124.9678],\n",
      "        [124.9678],\n",
      "        [124.9678],\n",
      "        [124.9678],\n",
      "        [124.9678],\n",
      "        [124.9678],\n",
      "        [124.9678],\n",
      "        [124.9678]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184],\n",
      "        [125.0184]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751],\n",
      "        [125.0751]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356],\n",
      "        [125.1356]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984],\n",
      "        [125.1984]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605],\n",
      "        [125.2605]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253],\n",
      "        [125.3253]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950],\n",
      "        [125.3950]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671],\n",
      "        [125.4671]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416],\n",
      "        [125.5416]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161],\n",
      "        [125.6161]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906],\n",
      "        [125.6906]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628],\n",
      "        [125.7628]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346],\n",
      "        [125.8346]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092],\n",
      "        [125.9092]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844],\n",
      "        [125.9844]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594],\n",
      "        [126.0594]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344],\n",
      "        [126.1344]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064],\n",
      "        [126.2064]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751],\n",
      "        [126.2751]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431],\n",
      "        [126.3431]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115],\n",
      "        [126.4115]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785],\n",
      "        [126.4785]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417],\n",
      "        [126.5417]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018],\n",
      "        [126.6018]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599],\n",
      "        [126.6599]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150],\n",
      "        [126.7150]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704],\n",
      "        [126.7704]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258],\n",
      "        [126.8258]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8801],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802],\n",
      "        [126.8802]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333],\n",
      "        [126.9333]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863],\n",
      "        [126.9863]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403],\n",
      "        [127.0403]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930],\n",
      "        [127.0930]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463],\n",
      "        [127.1463]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021],\n",
      "        [127.2021]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600],\n",
      "        [127.2600]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209],\n",
      "        [127.3209]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847],\n",
      "        [127.3847]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503],\n",
      "        [127.4503]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128],\n",
      "        [127.5128]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703],\n",
      "        [127.5703]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207],\n",
      "        [127.6207]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705],\n",
      "        [127.6705]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199],\n",
      "        [127.7199]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699],\n",
      "        [127.7699]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196],\n",
      "        [127.8196]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684],\n",
      "        [127.8684]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178],\n",
      "        [127.9178]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671],\n",
      "        [127.9671]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195],\n",
      "        [128.0195]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705],\n",
      "        [128.0705]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210],\n",
      "        [128.1210]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677],\n",
      "        [128.1677]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070],\n",
      "        [128.2070]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415],\n",
      "        [128.2415]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738],\n",
      "        [128.2738]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025],\n",
      "        [128.3025]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258],\n",
      "        [128.3258]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3410],\n",
      "        [128.3410],\n",
      "        [128.3409],\n",
      "        [128.3410],\n",
      "        [128.3409],\n",
      "        [128.3409],\n",
      "        [128.3409],\n",
      "        [128.3409],\n",
      "        [128.3409],\n",
      "        [128.3409],\n",
      "        [128.3409],\n",
      "        [128.3409],\n",
      "        [128.3409],\n",
      "        [128.3409],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472],\n",
      "        [128.3472]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410],\n",
      "        [128.3410]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310],\n",
      "        [128.3310]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211],\n",
      "        [128.3211]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105],\n",
      "        [128.3105]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2983],\n",
      "        [128.2984],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2984],\n",
      "        [128.2984],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983],\n",
      "        [128.2983]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873],\n",
      "        [128.2873]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721],\n",
      "        [128.2721]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490],\n",
      "        [128.2490]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2257],\n",
      "        [128.2257],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2256],\n",
      "        [128.2257],\n",
      "        [128.2257],\n",
      "        [128.2257],\n",
      "        [128.2257],\n",
      "        [128.2257],\n",
      "        [128.2257],\n",
      "        [128.2257],\n",
      "        [128.2257]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049],\n",
      "        [128.2049]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881],\n",
      "        [128.1881]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745],\n",
      "        [128.1745]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572],\n",
      "        [128.1572]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319],\n",
      "        [128.1319]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1063],\n",
      "        [128.1063],\n",
      "        [128.1063],\n",
      "        [128.1063],\n",
      "        [128.1063],\n",
      "        [128.1063],\n",
      "        [128.1063]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [9/10], Loss: 1831.4367\n",
      "outputs: tensor([[128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900],\n",
      "        [128.0900]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787],\n",
      "        [128.0787]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786],\n",
      "        [128.0786]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850],\n",
      "        [128.0850]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026],\n",
      "        [128.1026]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207],\n",
      "        [128.1207]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391],\n",
      "        [128.1391]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503],\n",
      "        [128.1503]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630],\n",
      "        [128.1630]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823],\n",
      "        [128.1823]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090],\n",
      "        [128.2090]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382],\n",
      "        [128.2382]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726],\n",
      "        [128.2726]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3124],\n",
      "        [128.3124],\n",
      "        [128.3123],\n",
      "        [128.3123],\n",
      "        [128.3123],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124],\n",
      "        [128.3124]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513],\n",
      "        [128.3513]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886],\n",
      "        [128.3886]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269],\n",
      "        [128.4269]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4631],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630],\n",
      "        [128.4630]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775],\n",
      "        [128.4775]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967],\n",
      "        [128.4967]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098],\n",
      "        [128.5098]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266],\n",
      "        [128.5266]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381],\n",
      "        [128.5381]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551],\n",
      "        [128.5551]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822],\n",
      "        [128.5822]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121],\n",
      "        [128.6121]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463],\n",
      "        [128.6463]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650],\n",
      "        [128.6650]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765],\n",
      "        [128.6765]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6972],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6972],\n",
      "        [128.6972],\n",
      "        [128.6972],\n",
      "        [128.6972],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971],\n",
      "        [128.6971]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118],\n",
      "        [128.7118]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326],\n",
      "        [128.7326]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598],\n",
      "        [128.7598]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7930],\n",
      "        [128.7929],\n",
      "        [128.7930],\n",
      "        [128.7930],\n",
      "        [128.7930],\n",
      "        [128.7930],\n",
      "        [128.7929],\n",
      "        [128.7930],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929],\n",
      "        [128.7929]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281],\n",
      "        [128.8281]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662],\n",
      "        [128.8662]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063],\n",
      "        [128.9063]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491],\n",
      "        [128.9491]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882],\n",
      "        [128.9882]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225],\n",
      "        [129.0225]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541],\n",
      "        [129.0541]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807],\n",
      "        [129.0807]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992],\n",
      "        [129.0992]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094],\n",
      "        [129.1094]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263],\n",
      "        [129.1263]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446],\n",
      "        [129.1446]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614],\n",
      "        [129.1614]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713],\n",
      "        [129.1713]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714],\n",
      "        [129.1714]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737],\n",
      "        [129.1737]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769],\n",
      "        [129.1769]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836],\n",
      "        [129.1836]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1949],\n",
      "        [129.1949],\n",
      "        [129.1949],\n",
      "        [129.1949],\n",
      "        [129.1949],\n",
      "        [129.1949],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1950],\n",
      "        [129.1949],\n",
      "        [129.1950],\n",
      "        [129.1949],\n",
      "        [129.1949]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986],\n",
      "        [129.1986]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1964],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1964],\n",
      "        [129.1964],\n",
      "        [129.1964]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984],\n",
      "        [129.1984]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1964],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963],\n",
      "        [129.1963]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785],\n",
      "        [129.1785]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653],\n",
      "        [129.1653]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547],\n",
      "        [129.1547]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445],\n",
      "        [129.1445]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245],\n",
      "        [129.1245]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000],\n",
      "        [129.1000]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693],\n",
      "        [129.0693]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190],\n",
      "        [129.0190]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720],\n",
      "        [128.9720]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094],\n",
      "        [128.9094]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556],\n",
      "        [128.8556]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940],\n",
      "        [128.7940]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195],\n",
      "        [128.7195]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360],\n",
      "        [128.6360]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458],\n",
      "        [128.5458]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.4469],\n",
      "        [128.4469],\n",
      "        [128.4469],\n",
      "        [128.4469],\n",
      "        [128.4469],\n",
      "        [128.4469],\n",
      "        [128.4469],\n",
      "        [128.4469],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4470],\n",
      "        [128.4469],\n",
      "        [128.4469],\n",
      "        [128.4469]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452],\n",
      "        [128.3452]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272],\n",
      "        [128.2272]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.0837],\n",
      "        [128.0837],\n",
      "        [128.0837],\n",
      "        [128.0837],\n",
      "        [128.0837],\n",
      "        [128.0837],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0837],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0837],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0838],\n",
      "        [128.0838]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.9339],\n",
      "        [127.9339],\n",
      "        [127.9339],\n",
      "        [127.9339],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9338],\n",
      "        [127.9339],\n",
      "        [127.9339],\n",
      "        [127.9339],\n",
      "        [127.9339],\n",
      "        [127.9339]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.7829],\n",
      "        [127.7829],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7828],\n",
      "        [127.7829],\n",
      "        [127.7829],\n",
      "        [127.7829]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348],\n",
      "        [127.6348]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987],\n",
      "        [127.4987]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752],\n",
      "        [127.3752]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487],\n",
      "        [127.2487]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.1197],\n",
      "        [127.1197],\n",
      "        [127.1197],\n",
      "        [127.1197],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1196],\n",
      "        [127.1197],\n",
      "        [127.1197],\n",
      "        [127.1197],\n",
      "        [127.1197],\n",
      "        [127.1197],\n",
      "        [127.1197],\n",
      "        [127.1197],\n",
      "        [127.1197]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817],\n",
      "        [126.9817]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455],\n",
      "        [126.8455]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098],\n",
      "        [126.7098]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5855],\n",
      "        [126.5854],\n",
      "        [126.5854],\n",
      "        [126.5855],\n",
      "        [126.5854]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775],\n",
      "        [126.4775]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.3829],\n",
      "        [126.3829],\n",
      "        [126.3829],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3828],\n",
      "        [126.3829],\n",
      "        [126.3829],\n",
      "        [126.3829],\n",
      "        [126.3829],\n",
      "        [126.3829],\n",
      "        [126.3829]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873],\n",
      "        [126.2873]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887],\n",
      "        [126.1887]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939],\n",
      "        [126.0939]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056],\n",
      "        [126.0056]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.9279],\n",
      "        [125.9279],\n",
      "        [125.9279],\n",
      "        [125.9279],\n",
      "        [125.9278],\n",
      "        [125.9278],\n",
      "        [125.9279],\n",
      "        [125.9278],\n",
      "        [125.9278],\n",
      "        [125.9278],\n",
      "        [125.9278],\n",
      "        [125.9278],\n",
      "        [125.9278],\n",
      "        [125.9278],\n",
      "        [125.9278],\n",
      "        [125.9278],\n",
      "        [125.9279],\n",
      "        [125.9279],\n",
      "        [125.9279],\n",
      "        [125.9279],\n",
      "        [125.9279],\n",
      "        [125.9279],\n",
      "        [125.9279],\n",
      "        [125.9279]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609],\n",
      "        [125.8609]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010],\n",
      "        [125.8010]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481],\n",
      "        [125.7481]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969],\n",
      "        [125.6969]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489],\n",
      "        [125.6489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064],\n",
      "        [125.6064]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707],\n",
      "        [125.5707]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407],\n",
      "        [125.5407]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155],\n",
      "        [125.5155]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932],\n",
      "        [125.4932]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4689],\n",
      "        [125.4689],\n",
      "        [125.4689],\n",
      "        [125.4690],\n",
      "        [125.4689],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690],\n",
      "        [125.4690]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471],\n",
      "        [125.4471]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304],\n",
      "        [125.4304]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176],\n",
      "        [125.4176]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072],\n",
      "        [125.4072]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997],\n",
      "        [125.3997]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945],\n",
      "        [125.3945]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3875],\n",
      "        [125.3876]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774],\n",
      "        [125.3774]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761],\n",
      "        [125.3761]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772],\n",
      "        [125.3772]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790],\n",
      "        [125.3790]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812],\n",
      "        [125.3812]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3815],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3814],\n",
      "        [125.3815],\n",
      "        [125.3815],\n",
      "        [125.3815],\n",
      "        [125.3815],\n",
      "        [125.3815],\n",
      "        [125.3815],\n",
      "        [125.3815],\n",
      "        [125.3815]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831],\n",
      "        [125.3831]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874],\n",
      "        [125.3874]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919],\n",
      "        [125.3919]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967],\n",
      "        [125.3967]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031],\n",
      "        [125.4031]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4110],\n",
      "        [125.4110],\n",
      "        [125.4110],\n",
      "        [125.4110],\n",
      "        [125.4110],\n",
      "        [125.4110],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111],\n",
      "        [125.4111]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182],\n",
      "        [125.4182]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263],\n",
      "        [125.4263]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367],\n",
      "        [125.4367]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489],\n",
      "        [125.4489]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632],\n",
      "        [125.4632]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804],\n",
      "        [125.4804]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988],\n",
      "        [125.4988]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141],\n",
      "        [125.5141]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293],\n",
      "        [125.5293]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448],\n",
      "        [125.5448]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601],\n",
      "        [125.5601]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767],\n",
      "        [125.5767]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959],\n",
      "        [125.5959]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153],\n",
      "        [125.6153]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338],\n",
      "        [125.6338]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518],\n",
      "        [125.6518]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717],\n",
      "        [125.6717]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928],\n",
      "        [125.6928]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152],\n",
      "        [125.7152]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401],\n",
      "        [125.7401]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.7652],\n",
      "        [125.7652],\n",
      "        [125.7652],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7651],\n",
      "        [125.7652],\n",
      "        [125.7652],\n",
      "        [125.7652],\n",
      "        [125.7652],\n",
      "        [125.7652],\n",
      "        [125.7652],\n",
      "        [125.7652],\n",
      "        [125.7652]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890],\n",
      "        [125.7890]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8122],\n",
      "        [125.8123],\n",
      "        [125.8123],\n",
      "        [125.8123],\n",
      "        [125.8123],\n",
      "        [125.8123],\n",
      "        [125.8123],\n",
      "        [125.8122]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361],\n",
      "        [125.8361]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612],\n",
      "        [125.8612]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881],\n",
      "        [125.8881]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197],\n",
      "        [125.9197]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541],\n",
      "        [125.9541]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905],\n",
      "        [125.9905]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306],\n",
      "        [126.0306]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769],\n",
      "        [126.0769]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284],\n",
      "        [126.1284]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1865],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1865],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866],\n",
      "        [126.1866]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488],\n",
      "        [126.2488]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135],\n",
      "        [126.3135]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775],\n",
      "        [126.3775]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445],\n",
      "        [126.4445]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167],\n",
      "        [126.5167]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916],\n",
      "        [126.5916]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691],\n",
      "        [126.6691]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466],\n",
      "        [126.7466]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241],\n",
      "        [126.8241]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991],\n",
      "        [126.8991]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736],\n",
      "        [126.9736]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511],\n",
      "        [127.0511]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294],\n",
      "        [127.1294]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074],\n",
      "        [127.2074]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854],\n",
      "        [127.2854]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600],\n",
      "        [127.3600]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4311],\n",
      "        [127.4312],\n",
      "        [127.4312],\n",
      "        [127.4312],\n",
      "        [127.4312],\n",
      "        [127.4311],\n",
      "        [127.4312],\n",
      "        [127.4311]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014],\n",
      "        [127.5014]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722],\n",
      "        [127.5722]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414],\n",
      "        [127.6414]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064],\n",
      "        [127.7064]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680],\n",
      "        [127.7680]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8275],\n",
      "        [127.8276],\n",
      "        [127.8276],\n",
      "        [127.8276],\n",
      "        [127.8276],\n",
      "        [127.8276],\n",
      "        [127.8276],\n",
      "        [127.8276],\n",
      "        [127.8276]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837],\n",
      "        [127.8837]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402],\n",
      "        [127.9402]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967],\n",
      "        [127.9967]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520],\n",
      "        [128.0520]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060],\n",
      "        [128.1060]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1599],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598],\n",
      "        [128.1598]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148],\n",
      "        [128.2148]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684],\n",
      "        [128.2684]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225],\n",
      "        [128.3225]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793],\n",
      "        [128.3793]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4384],\n",
      "        [128.4384],\n",
      "        [128.4384],\n",
      "        [128.4384],\n",
      "        [128.4384],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385],\n",
      "        [128.4385]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009],\n",
      "        [128.5009]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665],\n",
      "        [128.5665]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340],\n",
      "        [128.6340]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981],\n",
      "        [128.6981]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568],\n",
      "        [128.7568]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077],\n",
      "        [128.8077]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579],\n",
      "        [128.8579]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078],\n",
      "        [128.9078]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583],\n",
      "        [128.9583]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084],\n",
      "        [129.0084]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576],\n",
      "        [129.0576]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073],\n",
      "        [129.1073]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571],\n",
      "        [129.1571]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100],\n",
      "        [129.2100]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616],\n",
      "        [129.2616]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125],\n",
      "        [129.3125]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594],\n",
      "        [129.3594]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981],\n",
      "        [129.3981]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317],\n",
      "        [129.4317]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628],\n",
      "        [129.4628]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899],\n",
      "        [129.4899]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112],\n",
      "        [129.5112]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237],\n",
      "        [129.5237]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5264],\n",
      "        [129.5264],\n",
      "        [129.5264],\n",
      "        [129.5264],\n",
      "        [129.5263],\n",
      "        [129.5263],\n",
      "        [129.5263]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155],\n",
      "        [129.5155]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006],\n",
      "        [129.5006]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857],\n",
      "        [129.4857]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700],\n",
      "        [129.4700]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527],\n",
      "        [129.4527]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366],\n",
      "        [129.4366]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160],\n",
      "        [129.4160]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868],\n",
      "        [129.3868]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.3573],\n",
      "        [129.3573],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3572],\n",
      "        [129.3573],\n",
      "        [129.3573],\n",
      "        [129.3573],\n",
      "        [129.3573],\n",
      "        [129.3573],\n",
      "        [129.3573],\n",
      "        [129.3573],\n",
      "        [129.3572]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306],\n",
      "        [129.3306]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.3082],\n",
      "        [129.3083],\n",
      "        [129.3082],\n",
      "        [129.3082],\n",
      "        [129.3083],\n",
      "        [129.3083],\n",
      "        [129.3082],\n",
      "        [129.3082],\n",
      "        [129.3082],\n",
      "        [129.3082],\n",
      "        [129.3082],\n",
      "        [129.3082],\n",
      "        [129.3082],\n",
      "        [129.3082],\n",
      "        [129.3083],\n",
      "        [129.3083],\n",
      "        [129.3083],\n",
      "        [129.3083],\n",
      "        [129.3083],\n",
      "        [129.3083],\n",
      "        [129.3083],\n",
      "        [129.3083],\n",
      "        [129.3083],\n",
      "        [129.3083]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894],\n",
      "        [129.2894]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666],\n",
      "        [129.2666]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351],\n",
      "        [129.2351]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "outputs: tensor([[129.2031],\n",
      "        [129.2031],\n",
      "        [129.2031],\n",
      "        [129.2031],\n",
      "        [129.2031],\n",
      "        [129.2031],\n",
      "        [129.2031]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "Epoch [10/10], Loss: 1828.7033\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "model = train(model, dataloader, criterion, optimizer, epoches, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 예측(미완)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### X 데이터\n",
    "\n",
    "- 제주 기상 예측 (n+1)\n",
    "- 제주 전력 시장 실시간 (n-1)\n",
    "- 제주 전력 시장 현황 (n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [weather_forecast_1, smp_rt_rc, elec_supply]\n",
    "\n",
    "input_data = reduce(lambda left, right: pd.merge(left, right, on='datetime', how='inner'), dfs)\n",
    "\n",
    "target_day = datetime.strptime(target_date['predict_target_date'], '%Y-%m-%d')\n",
    "\n",
    "input_data = input_data.loc[\n",
    "  (input_data['datetime'] > target_day) &\n",
    "  (input_data['datetime'] <= target_day + timedelta(days=1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>real_feel_temp</th>\n",
       "      <th>rel_hum</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>wind_spd</th>\n",
       "      <th>wind_gust_spd</th>\n",
       "      <th>uv_idx</th>\n",
       "      <th>vis</th>\n",
       "      <th>...</th>\n",
       "      <th>precip_1h</th>\n",
       "      <th>실시간 임시 가격(원/kWh)</th>\n",
       "      <th>실시간 확정 가격(원/kWh)</th>\n",
       "      <th>공급능력(kW)</th>\n",
       "      <th>현재 수요(kW)</th>\n",
       "      <th>태양광 발전량kW)</th>\n",
       "      <th>풍력 발전량(kW)</th>\n",
       "      <th>신재생 발전량 총합(kW)</th>\n",
       "      <th>공급 예비력(kW)</th>\n",
       "      <th>운영 예비력(kW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>2024-11-03 01:00:00</td>\n",
       "      <td>18.209867</td>\n",
       "      <td>16.358033</td>\n",
       "      <td>76.888889</td>\n",
       "      <td>14.074067</td>\n",
       "      <td>60.777778</td>\n",
       "      <td>17.327300</td>\n",
       "      <td>30.255644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.924000</td>\n",
       "      <td>108.924000</td>\n",
       "      <td>1.139692e+06</td>\n",
       "      <td>528153.846154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77352.069231</td>\n",
       "      <td>77597.192308</td>\n",
       "      <td>581615.384615</td>\n",
       "      <td>364769.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>2024-11-03 02:00:00</td>\n",
       "      <td>17.716044</td>\n",
       "      <td>15.925922</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>13.641967</td>\n",
       "      <td>55.222222</td>\n",
       "      <td>17.523989</td>\n",
       "      <td>29.433111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.236667</td>\n",
       "      <td>103.236667</td>\n",
       "      <td>1.155455e+06</td>\n",
       "      <td>511090.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86352.463636</td>\n",
       "      <td>86597.045455</td>\n",
       "      <td>625363.636364</td>\n",
       "      <td>398727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>2024-11-03 03:00:00</td>\n",
       "      <td>17.469133</td>\n",
       "      <td>15.679022</td>\n",
       "      <td>77.888889</td>\n",
       "      <td>13.580233</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>17.112711</td>\n",
       "      <td>28.628433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.398000</td>\n",
       "      <td>98.398000</td>\n",
       "      <td>1.162154e+06</td>\n",
       "      <td>504692.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92392.100000</td>\n",
       "      <td>92636.153846</td>\n",
       "      <td>647846.153846</td>\n",
       "      <td>373923.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5796</th>\n",
       "      <td>2024-11-03 04:00:00</td>\n",
       "      <td>17.098756</td>\n",
       "      <td>15.246933</td>\n",
       "      <td>79.333333</td>\n",
       "      <td>13.518500</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>17.130600</td>\n",
       "      <td>27.805878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.116667</td>\n",
       "      <td>95.116667</td>\n",
       "      <td>1.188909e+06</td>\n",
       "      <td>491454.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117552.909091</td>\n",
       "      <td>117796.636364</td>\n",
       "      <td>687363.636364</td>\n",
       "      <td>408000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5797</th>\n",
       "      <td>2024-11-03 05:00:00</td>\n",
       "      <td>17.160489</td>\n",
       "      <td>15.246911</td>\n",
       "      <td>78.777778</td>\n",
       "      <td>13.395056</td>\n",
       "      <td>32.777778</td>\n",
       "      <td>16.486867</td>\n",
       "      <td>26.965444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.490000</td>\n",
       "      <td>102.490000</td>\n",
       "      <td>1.219462e+06</td>\n",
       "      <td>506769.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148452.769231</td>\n",
       "      <td>148696.307692</td>\n",
       "      <td>710384.615385</td>\n",
       "      <td>424076.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>2024-11-03 06:00:00</td>\n",
       "      <td>17.037033</td>\n",
       "      <td>15.308656</td>\n",
       "      <td>78.888889</td>\n",
       "      <td>13.395056</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>15.861011</td>\n",
       "      <td>25.964078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.500000</td>\n",
       "      <td>104.500000</td>\n",
       "      <td>1.213364e+06</td>\n",
       "      <td>524272.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143401.181818</td>\n",
       "      <td>143643.363636</td>\n",
       "      <td>684363.636364</td>\n",
       "      <td>402363.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>2024-11-03 07:00:00</td>\n",
       "      <td>16.913567</td>\n",
       "      <td>15.432111</td>\n",
       "      <td>80.222222</td>\n",
       "      <td>13.456778</td>\n",
       "      <td>41.111111</td>\n",
       "      <td>15.235156</td>\n",
       "      <td>25.123656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.480000</td>\n",
       "      <td>116.480000</td>\n",
       "      <td>1.223154e+06</td>\n",
       "      <td>565384.615385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151426.230769</td>\n",
       "      <td>151670.153846</td>\n",
       "      <td>653000.000000</td>\n",
       "      <td>369000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>2024-11-03 08:00:00</td>\n",
       "      <td>18.086411</td>\n",
       "      <td>17.407400</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>13.703689</td>\n",
       "      <td>37.777778</td>\n",
       "      <td>15.253033</td>\n",
       "      <td>24.515678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137.910000</td>\n",
       "      <td>137.910000</td>\n",
       "      <td>1.237727e+06</td>\n",
       "      <td>622727.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165409.000000</td>\n",
       "      <td>165729.000000</td>\n",
       "      <td>610181.818182</td>\n",
       "      <td>378909.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>2024-11-03 09:00:00</td>\n",
       "      <td>19.320978</td>\n",
       "      <td>19.074067</td>\n",
       "      <td>70.888889</td>\n",
       "      <td>13.888867</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>15.449733</td>\n",
       "      <td>24.301089</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.890000</td>\n",
       "      <td>150.890000</td>\n",
       "      <td>1.262538e+06</td>\n",
       "      <td>664461.538462</td>\n",
       "      <td>1884.663846</td>\n",
       "      <td>188450.153846</td>\n",
       "      <td>190779.846154</td>\n",
       "      <td>593153.846154</td>\n",
       "      <td>362153.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>2024-11-03 10:00:00</td>\n",
       "      <td>20.555556</td>\n",
       "      <td>21.049378</td>\n",
       "      <td>66.888889</td>\n",
       "      <td>14.197500</td>\n",
       "      <td>109.888889</td>\n",
       "      <td>14.859633</td>\n",
       "      <td>23.496422</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148.923333</td>\n",
       "      <td>148.923333</td>\n",
       "      <td>1.280000e+06</td>\n",
       "      <td>690545.454545</td>\n",
       "      <td>3222.000909</td>\n",
       "      <td>204576.636364</td>\n",
       "      <td>208088.909091</td>\n",
       "      <td>584909.090909</td>\n",
       "      <td>353909.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>2024-11-03 11:00:00</td>\n",
       "      <td>21.419767</td>\n",
       "      <td>22.222211</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>14.135767</td>\n",
       "      <td>101.444444</td>\n",
       "      <td>14.859633</td>\n",
       "      <td>22.423533</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.514000</td>\n",
       "      <td>141.514000</td>\n",
       "      <td>1.278615e+06</td>\n",
       "      <td>696307.692308</td>\n",
       "      <td>5440.853077</td>\n",
       "      <td>200946.923077</td>\n",
       "      <td>206677.846154</td>\n",
       "      <td>577461.538462</td>\n",
       "      <td>346230.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>2024-11-03 12:00:00</td>\n",
       "      <td>22.037033</td>\n",
       "      <td>22.777767</td>\n",
       "      <td>59.444444</td>\n",
       "      <td>14.012322</td>\n",
       "      <td>162.666667</td>\n",
       "      <td>14.645056</td>\n",
       "      <td>22.244733</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>15.37814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.916667</td>\n",
       "      <td>128.916667</td>\n",
       "      <td>1.268636e+06</td>\n",
       "      <td>700727.272727</td>\n",
       "      <td>3809.337273</td>\n",
       "      <td>191933.454545</td>\n",
       "      <td>196032.818182</td>\n",
       "      <td>563000.000000</td>\n",
       "      <td>331909.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>2024-11-03 13:00:00</td>\n",
       "      <td>22.839511</td>\n",
       "      <td>23.580233</td>\n",
       "      <td>56.888889</td>\n",
       "      <td>13.950600</td>\n",
       "      <td>174.222222</td>\n",
       "      <td>15.074211</td>\n",
       "      <td>21.851344</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.314000</td>\n",
       "      <td>115.314000</td>\n",
       "      <td>1.260308e+06</td>\n",
       "      <td>711692.307692</td>\n",
       "      <td>3216.756154</td>\n",
       "      <td>185112.307692</td>\n",
       "      <td>188531.153846</td>\n",
       "      <td>543692.307692</td>\n",
       "      <td>312846.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>2024-11-03 14:00:00</td>\n",
       "      <td>22.530856</td>\n",
       "      <td>22.716033</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>14.012333</td>\n",
       "      <td>182.444444</td>\n",
       "      <td>15.664311</td>\n",
       "      <td>22.655978</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.953333</td>\n",
       "      <td>113.953333</td>\n",
       "      <td>1.270273e+06</td>\n",
       "      <td>713909.090909</td>\n",
       "      <td>4464.423636</td>\n",
       "      <td>193692.909091</td>\n",
       "      <td>198330.272727</td>\n",
       "      <td>551272.727273</td>\n",
       "      <td>320727.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5807</th>\n",
       "      <td>2024-11-03 15:00:00</td>\n",
       "      <td>21.851867</td>\n",
       "      <td>21.543222</td>\n",
       "      <td>60.333333</td>\n",
       "      <td>14.012333</td>\n",
       "      <td>183.888889</td>\n",
       "      <td>15.700067</td>\n",
       "      <td>24.104411</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.37814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028222</td>\n",
       "      <td>113.732000</td>\n",
       "      <td>113.732000</td>\n",
       "      <td>1.272000e+06</td>\n",
       "      <td>698615.384615</td>\n",
       "      <td>5389.608462</td>\n",
       "      <td>194680.461538</td>\n",
       "      <td>200145.076923</td>\n",
       "      <td>568615.384615</td>\n",
       "      <td>337000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5808</th>\n",
       "      <td>2024-11-03 16:00:00</td>\n",
       "      <td>21.358022</td>\n",
       "      <td>20.679022</td>\n",
       "      <td>62.444444</td>\n",
       "      <td>14.012333</td>\n",
       "      <td>184.111111</td>\n",
       "      <td>14.430478</td>\n",
       "      <td>23.067256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119.056667</td>\n",
       "      <td>119.056667</td>\n",
       "      <td>1.281727e+06</td>\n",
       "      <td>694636.363636</td>\n",
       "      <td>1842.583636</td>\n",
       "      <td>207820.272727</td>\n",
       "      <td>209796.636364</td>\n",
       "      <td>582454.545455</td>\n",
       "      <td>351636.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5809</th>\n",
       "      <td>2024-11-03 17:00:00</td>\n",
       "      <td>20.679033</td>\n",
       "      <td>19.197533</td>\n",
       "      <td>65.555556</td>\n",
       "      <td>13.888878</td>\n",
       "      <td>148.222222</td>\n",
       "      <td>13.214522</td>\n",
       "      <td>22.226811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>131.206000</td>\n",
       "      <td>131.206000</td>\n",
       "      <td>1.268615e+06</td>\n",
       "      <td>707153.846154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>198144.076923</td>\n",
       "      <td>198321.230769</td>\n",
       "      <td>556615.384615</td>\n",
       "      <td>327230.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5810</th>\n",
       "      <td>2024-11-03 18:00:00</td>\n",
       "      <td>19.567889</td>\n",
       "      <td>18.024689</td>\n",
       "      <td>70.222222</td>\n",
       "      <td>13.827144</td>\n",
       "      <td>73.222222</td>\n",
       "      <td>11.336956</td>\n",
       "      <td>22.441411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>131.260000</td>\n",
       "      <td>131.260000</td>\n",
       "      <td>1.302455e+06</td>\n",
       "      <td>716363.636364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>233242.545455</td>\n",
       "      <td>233358.545455</td>\n",
       "      <td>581272.727273</td>\n",
       "      <td>353272.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5811</th>\n",
       "      <td>2024-11-03 19:00:00</td>\n",
       "      <td>18.209867</td>\n",
       "      <td>17.160489</td>\n",
       "      <td>75.111111</td>\n",
       "      <td>13.827144</td>\n",
       "      <td>70.111111</td>\n",
       "      <td>10.728978</td>\n",
       "      <td>21.618844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.588000</td>\n",
       "      <td>121.588000</td>\n",
       "      <td>1.325846e+06</td>\n",
       "      <td>702076.923077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256310.692308</td>\n",
       "      <td>256455.153846</td>\n",
       "      <td>619000.000000</td>\n",
       "      <td>360000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5812</th>\n",
       "      <td>2024-11-03 20:00:00</td>\n",
       "      <td>17.716067</td>\n",
       "      <td>16.851844</td>\n",
       "      <td>77.111111</td>\n",
       "      <td>13.703678</td>\n",
       "      <td>57.222222</td>\n",
       "      <td>10.138878</td>\n",
       "      <td>21.207578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.860000</td>\n",
       "      <td>105.860000</td>\n",
       "      <td>1.294455e+06</td>\n",
       "      <td>702909.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>224797.545455</td>\n",
       "      <td>224923.545455</td>\n",
       "      <td>586909.090909</td>\n",
       "      <td>305636.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5813</th>\n",
       "      <td>2024-11-03 21:00:00</td>\n",
       "      <td>17.345656</td>\n",
       "      <td>16.604922</td>\n",
       "      <td>78.111111</td>\n",
       "      <td>13.580233</td>\n",
       "      <td>143.444444</td>\n",
       "      <td>9.924298</td>\n",
       "      <td>22.244722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.420000</td>\n",
       "      <td>103.420000</td>\n",
       "      <td>1.275000e+06</td>\n",
       "      <td>671000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>204638.076923</td>\n",
       "      <td>204759.846154</td>\n",
       "      <td>599384.615385</td>\n",
       "      <td>316538.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5814</th>\n",
       "      <td>2024-11-03 22:00:00</td>\n",
       "      <td>16.604956</td>\n",
       "      <td>15.740744</td>\n",
       "      <td>81.444444</td>\n",
       "      <td>13.518511</td>\n",
       "      <td>284.222222</td>\n",
       "      <td>10.317698</td>\n",
       "      <td>24.515678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.420000</td>\n",
       "      <td>103.420000</td>\n",
       "      <td>1.294182e+06</td>\n",
       "      <td>636818.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>224458.272727</td>\n",
       "      <td>224580.181818</td>\n",
       "      <td>652636.363636</td>\n",
       "      <td>369272.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5815</th>\n",
       "      <td>2024-11-03 23:00:00</td>\n",
       "      <td>15.864200</td>\n",
       "      <td>14.753089</td>\n",
       "      <td>84.888889</td>\n",
       "      <td>13.395056</td>\n",
       "      <td>308.222222</td>\n",
       "      <td>10.943556</td>\n",
       "      <td>26.750844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.37814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.420000</td>\n",
       "      <td>103.420000</td>\n",
       "      <td>1.292538e+06</td>\n",
       "      <td>615692.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>221744.076923</td>\n",
       "      <td>221866.000000</td>\n",
       "      <td>672153.846154</td>\n",
       "      <td>388615.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5816</th>\n",
       "      <td>2024-11-04 00:00:00</td>\n",
       "      <td>15.524700</td>\n",
       "      <td>14.135800</td>\n",
       "      <td>86.222222</td>\n",
       "      <td>13.271594</td>\n",
       "      <td>303.888889</td>\n",
       "      <td>11.354833</td>\n",
       "      <td>28.395967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.09340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.716667</td>\n",
       "      <td>103.716667</td>\n",
       "      <td>1.281600e+06</td>\n",
       "      <td>583500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>211286.100000</td>\n",
       "      <td>211408.000000</td>\n",
       "      <td>693400.000000</td>\n",
       "      <td>349100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime       temp  real_feel_temp    rel_hum  dew_point  \\\n",
       "5793 2024-11-03 01:00:00  18.209867       16.358033  76.888889  14.074067   \n",
       "5794 2024-11-03 02:00:00  17.716044       15.925922  77.666667  13.641967   \n",
       "5795 2024-11-03 03:00:00  17.469133       15.679022  77.888889  13.580233   \n",
       "5796 2024-11-03 04:00:00  17.098756       15.246933  79.333333  13.518500   \n",
       "5797 2024-11-03 05:00:00  17.160489       15.246911  78.777778  13.395056   \n",
       "5798 2024-11-03 06:00:00  17.037033       15.308656  78.888889  13.395056   \n",
       "5799 2024-11-03 07:00:00  16.913567       15.432111  80.222222  13.456778   \n",
       "5800 2024-11-03 08:00:00  18.086411       17.407400  75.000000  13.703689   \n",
       "5801 2024-11-03 09:00:00  19.320978       19.074067  70.888889  13.888867   \n",
       "5802 2024-11-03 10:00:00  20.555556       21.049378  66.888889  14.197500   \n",
       "5803 2024-11-03 11:00:00  21.419767       22.222211  62.444444  14.135767   \n",
       "5804 2024-11-03 12:00:00  22.037033       22.777767  59.444444  14.012322   \n",
       "5805 2024-11-03 13:00:00  22.839511       23.580233  56.888889  13.950600   \n",
       "5806 2024-11-03 14:00:00  22.530856       22.716033  58.333333  14.012333   \n",
       "5807 2024-11-03 15:00:00  21.851867       21.543222  60.333333  14.012333   \n",
       "5808 2024-11-03 16:00:00  21.358022       20.679022  62.444444  14.012333   \n",
       "5809 2024-11-03 17:00:00  20.679033       19.197533  65.555556  13.888878   \n",
       "5810 2024-11-03 18:00:00  19.567889       18.024689  70.222222  13.827144   \n",
       "5811 2024-11-03 19:00:00  18.209867       17.160489  75.111111  13.827144   \n",
       "5812 2024-11-03 20:00:00  17.716067       16.851844  77.111111  13.703678   \n",
       "5813 2024-11-03 21:00:00  17.345656       16.604922  78.111111  13.580233   \n",
       "5814 2024-11-03 22:00:00  16.604956       15.740744  81.444444  13.518511   \n",
       "5815 2024-11-03 23:00:00  15.864200       14.753089  84.888889  13.395056   \n",
       "5816 2024-11-04 00:00:00  15.524700       14.135800  86.222222  13.271594   \n",
       "\n",
       "        wind_dir   wind_spd  wind_gust_spd    uv_idx       vis  ...  \\\n",
       "5793   60.777778  17.327300      30.255644  0.000000  16.09340  ...   \n",
       "5794   55.222222  17.523989      29.433111  0.000000  16.09340  ...   \n",
       "5795   94.333333  17.112711      28.628433  0.000000  16.09340  ...   \n",
       "5796   22.000000  17.130600      27.805878  0.000000  16.09340  ...   \n",
       "5797   32.777778  16.486867      26.965444  0.000000  16.09340  ...   \n",
       "5798   40.666667  15.861011      25.964078  0.000000  16.09340  ...   \n",
       "5799   41.111111  15.235156      25.123656  0.000000  16.09340  ...   \n",
       "5800   37.777778  15.253033      24.515678  1.000000  16.09340  ...   \n",
       "5801   74.000000  15.449733      24.301089  1.888889  16.09340  ...   \n",
       "5802  109.888889  14.859633      23.496422  2.777778  16.09340  ...   \n",
       "5803  101.444444  14.859633      22.423533  3.444444  16.09340  ...   \n",
       "5804  162.666667  14.645056      22.244733  3.222222  15.37814  ...   \n",
       "5805  174.222222  15.074211      21.851344  3.777778  16.09340  ...   \n",
       "5806  182.444444  15.664311      22.655978  3.000000  16.09340  ...   \n",
       "5807  183.888889  15.700067      24.104411  2.000000  15.37814  ...   \n",
       "5808  184.111111  14.430478      23.067256  1.000000  16.09340  ...   \n",
       "5809  148.222222  13.214522      22.226811  0.000000  16.09340  ...   \n",
       "5810   73.222222  11.336956      22.441411  0.000000  16.09340  ...   \n",
       "5811   70.111111  10.728978      21.618844  0.000000  16.09340  ...   \n",
       "5812   57.222222  10.138878      21.207578  0.000000  16.09340  ...   \n",
       "5813  143.444444   9.924298      22.244722  0.000000  16.09340  ...   \n",
       "5814  284.222222  10.317698      24.515678  0.000000  16.09340  ...   \n",
       "5815  308.222222  10.943556      26.750844  0.000000  15.37814  ...   \n",
       "5816  303.888889  11.354833      28.395967  0.000000  16.09340  ...   \n",
       "\n",
       "      precip_1h  실시간 임시 가격(원/kWh)  실시간 확정 가격(원/kWh)      공급능력(kW)  \\\n",
       "5793   0.000000        108.924000        108.924000  1.139692e+06   \n",
       "5794   0.000000        103.236667        103.236667  1.155455e+06   \n",
       "5795   0.000000         98.398000         98.398000  1.162154e+06   \n",
       "5796   0.000000         95.116667         95.116667  1.188909e+06   \n",
       "5797   0.000000        102.490000        102.490000  1.219462e+06   \n",
       "5798   0.000000        104.500000        104.500000  1.213364e+06   \n",
       "5799   0.000000        116.480000        116.480000  1.223154e+06   \n",
       "5800   0.000000        137.910000        137.910000  1.237727e+06   \n",
       "5801   0.000000        150.890000        150.890000  1.262538e+06   \n",
       "5802   0.000000        148.923333        148.923333  1.280000e+06   \n",
       "5803   0.000000        141.514000        141.514000  1.278615e+06   \n",
       "5804   0.000000        128.916667        128.916667  1.268636e+06   \n",
       "5805   0.000000        115.314000        115.314000  1.260308e+06   \n",
       "5806   0.000000        113.953333        113.953333  1.270273e+06   \n",
       "5807   0.028222        113.732000        113.732000  1.272000e+06   \n",
       "5808   0.000000        119.056667        119.056667  1.281727e+06   \n",
       "5809   0.000000        131.206000        131.206000  1.268615e+06   \n",
       "5810   0.000000        131.260000        131.260000  1.302455e+06   \n",
       "5811   0.000000        121.588000        121.588000  1.325846e+06   \n",
       "5812   0.000000        105.860000        105.860000  1.294455e+06   \n",
       "5813   0.000000        103.420000        103.420000  1.275000e+06   \n",
       "5814   0.000000        103.420000        103.420000  1.294182e+06   \n",
       "5815   0.000000        103.420000        103.420000  1.292538e+06   \n",
       "5816   0.000000        103.716667        103.716667  1.281600e+06   \n",
       "\n",
       "          현재 수요(kW)   태양광 발전량kW)     풍력 발전량(kW)  신재생 발전량 총합(kW)  \\\n",
       "5793  528153.846154     0.000000   77352.069231    77597.192308   \n",
       "5794  511090.909091     0.000000   86352.463636    86597.045455   \n",
       "5795  504692.307692     0.000000   92392.100000    92636.153846   \n",
       "5796  491454.545455     0.000000  117552.909091   117796.636364   \n",
       "5797  506769.230769     0.000000  148452.769231   148696.307692   \n",
       "5798  524272.727273     0.000000  143401.181818   143643.363636   \n",
       "5799  565384.615385     0.000000  151426.230769   151670.153846   \n",
       "5800  622727.272727     0.000000  165409.000000   165729.000000   \n",
       "5801  664461.538462  1884.663846  188450.153846   190779.846154   \n",
       "5802  690545.454545  3222.000909  204576.636364   208088.909091   \n",
       "5803  696307.692308  5440.853077  200946.923077   206677.846154   \n",
       "5804  700727.272727  3809.337273  191933.454545   196032.818182   \n",
       "5805  711692.307692  3216.756154  185112.307692   188531.153846   \n",
       "5806  713909.090909  4464.423636  193692.909091   198330.272727   \n",
       "5807  698615.384615  5389.608462  194680.461538   200145.076923   \n",
       "5808  694636.363636  1842.583636  207820.272727   209796.636364   \n",
       "5809  707153.846154     0.000000  198144.076923   198321.230769   \n",
       "5810  716363.636364     0.000000  233242.545455   233358.545455   \n",
       "5811  702076.923077     0.000000  256310.692308   256455.153846   \n",
       "5812  702909.090909     0.000000  224797.545455   224923.545455   \n",
       "5813  671000.000000     0.000000  204638.076923   204759.846154   \n",
       "5814  636818.181818     0.000000  224458.272727   224580.181818   \n",
       "5815  615692.307692     0.000000  221744.076923   221866.000000   \n",
       "5816  583500.000000     0.000000  211286.100000   211408.000000   \n",
       "\n",
       "         공급 예비력(kW)     운영 예비력(kW)  \n",
       "5793  581615.384615  364769.230769  \n",
       "5794  625363.636364  398727.272727  \n",
       "5795  647846.153846  373923.076923  \n",
       "5796  687363.636364  408000.000000  \n",
       "5797  710384.615385  424076.923077  \n",
       "5798  684363.636364  402363.636364  \n",
       "5799  653000.000000  369000.000000  \n",
       "5800  610181.818182  378909.090909  \n",
       "5801  593153.846154  362153.846154  \n",
       "5802  584909.090909  353909.090909  \n",
       "5803  577461.538462  346230.769231  \n",
       "5804  563000.000000  331909.090909  \n",
       "5805  543692.307692  312846.153846  \n",
       "5806  551272.727273  320727.272727  \n",
       "5807  568615.384615  337000.000000  \n",
       "5808  582454.545455  351636.363636  \n",
       "5809  556615.384615  327230.769231  \n",
       "5810  581272.727273  353272.727273  \n",
       "5811  619000.000000  360000.000000  \n",
       "5812  586909.090909  305636.363636  \n",
       "5813  599384.615385  316538.461538  \n",
       "5814  652636.363636  369272.727273  \n",
       "5815  672153.846154  388615.384615  \n",
       "5816  693400.000000  349100.000000  \n",
       "\n",
       "[24 rows x 23 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_set = ElecDataset(input_data, Y.iloc[:24])\n",
    "\n",
    "predict_dataloader = DataLoader(dataset=predict_set,\n",
    "                        batch_size=24,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815],\n",
      "        [129.1815]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  for inputs, _ in predict_dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    predictions = model(inputs)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129.18152247732968, 129.18152137362506, 129.18152048631006, 129.1815199554289, 129.18152385138816, 129.1815210415397, 129.18152358236506, 129.18153098110392, 129.18153426704106, 129.18153569574054, 129.18153565898717, 129.18153341082245, 129.1815342274402, 129.18153474889675, 129.1815343280527, 129.1815337762944, 129.1815313405146, 129.18153087053045, 129.1815303783442, 129.1815223523374, 129.18152282752257, 129.1815288665157, 129.18152694718293, 129.18152899299724]\n"
     ]
    }
   ],
   "source": [
    "flattened_list = predictions.view(-1).tolist()\n",
    "\n",
    "print(flattened_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
